{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8098a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 라이브러리 임포트\n",
    "# 필요한 라이브러리를 불러옵니다. 초보자: 설치 안 됐으면 `pip install roboflow ultralytics opencv-python` 실행\n",
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "import cv2  # 웹캠 영상 처리를 위해 OpenCV 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc47b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 로드\n",
    "# 경로 확인: 학습 후 저장된 best.pt 파일 경로로 변경 (예: runs/detect/acne_detection2/weights/best.pt)\n",
    "model_path = 'acne_lesion_detection/yolo11n_lesion_detection_run/weights/best.pt'\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c85521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 및 경로 설정\n",
    "BASE_DIR = os.path.join(os.getcwd(), \"resized\")\n",
    "MODEL_PATH = os.path.join(BASE_DIR, 'best_acne_yolo.pt')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "YAML_PATH = os.path.join(BASE_DIR, 'data.yaml')\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"yolo_dataset\")\n",
    "LABEL_DIR = os.path.join(BASE_DIR, 'labels')  # 실제 레이블 파일(.txt)이 있는 폴더\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)\n",
    "\n",
    "# 클래스 및 디렉토리 정의\n",
    "CLASS_NAMES = ['normal', 'mild', 'moderate', 'severe', 'very_severe']\n",
    "CLASS_ID_MAP = {\"normal\": 0, \"mild\": 1, \"moderate\": 2, \"severe\": 3, \"very_severe\": 4}\n",
    "CLASS_DIRS = {\n",
    "    \"normal\": os.path.join(BASE_DIR, \"normal\"),\n",
    "    \"mild\": os.path.join(BASE_DIR, \"mild\"),\n",
    "    \"moderate\": os.path.join(BASE_DIR, \"moderate\"),\n",
    "    \"severe\": os.path.join(BASE_DIR, \"severe\"),\n",
    "    \"very_severe\": os.path.join(BASE_DIR, \"very_severe\")\n",
    "}\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\", \".JPG\", \".JPEG\", \".PNG\")\n",
    "NUM_CLASSES = 5\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 416  # 학습 및 감지 이미지 크기 (화질 개선)\n",
    "\n",
    "# 데이터셋 폴더 생성\n",
    "train_dir = os.path.join(DATASET_DIR, 'train')\n",
    "val_dir = os.path.join(DATASET_DIR, 'val')\n",
    "test_dir = os.path.join(DATASET_DIR, 'test')\n",
    "os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'labels'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc0a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 이미지 파일 확인 함수\n",
    "def is_image(p):\n",
    "    return os.path.isfile(p) and any(p.lower().endswith(ext) for ext in IMG_EXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156e3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 데이터 로드 및 분할 함수\n",
    "def load_and_split_data():\n",
    "    rows = []\n",
    "    for label_name, class_dir in CLASS_DIRS.items():\n",
    "        if not os.path.isdir(class_dir):\n",
    "            print(f\"[ERROR] Directory not found: {class_dir}\")\n",
    "            continue\n",
    "        class_files = [p for p in glob(os.path.join(class_dir, \"**\", \"*\"), recursive=True) if is_image(p)]\n",
    "        if not class_files:\n",
    "            print(f\"[ERROR] No images found in: {class_dir}\")\n",
    "            continue\n",
    "        print(f\"Found {len(class_files)} images in {label_name}\")\n",
    "        for fp in class_files:\n",
    "            rows.append([fp, label_name, CLASS_ID_MAP[label_name]])\n",
    "    \n",
    "    if not rows:\n",
    "        raise ValueError(\"No images found in any class directories.\")\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=[\"filepath\", \"label_name\", \"label_id\"])\n",
    "    out_csv = os.path.join(BASE_DIR, \"labels_total.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"CSV saved: {out_csv}\")\n",
    "    print(\"Label distribution:\\n\", df[\"label_name\"].value_counts())\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.15, stratify=df[\"label_name\"], random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.1765, stratify=train_df[\"label_name\"], random_state=42)\n",
    "    print(\"Train dataset size:\", len(train_df))\n",
    "    print(\"Val dataset size:\", len(val_df))\n",
    "    print(\"Test dataset size:\", len(test_df))\n",
    "    \n",
    "    targets = {\"normal\": 1000, \"mild\": 800, \"moderate\": 800, \"severe\": 1000, \"very_severe\": 1000}\n",
    "    rng = np.random.default_rng(42)\n",
    "    outs = []\n",
    "    for lab, n in targets.items():\n",
    "        sub = train_df[train_df[\"label_name\"] == lab]\n",
    "        if len(sub) >= n:\n",
    "            outs.append(sub.sample(n=n, random_state=42))\n",
    "        else:\n",
    "            idx = rng.choice(sub.index.to_numpy(), size=n, replace=True)\n",
    "            outs.append(train_df.loc[idx])\n",
    "    train_bal = pd.concat(outs, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    train_bal.to_csv(os.path.join(BASE_DIR, \"split_train.balanced.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(BASE_DIR, \"split_val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(BASE_DIR, \"split_test.csv\"), index=False)\n",
    "    print(\"Train balanced:\\n\", train_bal[\"label_name\"].value_counts())\n",
    "    print(\"Val:\\n\", val_df[\"label_name\"].value_counts())\n",
    "    print(\"Test:\\n\", test_df[\"label_name\"].value_counts())\n",
    "    \n",
    "    return train_bal, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654b84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. YOLO 데이터셋 폴더 구조 생성 및 실제 레이블 파일 복사\n",
    "def organize_yolo_folders(csv_df, dest_folder):\n",
    "    for _, row in csv_df.iterrows():\n",
    "        label_id = row['label_id']\n",
    "        src_path = row['filepath']\n",
    "        img_dest_dir = os.path.join(dest_folder, 'images')\n",
    "        label_dest_dir = os.path.join(dest_folder, 'labels')\n",
    "        dest_img_path = os.path.join(img_dest_dir, os.path.basename(src_path))\n",
    "        dest_label_path = os.path.join(label_dest_dir, os.path.splitext(os.path.basename(src_path))[0] + '.txt')\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_img_path)\n",
    "            src_label_path = os.path.join(LABEL_DIR, os.path.splitext(os.path.basename(src_path))[0] + '.txt')\n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.copy(src_label_path, dest_label_path)\n",
    "            else:\n",
    "                print(f\"[WARNING] Label file not found: {src_label_path}\")\n",
    "                if label_id == 0:  # normal 클래스\n",
    "                    with open(dest_label_path, 'w') as f:\n",
    "                        f.write(\"\")  # 빈 파일\n",
    "                else:\n",
    "                    print(f\"[ERROR] Non-normal class missing label: {src_label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9086e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file created: c:\\Users\\Admin\\work space\\2nd\\resized\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "# 7. YOLO 데이터 YAML 파일 생성\n",
    "\n",
    "data_yaml = {\n",
    "    'path': DATASET_DIR,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': NUM_CLASSES,\n",
    "    'names': CLASS_NAMES\n",
    "}\n",
    "with open(YAML_PATH, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "print(f\"YAML file created: {YAML_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c20acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 936 images in normal\n",
      "Found 359 images in mild\n",
      "Found 95 images in moderate\n",
      "Found 128 images in severe\n",
      "Found 90 images in very_severe\n",
      "[ERROR] Failed to prepare dataset: name 'pd' is not defined\n"
     ]
    }
   ],
   "source": [
    "# 8. 데이터셋 준비\n",
    "try:\n",
    "    train_bal, val_df, test_df = load_and_split_data()\n",
    "    organize_yolo_folders(train_bal, train_dir)\n",
    "    organize_yolo_folders(val_df, val_dir)\n",
    "    organize_yolo_folders(test_df, test_dir)\n",
    "    print(\"YOLO folder structure and labels created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to prepare dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b5ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded model from: c:\\Users\\Admin\\work space\\2nd\\resized\\best_acne_yolo.pt\n",
      "Class names in code: ['normal', 'mild', 'moderate', 'severe', 'very_severe']\n",
      "Class names in data.yaml: ['normal', 'mild', 'moderate', 'severe', 'very_severe']\n"
     ]
    }
   ],
   "source": [
    "import torch  # <-- torch 라이브러리를 import 합니다.\n",
    "\n",
    "# --- 1. 장치(DEVICE) 설정 ---\n",
    "# GPU(CUDA) 사용이 가능하면 'cuda'를, 그렇지 않으면 'cpu'를 사용하도록 설정합니다.\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- 2. 학습된 YOLO 모델 로드 ---\n",
    "# MODEL_PATH 변수는 이전 셀에서 정의된 것을 사용합니다.\n",
    "model = YOLO(MODEL_PATH)\n",
    "model.to(DEVICE)  # <-- 이제 DEVICE 변수가 정의되었으므로 오류가 발생하지 않습니다.\n",
    "print(f\"Loaded model from: {MODEL_PATH}\")\n",
    "\n",
    "# --- 3. 클래스 매핑 확인 ---\n",
    "print(\"Class names in code:\", CLASS_NAMES)\n",
    "with open(YAML_PATH, 'r') as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "print(\"Class names in data.yaml:\", yaml_data['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d867173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 재학습 함수\n",
    "def retrain_model():\n",
    "    model = YOLO('yolo11n.pt')  # 새 모델 로드\n",
    "    results = model.train(\n",
    "        data=YAML_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,  # 416\n",
    "        batch=BATCH_SIZE,\n",
    "        device=DEVICE,\n",
    "        name='acne_yolo',\n",
    "        patience=10,\n",
    "        project=BASE_DIR,\n",
    "        exist_ok=True,\n",
    "        augment=True\n",
    "    )\n",
    "    model.save(MODEL_PATH)\n",
    "    print(f\"Retrained model saved at: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aac6aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['epoch', 'time', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAHqCAYAAADyGZa5AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsXQeYG9XVvdpebK977+CCKQYMmF4SSoAEQkkIJCH0kpCEkAah/QECKUAqJXQIJEBogdBx6BiMMQbce+9td7296P/Om7mjN6MZaSSN+j3ft16tVrsrPY9m3rnn3HND4XA4TAKBQCAQCAQCgUAgEAjSgpL0/FqBQCAQCAQCgUAgEAgEgBBvgUAgEAgEAoFAIBAI0ggh3gKBQCAQCAQCgUAgEKQRQrwFAoFAIBAIBAKBQCBII4R4CwQCgUAgEAgEAoFAkEYI8RYIBAKBQCAQCAQCgSCNEOItEAgEAoFAIBAIBAJBGiHEWyAQCAQCgUAgEAgEgjRCiLdAIBAIBAKBQCAQCARphBBvgUAgEAgEAoEgDTjnnHNo9OjRCf3MW2+9RaFQSH0WpAdua5zM/5VAkAiEeAsEeYqHHnpIXTT0j4EDB9JRRx1FL7/8ctYuYk899VTG/7ZAIBAIBG7XxqqqKho/fjxddtlltHHjxmw/vbxAa2srXXXVVYqE1tTU0MSJE+lnP/tZQr8DJFb/f6isrFT/D9ddd536/QJBMaIs209AIBCkhhtuuIHGjBlD4XBYbSqw6TjhhBPohRdeoK9+9avZfnoCgUAgEGTt2giS995779Fdd91FL730Es2ZM0eRyUzh3nvvpe7u7oR+5vDDD6eWlhaqqKigbOCXv/wl/eUvf6HzzjuPpk6dSgsXLqRHH32Ubr311oR+D8j2fffdp27X19fTf/7zH7rxxhtp6dKl9Nhjj6Xp2QsEuQsh3gJBnuP444+n/fbbz/r6/PPPp0GDBtG//vUvId4CgUAgoGK/Nl5wwQXUr18/uv322xX5O/PMM11/pqmpiWprawN9HuXl5Qn/TElJiVLqs4XHH39cFfDvv/9+676bb7454d9TVlZG3/nOd6yvv//979PBBx+s9if4v8BeRSAoJojVXCAoMPTu3Zuqq6vVBc+5ofjpT39KI0aMUFXoCRMmqOo1lHIA1XXYyfCB24xt27bRkCFD1MWyq6sr5ee3bNky+sY3vkF9+/ZVqsOBBx5IL774YtTj/vrXv9Luu++uHtOnTx+1gfrnP/9pfb+xsZEuv/xyZYXD64HN/phjjqFZs2al/BwFAoFAUFj40pe+pD4vX77cskL36NFDqa8gmT179qRvf/vb6ntQqP/0pz+paxAIMAjixRdfTNu3b4/6vWjtOuKII9TP9+rVi/bff3/btcqtbxjEdsqUKdbP7LnnnvTnP/85bo/3v//9b/VzuMb3799fkdq1a9faHsOvC/d//etfV7cHDBigrOJ+r+Eg/rw3YOA6myrwmg499FD1u7EXcK7jYYcdpgofWJcTTzyR5s6dG/U7FixYQN/85jfVa8I6YC9z9dVXW99fuXKlIvi4H99HwQV7jhUrVqT8/AWCVCHEWyDIc8C+tWXLFtq8ebO6SF166aW0c+dOW5UZF7mTTjqJ/vjHP9JXvvIVVWnGRennP/85XXHFFeoxuEA9/PDDtGTJEttF7Ac/+IH6G7Cwl5aWpvRcYYUHgX/11VfVhfE3v/mNsgHiuT377LM2a96PfvQjmjRpktr8/PrXv6a9996bPvroI+sxl1xyibIOnnbaaXTnnXeqTQVew/z581N6jgKBQCAoPIBgAyBijM7OTjruuONU4RaFaFxPAJBsXB8POeQQRYjPPfdcZY3GYzs6Oqyfx3URBBEFavRE//a3v1XXqldeecXzebz++utKcUdB+Xe/+536mSOPPJLef//9mM8ffwuEE9fhW265hS688EJ65plnFJHdsWOH7bEg2HiueK14XSgM3HbbbXTPPff4Wiu8XryGdOTFMAHG62f84x//UOuIIgHW5Nprr6V58+ap16YT5s8//1xZ3//3v/+p14//GxQX0FrH+Pjjj+mDDz6gb33rW8ouj73CtGnT1Bo3NzcH/noEgoQQFggEeYkHH3wQ5eioj8rKyvBDDz1ke+xzzz2nvnfTTTfZ7j/99NPDoVAovGTJEuu+q666KlxSUhJ+5513wv/+97/Vz/3pT3+K+3zefPNN9Vj8jBcuv/xy9Zh3333Xuq+xsTE8ZsyY8OjRo8NdXV3qvpNPPjm8++67x/x7dXV14R/84Adxn5dAIBAIiu/a+MYbb4Q3b94cXr16dfjxxx8P9+vXL1xdXR1es2aNetz3vvc99bgrr7zS9vO4PuH+xx57zHb/K6+8Yrt/x44d4Z49e4anTp0abmlpsT22u7vbuo2/M2rUKOvrH//4x+FevXqFOzs7415P8Rlob28PDxw4MLzHHnvY/tZ///tf9bjrrrvO9vdw3w033GD7nfvss094ypQpcdevo6Mj/J3vfCdcUVERrq2tDX/wwQfhZIDngZ/H/wE+sM+49dZb1Z4Dr4PXCHuA3r17hy+88ELbz2/YsEFd5/X7Dz/8cLXmK1eu9Fzv5ubmqOcyffp0tSaPPPKI5xq7/V8JBEFDFG+BIM9xxx13qAo6PhB+glRz9LOhEs5AoAyq5FCRdcB6DjVcr2r/3//9n7LXfe9731OqNCrlzp9LFngeBxxwgKpiM1Dhvuiii1RVGxVutsuvWbNGVa69gMdAAV+3bl0gz00gEAgEhYOjjz5a2ZHRXgX1E9caOKuGDRtmexxcYk47d11dnWpdgpuMP2Dxxu9488031eNwzUXL05VXXhnVjw1LdaxrF1q/8PN+MXPmTNq0aZO6Jut/Cyox2sPc2rWg9OqAjdtp73bDL37xC7Un+OKLL5S6DBv+7Nmzre+vX79evT69/9sLeJ34P8DHrrvuqpxpcBGgz57XCOsAxR4uAH29sWfB3+f1hqvvnXfeUYFvI0eO9FxvON8YcCds3bpV/W2su7SiCbINCVcTCPIcILJ6uBouXvvss48anYJwNaSioudp6NChqm9Kx2677aY+4/sMPP6BBx5QfWq4wD/44IMxNxGJAH8HF1In9Oexxx57qETVN954Q702XDCPPfZYOuuss9QFm/H73/9eFQewqcKGCJuDs88+m8aOHRvIcxUIBAJBfhelMb4KeSfo0UZ7FXqXdeB7w4cPt923ePFi1V4F+7kbQIB16zquWYkA5PnJJ59U4W8oAuD6Bgs52sC8wNdovAYnQLyR2q4D126QXR2wdrv1qOtAXzjs2bCyY+2ee+45VXzHc3z33XfV30cqPOB2LXcCz4Nt4Cim47qN9dPJMdZb78F3Aj3wABcN4q03Mmrw/LF3wevRe9Xx/yoQZBNCvAWCAgM2FlC90fuECxrU60SBHmwA/df4HRjJkkmAiGN8yX//+1/VZ/b000+rPm7M/0S/N4CNCir4UDBee+01+sMf/qB6w6D0Y0MjEAgEguKFsyjtBgSGOck4gtVAur3GXTkJbaLA74aCjOsslGV8gCSicIyclSCQbB4LXGToD0foKYBiPZ4fit5wEIB8o0988uTJvgoOeB74OQb6zlEoQA/9888/r+7jUWvo8x48eHDU73AGxcbDD3/4Q7WeCF896KCDlHsB4gFcD4mOdRMIgoYQb4GgAIHAGAAha8CoUaOUggxbnK56Ix2Uv6+Hl2D+KcJVsDmAbR2WM1y8UgX+Dgi1E27PA8mmZ5xxhvpob2+nU089VYWxIcCGrXZIW4d6gA9U0ffdd1/1GCHeAoFAIEgGu+yyi7pegmzqyqzb4wAowHBmJQI4y772ta+pD5BBXMP+/ve/q1Axt9/F10ZcP53KMO7Tr52pgN1tq1evtu6DWwBFAqwH1G8o13orWyLANfsnP/mJKqB/+OGHiuDzOqIgoZN0J9jNxoq7F5566inlhkOYHAMigjOATiDIBqTHWyAoMKCnCQowLuxs4YYNG1Xsv/3tb7bHIuUcF1omqvhZjCKBLR2KOVJUkUSOC2UQwPOYMWMGTZ8+3dYDhgo6xq0gxRxAT5YOvBZ8D5YxPEe8FqdlDBdtPO+2trZAnqtAIBAIig9wU+Eac+ONN7oWtZnAwX6NQjZszSB2OpyjuHQ4r29Q3Pfaay912+v6BeUe17i7777b9hio0ZjkgV7vIID8FbgAkLSuJ4CDHGPCyKpVq1QRHgQ8WUCRxphQ/A1WwWEnx5xwPTGegd5udhocfvjhqhUOz8NrvaGyO9cf40mDGIcqEKQKUbwFgjwHLrysGEP1xfxQ2MMR+MK9Uaiqw36OMWEIMYNNDOQcASewY3HF+aabblIqN0ZvYEOBzQDs3ddccw2dfvrpijjHA2zh/Hx0oAKN5/Svf/1LEX0EtmGWN6x1mKuKn2PLHzY0sJyhwo5qOzYWKBpgc4HnhY0P+vLwnPBaEHgDhQJhbHqVWyAQCASCRABSCSs0CDWuh7gelZeXq+sqgtdQlMa1B9dXFK/hCkMmCnJI0Ef92WefKdLqZRvH4zF+DMo1rmPo3wYxxBgyLpY7gb+PVio40fD8kOWCojieC4rWQRXHQW7xujFmFLPFEWSGazHC3fB6oFAjoAyvH3sPPK9EgRFneB1oH8O1Ha8Zo0G/+93vKtcaLOF4HiDXCI3DPoBFA/SfoziAxyGUFW1w2NPgcRwAh2wb2NZRIEDBHoV+7A/0MXICQdYQeE66QCDI2jixqqqq8N577x2+6667bOM1eGTHT37yk/DQoUPD5eXl4XHjxoX/8Ic/WI/75JNPwmVlZeEf/vCHtp/DyJP9999f/dz27ds9nw+P5vD64BFiS5cuVWPMMD4Ez/eAAw5QI1F0/P3vf1djQzD+BePRdtlll/DPf/7zcH19vfp+W1ub+nry5MlqtAhGluD2nXfeGdj6CgQCgSB/r40ff/yxr3FXXrjnnnvU+C2MIMN1Zs899wz/4he/CK9bt872uOeffz588MEHq8dhTBiuaf/61788R1Q99dRT4WOPPVaNB8PIrpEjR4Yvvvji8Pr162OOugKeeOIJNRYM18W+ffuGv/3tb1vj0eK9ruuvv179Tj/ACNLDDjtM/R68rv3220/tK7AfwLrg95x33nlJry/2AaWlpeox+ms+7rjj1Agx7A1w3T/nnHPCM2fOtP3snDlzwqeccoq1h5gwYUL42muvtb6Pfcq5554b7t+/f7hHjx7qdy5YsED9Hzj/nowTE2QaIfyTPdovEAgEAoFAIBAIBAJBYUN6vAUCgUAgEAgEAoFAIEgjhHgLBAKBQCAQCAQCgUCQRgjxFggEAoFAIBAIBAKBII0Q4i0QCAQCgUAgEAgEAkEaIcRbIBAIBAKBQCAQCASCNEKIt0AgEAgEAoFAIBAIBGlEGRUZuru7ad26ddSzZ08KhULZfjoCgUAgEEQBkz4bGxtp6NChVFJSvDVyuWYLBAKBoFCu10VHvHEBHzFiRLafhkAgEAgEcbF69WoaPnw4FSvkmi0QCASCQrleFx3xRtWcF6dXr17ZfjoCgUAgEEShoaFBEU6+ZhUr5JotEAgEgkK5Xhcd8WarGi7gchEXCAQCQS6j2O3Vcs0WCAQCQaFcr4u3cUwgEAgEAoFAIBAIBIIMQIi3QCAQCAQCgUAgEAgEaYQQb4FAIBAIBAKBQCAQCNKIouvx9ouuri7q6OjI9tMQ5DHKy8uptLQ0209DIBAIBAKBQCAQZBlCvF1msW3YsIF27NiR7aciKAD07t2bBg8eXPQBSQKBQCAQCAQCQTFDiLcDTLoHDhxINTU1QpgESRdwmpubadOmTerrIUOGZPspCQQCgUAgEAgEgixBiLfDXs6ku1+/ftl+OoI8R3V1tfoM8o1jSmznAoFAIBAIBAJBcULC1TRwTzeUboEgCPCxJHkBAoFAIBAIBAJB8UKItwvEXi4ICnIsCQQCgUAgEAgEAiHeAoFAIBAIBAKBQCAQpBFCvAWeGD16NP3pT3/K9tMQCAQCgUAgEAgEgryGEO8CsTPH+vi///u/pH7vxx9/TBdddFFKz+3II4+0PZdBgwbRN77xDVq5ciWlEw899JAa5SUQCASCYPDOO+/Q1772NRo6dKg6nz/33HNxf+att96ifffdlyorK2nXXXdV52aBQCAQCIoRQrwLAOvXr7c+oFD36tXLdt/PfvYz25irzs5OX793wIABgQTNXXjhhep5rFu3jv7zn//Q6tWr6Tvf+U7Kv1cgEAgEmUNTUxNNnjyZ7rjjDl+PX758OZ144ol01FFH0ezZs+nyyy+nCy64gF599dW0P1eBQCAQCHINQrwLAIMHD7Y+6urqlBLBXy9YsIB69uxJL7/8Mk2ZMkWpDu+99x4tXbqUTj75ZKVA9+jRg/bff3964403YlrN8Xvvu+8+OuWUUxQhHzduHD3//PNxnx8ei+eCWdYHHnggXXbZZTRr1izbY95++2064IAD1PPD46688kqrQPDII4+o57h48WLr8d///vdp4sSJalZ2Mli1apV6/fi9KFR885vfpI0bN1rf/+yzz9RmEWuH72PtZs6cqb4HtR6qT58+fai2tpZ23313eumll5J6HgKBQJAvOP744+mmm25S1wA/uPvuu2nMmDF022230W677abO/aeffjr98Y9/TPtzFQgEAoEg1yDEOw6gEDe3d2blA387KIDI/va3v6X58+fTXnvtRTt37qQTTjiBpk2bRp9++il95StfUWQShDQWfv3rXyuS+vnnn6uf//a3v03btm3z/Tzw2CeffJKmTp1q3bd27Vr1u0D+QXjvuusuuv/++9UGDzj77LOtvwUy/uKLL6oCwGOPPZaUIt/d3a1IN54LCP/rr79Oy5YtozPOOMN6DP7W8OHDld3+k08+UetXXl6uvveDH/yA2tralO3yiy++oN/97neKwCeMDXOIdm5K/OcEAoEgDzB9+nQ6+uijbfcdd9xx6v6sYNFrRHOeIWrZQQWHTQuIGtZl+1kUDhrWE22cm+1nUThobyJaPQMbsGw/k8JAdxfRqg+JOlqy/UwECaIs0R8oNrR0dNGk67Jji5t3w3FUUxHMf9ENN9xAxxxzjPV13759lWWQceONN9Kzzz6rFGyoEl4455xz6Mwzz1S3b775ZvrLX/5CM2bMUMTdC3feeaciyqqI0dxM48ePt1kN8f0RI0bQ3/72N6WqQ8mGLf2Xv/wlXXfddVRSUkJ///vfVcHgRz/6ET3zzDOqbx0qdDJAsQGEGTZI/F1W1aFcg2ijAIACxM9//nP1XACo+wx877TTTqM999xTfT127NjEn0T9WqK/H0Y0ZDLRRW8l9ToEAoEgl7FhwwblqtKBrxsaGqilpYWqq6ujfgZFTXww8NjA8MKPiBrXE138LlF1AWWANG8zrie9RxH90HBmCVLEP75OtGUR0RXziXoOzvazyX+8fh3Rx/cRnfEo0W5fy/azyX+ggPjMBUQHXUZ03G+y/WwECUAU7yLBfvvtZ/saijd6v2H/QwgZFFuo4fEUb5BfBmzWsGFv2hRbtYV6jP4+qNmwuSNg59hjj6XGxkb1ffzdgw46yDbz+pBDDlHPcc2aNepr2LqhgkMN32WXXZQCnSzw90C4mXQDkyZNUuuA7wFXXHGF6kWEWgOnAKz5DJB/qPF4jtdff71S/xPGjlVE4W6ircuSfh0CgUBQaLjllltUyxR/6OfplFFiFrK7O6igUL+aqKudqGFttp9J4ajdmxcY1+jGDdl+NoWBdZ8an8WVEQzWmgU2Wc+8gyjecVBdXqqU52z97aAAkqwDpBsW61tvvVURYSgP6L1rb2+P+XvYbs0AWYZ1OxawecLfAPAZBBp93E888YQit34Ba3dpaakKakPID/qv0wUo6meddZaytaM/HgT78ccfV72NeM6wS+J7r732mtoooofxhz/8YWK2K6CtwbBelUgNTCAQFBaQ7aFnZwD4GgVbN7UbuOqqq1ThU1e8AyPfFvHuooICW+e7/QWnCuJg7SeR27KmwWD7CuNzV4EVvbKFrUsKs4hYBJDdfhyAWMLunY0PXQEOGu+//76yjYNIwjKNDdKKFeaJMc0AeQZgNQSguqPnT+9px/MDsUafNfDBBx+oXuoXXnhBqfOx7PDxgL+HZHV8MObNm0c7duxQyjcDlvif/OQnilyfeuqp9OCDD1rfw0bwkksuUbb3n/70p3Tvvfcm9iTad5o3wkTthvIvEAgEhQQ4mdDaowMFX9zvBQRsgpjrH4GBiXehbf5b643PQhKDJ96FdqxkA22NRM1bjdtCFIMl3l3yns83iOJdpEDPMkgjAtVA8K+99tq4ynWyQF83ev1Y7UA/eVVVlbKbc0I50tOhGINQL1y4UCnMUD3Q3w1L+ne/+11l8UaqLsg4+rDx3KHSe6Grq0tZ3J2bOtjHUWyABR5/F4FteA5HHHGEsuSjIID+bvxuJPLC7o7eb/R1AxiJg+cBYr59+3Z68803FZlPCKx4A60NRFV1if28QCAQZBho/1myZIltXBjOscgMGTlypFKrEZaJzAwAxUlkd/ziF7+g8847j/73v/+pcE24hbICS/HuLEziDWu0OKiCs/ECQhRTx/aVkduF9t7LBjrbjHZFQNYz7yDEu0hx++23q43QwQcfTP3791dBZoGG2GiAGsyKMHq10SeO8VsTJkxQ9w0bNkx9DbKLwDds4s4//3y65ppr1Pd//OMfK6s8wtwAkGbcvvjii5Vygp/32iTus88+tvvQH46NI+aJg+gffvjhitwjHO6vf/2rpchv3bpVpamjUID1geKNRHcm9Eg2ByGHGoOfTXg8jqV486YpwD5GgUAgSAMwUhFjFhlsCf/e975HDz30kGoD0nNCULgEyYZz6M9//rMqmiJoE606WUFpoRJvLaUdr62kIpvPJr+BwsXaT7WvC+xYyabNHBCFNpj1RJENkMJQ3iEUDnJmVR4A5BI9x/X19VEWttbWVlXBx2YBiqxAkCo8j6l3byOadoNx+9yXiUYdnLXnKBAI8utaVUwIdB3uOdIIeTrrSaLxWSL/6cD/biJ65w/G7V+tJ6pIfMymQBvLdmdk3Cmd9W+i8YY7T5AkPvgb0WtXG7cP+xnRl6/N9jPKbyx4kejxs4zbow8jOue/2X5GRY+GBK5T4kcSCLIBp9VcIBAIBOlFoVvNC/G1ZbO/GxBFMXXs0K3msp6B9XcDkkGQdxDiLRBknXhrmyaBQCAQpAcl5YVJToV4p6e/GxBiE6zVvNAmCmSbeMv7Pe8gxFsgyAbatB5vjBQTCAQCQXpRUlqYZIrHiQGyEQ9Y8Zb1DLbHu8Dee9nA1mWR2+IgyDsI8RYIsgFbuJq2aRIIBAJBelBaXpiqmyjewaCjhWjjXON2//HGZyGKqYfVSap5GhXvAjuXFQGEeAsE2YD0eAsEAkGWerwLjEwJ8Q4G6z831q92IFGfMYV5rGQaOzcSdbVFvpb1TH0m+k5jPK+CFIbyDjJOTCDINvEWq7lAIBCkHxKuJvDT3z18P6KQqUsJsQnOZg7IOLHUsHWp/WspZOQdRPEWCLKBqDneAoFAIEgrCpZ4a+1KQmxS7+8etm/hHivZJt6ynsHYzEsrjc+ynnkHId4CQdaJtyjeAoFAkHYwmSokctrZTtTRHPlaNuLJY42peA/bT8sDkPUMlniLQhuI4m1lEMjxmW8Q4i0QZAMyTkwgEAgyi0JUMZ2tSoX02jKJpi2RedND94mMnhOreTDEu9dw47Mcn8Eo3gMnGp9lPfMOQrwFFo488ki6/PLLs/00igPS4y0QCASZRSGqmPoosUJ7bdmwmUNJrO5NVFqgQXyZBhcz+u1ifBaFNhjiPYCJtxyf+QYh3gWAr33ta/SVr3zF9XvvvvsuhUIh+vzzz1P+Ow899JD6XfzRo0cPmjJlCj3zzDOUbuDvPffcc1Qw4zVE8RYIBILszPEupM2q8/ohxDvF/u4pxmdL8Zb1DETx7j/O+CzHZ/IIhyNWc4t4yzixfIMQ7wLA+eefT6+//jqtWbMm6nsPPvgg7bfffrTXXnsF8rd69epF69evVx+ffvopHXfccfTNb36TFi5cGMjvLwqofrxw5Gvp8RYIBIL0g8lUIW1W9WA1QIhNiv3dUxzuiAIq0mRjLnrjeuN2Pybesp4ptUO0odAWkjnzeQwh3gWAr371qzRgwAClSOvYuXMn/fvf/1bEfOvWrXTmmWfSsGHDqKamhvbcc0/617/+lZTyPHjwYPUxbtw4uummm6ikpMSmqG/fvp3OPvts6tOnj/pbxx9/PC1evFh9b/Pmzepnb775ZuvxH3zwAVVUVNC0adOSev3d3d10ww030PDhw6myspL23ntveuWVV6zvt7e302WXXUZDhgyhqqoqGjVqFN1yyy3qe+FwmP7v//6PRo4cqX526NCh9KMf/YjSCl3tBjpbjIAcgUAgEGQgXK2ANquieAejJEYp3gV4rGQaO1YZnyt6EvUYUHhFr2zZzOtGEFX2MG7L+z3vIMTbzwkZRCkbH/jbPlBWVqaILog3iCQDpLurq0sR7tbWVmULf/HFF2nOnDl00UUX0Xe/+12aMWNG0kuD3/3www+r2/vuu691/znnnEMzZ86k559/nqZPn66e0wknnEAdHR2qQPDAAw8osovHNDY2qucBYvzlL385qefx5z//mW677Ta69dZbVQEAKvxJJ51kkf2//OUv6rk8+eSTSpl/7LHHaPTo0ep7Tz/9NP3xj3+kv//97+rxsLOjKJGRRPPymsh90uctEAgE6UUhhquJ4p065jxtrGNZNdGgPQr3WMk0tpv93X1GBxNWh9+36DWiYife6Je33DsdvrlCFOC2nPcfw5kgyBjMM4sgpi345qHZ+du/WkdUUevroeeddx794Q9/oLfffluFpLHN/LTTTqO6ujr18bOf/cx6/A9/+EN69dVXFRk94IADfD+l+vp61dsNtLS0UHl5Od1zzz20yy5GcAbIK0ju+++/TwcffLC6D0R3xIgRitR+4xvfUCT8wgsvpG9/+9vKBl9bW2sp0MkAhPuXv/wlfetb31Jf/+53v6M333yT/vSnP9Edd9xBq1atUur8oYceqhR7KN4MfA8K/NFHH61eC5TvRNYjJcW7shdRqJSovdFQLWr7p/fvCgQCQTGjtADJVJTiXWCKIojaR38nmnB8JKArSDSsI3rxCuP2IT8mKquwW81F8U69v7vPKK2QkcJ6Pncp0cr3iS5+h2jIZCo6bDP7u/vtGsmr4Pc8n9sSwft/Inr3NqLjf0809eLgnqcgJkTxLhBMnDhREV2oycCSJUtUsBps5qxO33jjjUrN7du3ryLPIN4gnomgZ8+eNHv2bPWBHm9Yxi+55BJ64YUX1Pfnz5+vFPipU6daP9OvXz+aMGGC+p5Oljs7O5UqD2IOm3cyaGhooHXr1tEhhxxiux9f89+DAo/ni+cAG/lrr0UqpigEoIAwduxYVQx49tln1fPKCPFGUaWql3FbAtYEAoEgvShEFdN57UgnUYSy1tFKGcWn/yB67Wqil36entfznx8Ya4gRYodHxAmboihIkXiPDmaiAIokQH10nlFxKd67RtYzlTVtMPvv61cH8OQEeaF4v/POO0ql/eSTT1RYF0jP17/+9Zg/89Zbb9EVV1xBc+fOVSrqNddco4hV2gA7MJTnbEC3IvsASDaUbKi8ULuhQh9xxBHqe1hnWLKhAoN8Q2XG6DD0PycC9HPvuuuu1tcIbQORhcqMdHW/WLp0qSLM6M9esWJFWu3dsMEvX76cXn75ZXrjjTdUGBwU7qeeekodQ7Cf434E1H3/+9+3nANQwNNqNUePTimq62vFai4QCATpRjEQ73S+tn+fQ7TsTaLLPon07KYbKz8wPq/60EgYT0bZ88LH9xEt/R9RWRXRKffYyUwhuiOySbxZoU0lJb6ztbgDabfqirf2PlDFoarEfx/yhYC2xoCeoCDnFe+mpiaaPHmyIop+APJ04okn0lFHHaUUTBDHCy64QCm3aUMoZCiT2fjA304AIJQgxv/85z/pkUceUfZzWKsBWL9PPvlk+s53vqPWHArvokWLAlmi0tJSpRoDu+22m1KMP/roI+v7CHYDuZ00aZL6GmQfz+OMM85QKjz+Dzdt2pR0yjoC0fD6dOBr/nv8OPy9e++9l5544gnV271t2zb1verqalU0QC84CjvoS//iiy8obWDiXdGDqKquuC8kAoFAkClYKmYBkalMzvFe/o5B9DmILBNYbe4lOpqINnwW3O/dsoTotWuN28fcQDTATIlmyDixxNC8LboItMOlx7s7AOKdb0Rx0atENw0imv3P1MbQWsRb6/FOZU072/Jz/7l9BdEfxhG9cDnlI7KqeCPtGh9+cffdd9OYMWNUkBaTvPfee0+FYyFQq9gB+zjI5VVXXaUs2LoTAD3OUHiRII608dtvv502btxoI6d+gKC0DRs2qNsg21CJUfi47rrrrL8Dgg/bNgLLYE2/8sorVZo67geuvvpq1SsOoovn/NJLL6kiwX//+9+4hRcUXHTg7/385z+n66+/Xin8SDSH2o/HwcIO4LUi0XyfffZRhQnY29HX3bt3bxVIBxs+rPFIYH/00UcVEdf7wNNqNWeI1VwgEAjSiyBUt2Lt8cbvbdluVzLTjcYNkWRsVr05dTwV4P//2YsNxW/MEUT7Xxj9GBkn5h9bFhPd92Ujt+bS9w1BATZ+XfHGKKxU15PbHPLNIfjWb42iwXt/JJp8ZsKimkLDGqKuNoNw9x5JFNJ002TPZxyqlm+FjI/+TtS0iWjWI0RH/Yqox0DKJ+RVjzeUSFiEdYBw435BxG6OcV5YFyjBDFjyYbnG/QhfA/GMZ+t3Awg9SCw+UPhAEQSjvECmGSC+SFDHmLODDjpIkXWQa1i3oSjD7v6Pf/xDqdAgwriNfvS77ror5t9GiwHIs/6BPnP0beN7P/3pT5VlHaPEEPAGUg6A/P/+979XQW7777+/srbj+eBvg3xDBUdPOGzzsJyjXx196Znp8a7LzwtJDuDNhZto4YY8u2DkMOata6B3Fm3O9tMQCNKHIPpMc554d6RP0aRw8MQbpMGr8Lx6hrvtPFXALr92JlFlHdHX70QPXfRjZJyYf/KGFgT8H6JX+H83Gfc3bzXdfSFj/FWq7z0QecsanUf7pXWzidbNMm5vWUS03i4eJdzf3XesUUAEeU+1dcZyEDTk1/E223QOhLuMiQR5hrxKNYfSOmjQINt9+BpkEOorlEon2tra1AcDjy1kMNF1AoFqSBWPBZDiWICC7qefHoo6rO5uAOnHWDEdGO0FBTwW3F6TDije+HAD1Hd8uAHFh2QKECmBq4sV3OMtineiWLejhc598GMaO6CW/vdTI8VfkBou+sdMta4f/urLNLBnEv1iAkGuI4hk5USxczPRq78imvwtol2TG5kZE3ztgNqIDXS6igrNpmKpW4iDAMLN5j9PdOGbRAMnutvMMeJr4xxD8cZeIBnFUAeHc40+hKhuePEUadIBHNv4v+Hjb8a9hqob7ja+33MIUXlV6m6TLi2PKJ8U2k8etH/92RNGkF8q/d0MqN84PpM9n+WjdX/uc/YRip8/QXTgpck7anoOpkwjrxTvZIAxVTxOCx8I0xIIsgpL8ZYe72Sxvdm4CG9ujBTVBKlhW1M7dcMd2CQKj6BAkY1wtU8eIvriSaJ/fcvokQ4avAmt6Zfe19akuWGCVLxXTTfGtn7+uLfifcBFRKWVBvln5S8VsGW+uq/3Y4KYO13omPMM0UxM0gkRfeMhor3OMFwR/72caNuyiM0cSLXHW581nS9EEfu6z/9t3D74R8bnOU8lV3xYa6rm+ki9VM9nlnU/T9YTUMcbER34feP1r/uUaHMSeVXL3yX66xSiD2M7banYiTfs0ehL1oGvYVl2U7sB9DtDTeWP1aslNl+QZcg4sZSBnBGgrcO8IUgZXWDdOBQ7CmwOsEAQtVHN4DEOYsmK3b/OjGyggwDUX752WMQ7Ta+Ne3SB7SuNvx0EmATP/2908BPbcsccRjR8v+Ds5i1GsCpV984td0Q+AQrs8yaZPOwKw81x7E2GmLD+M6OvWSfeqfbMszqbT0IFCm4IBew/gejL1xnvURSwlsV2l9qA99mbNxN9ZtqrRx4UnbyfrIuArfv5sp4b5hCtmWG8Nw+5nGjXoyOqdyJY+DLRo6cZrRC4ncnrQb4Rb9iop02bZrsP4V643wuYDw1irn8IBDlDvGHPyrcemxxAl7npa+/qpm6TMApSQ7e5pm2dUswQFCgy3beLDR2rtgMmGhu9x043wqiCAMgIW3DTrXijZ5cBMqET8WSB/we+9m1dTLR5YeR7IG94bTX9ifqMiRAOLmQEQfZrYijeqZKafMaGL4jeuZWo02PcLIoiT51L1N5o/L8c+SvjfoRcHf1/xu1tSx2Kd4rrGYTijWvcMxcTPXp6+v9f8bc+NtXZ/c4zCg97nGZ87ebu8FIYXv4l0du/M74+6hqiCccHVxzSw+qSLaR9eDfRnQcR1a+ljNn2J36VqOcgor2+GSlwsBoTD7D6P/5tI6huwolEZz0ZaYMoBuK9c+dOlT7NSdWcWr1q1SpLrT777LOtx19yySW0bNky+sUvfkELFiygO++8k5588kn6yU9+krXXIBAEM05MFO9k1Fkm34Lg1rStUxRvQYEi01Zz9L6CnKDAet6rREP2NgjsP04JZqPKo8SQcMzqbbqKCk6iHYTdnAkwY/4LkdtcsBgx1ejpToR443q6+mPv7zez1byP92Msa3SRKd7oe33kZKL/3ehNEBe+ZBRGsH6n3W+frb7vOUTD94983cecEJNyEFhb6sR70zzjNS153bidTqz5mGjTXGNG/GRY8Mm04pvujnivAYWB/3yfaMbfja+P/wPRET+35xukat+3XAThiCCUCHCuefu3xloueJHSiradBmnmQgYw4QSiip7G5IPVH8b/HcgfePYiI5QNOQTffMTIH8gwskq8Z86caaVT66nVPJpq/fr1FgkHMErsxRdfVCo3ZlEjUfu+++6TUWKC/CTelUK8gyDeYjdPHQgv5CWV9RQULDI9IgphYEweQYy/87QRjoT0Z4yzShV83cB1JN1hYHqPd1ABayopXcOC/0YHq40wSdyIA4wCAwh/w/rYvxcp2/cfHVn/ZHq8izFcDarhc5dG3A0r3nN/HN+/17eI6obZv4eE+K/+kShUGknhDkKdZVs00FaffDAXY/MCCgyfPU70yq8iAWh6LzJUbi7wYBRe312M1xKPqL54BdFn/zLW8ZR7iKZeFP2YVF0Eun0/GdclMiv4vbR5PgWGNTONNgYcZ6zEozceRUycP8ccbtxXXk006WR/dvPZ/yJ66WfG7QMuJjr5TnvBqFiINxKuseFzfmC2MoDPzqRt/AxGSCGpfOnSpb5SthNFt1/LgkCQzLEk48SCJd6i0Aa8nnL+ExQo2FKYqZ4+7kceeaDxuba/EUIFrP3Ev71z/edEj30zOkRIJ97p7l+3Us1NxW378gB+51aNAIeMoCQkjmNddMUbQB4K0s2BVTH6vLctJ1r6P+P2pvlxerx9KN7FFK724Z2RtYvVT7/ifePzqIPdvz94T6JT7iY65MdEw/aLLmQkY2tmW3Qqive8/0Ruex0byQB28A/vIPrbfkbRB4QUwXO6OgtArWbVG2Q9lrrP3//GgxHF3AkmjskUh9R4thTX1LaeARYy3rmVaNbDRA+dSPTAcUQLX4kUMqaca1f92W4+91m7K8IJzPzmULbjf+c+QjBDyKtxYulGRUWFmu28bt06GjBggPo6lOrYCkFRAgWk9vZ22rx5szqmcCxFW821Hm9RvJPqRwaEKAbXMw9IIUNQsEjVmpkI8J5ixVUPROo3zviMJG8kkscif4xpvyZa8oahHh5vhlZ5Eu90Kd4mSR4wwVALEbCWKpgAI6kZyh7sogteIprwFaKdG4zXpI9ewjpu+NxYV+6XdUInNPoItGR7vLOteGNOcf/xBplNJ2Adf8Psz0ZIGm7DmQEbb++R9uOA1U0v4m0RIpMUAXx8cnEoUbXRSRITHSsHor1lYfCKNyzQPFkAI9RAAPEBDNrTULmd6/LWzUTL3zacG72GRP9OBDCiB7l2ANFuJ6WnHcJJUhMl3lDZdYcKjokgRv0BDea4P3a+/MssPGCywd5nkQ2jDyPqNYyoYS3RoleJJp3kXrRZO9O4vf8FwTzHFCDEWwMIEuzssLiDfAsEqaKmpoZGjhypji33cWJMvM1wCyn0JKzQSgp36tCNGa1iNRcUKjIZrgZLNMhjaYV9842eQgShQe1tWBefeKO3eumb7vZu3vBX9U5/CjeTWCiYinivCM5qDsUbyeWKeL8QIcSD9zLspIxRBxk9ryune5/IOP1ZLxbowHW2OU8Ub5DFp84zAsp+/Fn6/g72JE+dbxw7CK466DLDlg2yAtVbJ97cY4+wQDg4/MJGvDtTI974eYStVdQkrs4irA/HclCK986Nkf0cchze+yPR3GcMEn7AhdF7ur5jDBcHCCWKKgdfFv07V2qOglh7wlSKbbp1PxnxZ+V7xjkM7yH8LIpZOzcZoWdB5AwA337aKFBA7YZgtefp0cUy7K1x//t/NuzmbsQb7iIENfYYFGl9yCKEeDsAZRJEqbOzk7q6ZEMvSB6lpaVUVlYW7ZpAhdRpNUfYAy5+6PsWJKjQClFMFaJ4C4oCmQxXY4ICxdYZ4NNraIR4D9o9PmHA9QFwqswZVbzNHu9h+xLNfjRYxRubaRC+164xbMzYIOs2cwY7BxBah2A55zgwWNCh0LolsTNwneXihK8e7ywS7x3m+FsUOXC794jUfydeP8LT0I9c2dP4AKnFfPSeQ4hO+qtB9kYfYhLv94kmf8udFCYCG/HGmlYln2rOCm0ixJv7uw/5EdHr1xlr2t6c2O9wA97DQM/BRIP3IDr9fqIvXU20ZQnRuGPcfwZ2cxDvL/7tQbxNi/+oQ2L/7VSS93XrfjKKN68nFPkV7xpz21GQS5V4d7ZHzjVD9yYad7Qxrg5ztzGyzg3IGgDxhuKNcyLvq6PWM04hI0MQ4u0CEKXy8nL1IRAEDl3xLq8xLHbYWKHPW4i3L+gjxIQopg7p8RYUBSz7cFfmiDf3d+uANRIjm2CPjAfuFWXFW3dGWYp3mnu88TtZJeZ52rCDQg1mgpqq4g0lED3cINVfPGUPVmOA3GC0GPrL0QM+/lj792f/M+IAwNq4Wc2Z7MO2qqvpQQdXBQG9cAB7fRDEG6FeSNzW10IhRHTK3yOKIkgfyAz3c0cR7zik0An9OElKoXUSxQb/JA9j6mCFhoth3+8Rvfcn47VvWWSQuyDUWRQtGFBVYymrIKsv/tSYU4/pBnpAHY43zjeIV9wIUvFOhHjjOfIEAoSbwZXDxHvsERSIg6CkPFIYg6rupmQzBk0y2jHw/7lkGtEep9q/z5kQiR6zaUJezfEWCPIesMJhBioTb2ygrGRzCVjzC0k1DxaynoKiQLrt2DrYDj3SZfMMxVtXy7yA7zPRAWC31JPAM6V4q55o8xwxcJIxIglWWvQApwJ+LTWm5Ruqt0LYXfHWyYhzrBicZKzC7X++8dlt1rj1N/v6tPF25Abx9jMuyQ9gbwYOuIjo/NeJvvOMMVbpwml20qTWPmTM42ZyieMNBaNUFe+ugIh3ojbzXY4yXBIDdzO+1ufGJ4vG9dHEOx56DIiMXFv0iv17G78wRxDWGe+1WAi0xzuB9QSRRVELhBgJ4wMnGvcHYd9v1AoZiQSgjf+K8Xnhy/b7cayt+ig6ayOLEOItEGQSCNRhwGoOWH3eErDmF6LQBgtJiRcUBTJlNQfh27o4MgbLk3jHUbwVkQwTjTgwsrHfsSJ6jjfIRDpfGxNYbLShXPY2ZzOnaje3rOb9jM+7MfHGxnsoUd3w6J/hzTPSt3UCBwUORW0o4hNOdB9Xpv6mjxneukKbzR5vp+Kd8u/bZiiCwH7nG8cm7LtQLZ0hYDimYJ3WrbogMCi4YI35GPYLFDl4xFgyRDEVazQXZHj0FPrTgxqBZRHFwYn93ITj3YmiPgmBpzCkI7PCzbqf6HpOPNF4n1jruSDAQsbgxH4OM72Bxa/ZzwsbPjPOC1U+ChkZghBvgSAbNnPMI2WbGyeby0ixpHqSJVwt2JR4CVcTFCyswKw0E28mSQN2c0/OhtXcj+KN2bUAErzdyK6leGvEOx1EkXsuEUwF9OHn4hKwtnGu0aeZqNUcgNWcg7zcChYAVFm8Vth0n/yu0acLcKgaUo9rTSIPVc45usoaJRajvzvTCfh+iDfWNdXiPFKoQXqxzqxSxgJbc5kMsvsC/d/JIJXZ6FFhYD73S1sWE22aaxwzTM5Y8Q5iBFYyijfAzwWjxzj3x9mPnM7WmSgHgU/ijb9l2cxPMT4P0BTvZEbFBVHIwPkC72m0mOjuEKuQcXBWR4jpyI1nIRAUC6xRYqbNHLCs5qJ4+4Uo3sFCFG9Bcc3xTjfxnh5J4XYDq4Xo74w1jxppvCjS7v71CNnVk811q3k6+9e5V5pTrJGy7Ua8P3+S6K6Did68KfFwNQDXRPTgArt9zf1nQMxPf9Do0V74EtEjJxnzv0FgAASBcYEA5IKL3VGjxOIp3hlMwPeCLRwOs83N3uxkwb3zzh5YLzD5cxLvZHtlUykOJTv+ap6pzo45InKcYSReYIp3kgotngOcAxgbtuzNSCui32C1VNshnMTb7/4T57amTcY5BzZzAP3VOE+B9HKPdrJoXJdcIQPndje7eSKFjAxBiLdAkCEs27yTOlsa7TZzQIh3inO8hSimCilkCIoCqShuSQWreRFvH4o3RhIB2Nz2GBhH8a7LjNXcSbyd481AvAFWxBJVvIFDryC6/AtjRJAXELT0vecNpR9BYfcfG1krEHNcX9GHrv6Go8+72afVPCcU7212V1wqfd6NG430aWB3v8TbJH9QjOvXGAWOVEhMKgGAyVqj55r93SheMeBE4fcSOyYyrXijyMSqNxNFzBlHMQqhu0Mmx/8dqRyjyVr3LZv5V4nKKozbmNqAIkIQdvPGJBVv3b6PAEHsERMtZGQIQrwFggzgrYWb6Eu3vU2PvjvPm3iL1dw3ujRuKEQx6EKGrKegQJGJwCworOs/80401zfpCFHyssxymjls5gBbsPVxWa5zvDvTp7yykmwVAVbYXzerzkg4jqXmq+fZranPGvGGHVSfG+0FrO35rxHVjTRm9AKTz4qQGn6uzpFiVo93HKu5Pk4sVftssuDnPu7Y1Pu81Vi6bqOXGwnyfoBCS39THf7gr8ax1Wt45P8/UQSp0PrZL+E4RFgZesu575/DzVSuQNggu8kCxwUTxV4JEm9gwlciAWsoRrCjAMFrTGrT5cpIJtUcr1dPM9cRlH2/0SxkJJohAOzyJaLSCmPqARLO4WjAObK8lmjIXpQrEOItEGQAq7YZVdVt27dFE2+uZovindw4MelJThmdtvUUB4GgQJHOkVuMNTM1guJBIDE2kguubqo3Nq8YqwVFiy3X8azm6SwqeCneuvq+7G3DNstgddULbfWR+eTxSHAsu+4FrxMNP8AITtJHDjGZb3IS720+FW997nRXdon3xBMix1ay1ndOM+dCjl+wuv3JQ6nPQk7FcRKlePsg3kvfjBRpuO/fqXqnQhRB6rgg0CMJhRaOGLx38f8M50ai6mxKDoIkChno4d65gaismmjskfbvBRVY15iC4o3zKtvf0YbC64n+71TGHgYMId4CQQbQ2WUQm5A+w5thpZqL4p0UURSrecBz0aWQIShQZCLVnFVJL7WbAWLulWzOJGnXoyMEkVVGKN5Qi6E+2Yg39693ZS5cDSSWn8PiV+3213jEm23UUKNgVU0W2KBD+b70A3tBm4sETqu5m8oed+50Fvq8lSNgW4Sg4TiASrn+88R/147Vpk09RLS7GYjlF0wCmWCm0iurzUafs7aejrr1LXpljkm0/PZ4Ww5BHwrt8rcj/d1ODAyAKDJJxP9NMscwjjF2M8AenWg/sjZOrKmtk078y7t022s+FXz+/0xmPXFuK6tMr+LdMwkHgTMtPtVMgjRBiLdAkEErb2mnG/GWHu/UUs2FKKYKSYkXFAXSmfzNQCBarFRuP7O8l7we3ZeKvnBYZmGrhuqEjTKsw9Y4sTT2JLPyymS2smdkBBhUb5w/FpnEe/8LjM/L4xBvvwTY96gqhwrrZTW3+sp99nhnK2ANair//+K1YKRcsn3ec5+NELpELbzOgMDRh1IQha93Fm+m5Vua6LW5fom3qXjXDvQnVKBwwa0PTnXWlsSdAlHk926yJFEnirMfM0gnjrvh+yW8nvPWN9DcdQ303Ow4LR5O4s3r6Yd4w9XiuZ5aYF2yrRntzZF9cDKKNzDeXM/VMyKOhxwKVgOEeAsEGQyvKuts9raaS493kgqtEMVUIeFqgqJAJhRvWMSBwXsmR7xBGJgMoNdT7+fkudYgu7xBRU8jgsQyGa7mDFjb8LlBGhAKdfjPjQIB7tf70Z3wS4CTBRcG+Lkn2uNts5p3ZjdYDf2+I6fag/syYTMHcMyx26J2AFG/XSlpaH3zXaYLsEO79viyRiNo0A9RxDGJ/2uIHMP2jf4+K7SphIFZtugUiDdcLTjWuECEHnweNZtAjze7Kvmzb+t+D5+FDIxgXPFeZKSfE/3Gmcnm9ZF1SVbtLq+N7IsTRd0wM5gOjqAdxvnROaM+yxDiLRBk0Bpd6ka8RfFOGEIUgwX2+gxZT0HBwrIPh9M0dmtbxDo+aPfYj7WSzR0K1Y4VhroHMs3klqH3ees2c6i9aQ1X22JXkZ0Ba4teM26PPcropWWiwxt1P6PEgoY+y9vt78ZVvE3rfrYUbyvQrq89IX/VR/4VRZDV2f80Zp6jGOIMxPILVrlT6e92OE7YZdXh93pjKbQD/AkVbIuGzditv5d7vPFeco6cy5Qtmt+/uhU6EXVWe8+zq7JDT55NZD0R9KhvBJxYN8t4DIIcB7sElcFq33dsavb9Rq2/O5XjjFVvYNh+qbWypAFCvAWCDIAV2oouJt7S4x1YCrdYzQO1mouDQFCw0MlUOgjqxrnGZ4SqcUE1UcUbAUZA/3H256t+rzZSTCfeAD8WylSQwGbcaTV3BqwhlRkYb/arjj4svt3cIpaO0KugYFnNTaIdK0ndDaqYoSWbZxrO9Rmyt6HeYYYy0rpjAWO/Xvwp0W3jiZ671LgPM471/79EcNBlRp/0IZdTStDCwHhP1BmL7OnoTFDxtmzRLuosF2aYdG5emPkgMB08VizRfmStvYTFiA6/irdzPYH2nfHXc8xh0eelqIC1hdkrZOj2/Ry0mQNCvAWCDBKbiu7mSPoiQ6zmKSreQhRTRZe2+ZFChqBgofftpoV4mzbzQXFs5n6IN1K6nbAp3toosXTOKAdRtXqN+0UTb6Qxc187B0Vhc84Ba17qrNsM73RbzXGNtfrifVjceU2zqnibrwOq3dB9448V+/g+onuOND6jOIMQv8N/QXTKXck/l0GTjLnpbpbtRKAl73cmShQ7EuhJ7myPWPLdgtWiiOKCFIni4ACIYsgorMTLhvByEHAhw6/izeuJwh3+brw9aKyguqiAtQAU71QAq3ndCPu5KIegNbEIBIJ0gU+KFd0tRCgWitU8sFRzCVcLei66FDIEBQq9bzcdZGoD93fvEf+xXlZz3rQyKdDRe3QMxTtNVnO2aoPg65ZdLgLAxsybXS4mjJhqFDnqVxtFAqdlPiNWc5dUc1a70UPqTGWOqShm4ZxorY9W7ECfN8LV8LHPt91/jkPuEIB1yI8NouSlUGYaWnGIxQj/ijf3JA+I7xBEMaij2VC03QpYDLzHUBxKmigGpNDivfStfxrHJDsgE+nx1hVvvz3zvJ5oaUFYIgo9XsUMhJ6t/ijSTpLrhYxQiOiMR41CaKxCQZYgincqwHzI1R8TbZyX7WciyHHwSbGGWr1TzWHzCdomWKCQcLU0OgikkCEoVKR7NvPGL4zPg/wQb5OkQrnWe0x50xpX8c4Q8XYLVlPPxUGmxx0XuY3CMgcaednN0654u6Sa++3vjiI2OaB42/q8YyjeG8xj8MhfEe3ypdwh3Q6Ftjtha3SbQ/GGeyEcR509nKgkBs2xRoqZ7zkUAd7/M9GdB8XOJ3AqtL1SJN48q33XLyf2MyUuhQzfPd7meiLIDcQb8CLeKPRgmgKKhf128f6delI8/9+gEHT3oUQf3uWfePdKMHnfDUP3JtrnO6n1iqcJQrxTwdxniO4/muitW7L9TAQ5Dj4p1lKbd6o5IHbzJHqShSgG2jMv6ykoVGATjuTddBBUFE05jdyP4g1lq8Lc8Dasj/yOLYvspMCtxxsqORNijBIDrDneMV5XMiq/c4Y3AxZmBHYx0EOsQ7ebuyHdijcTVhQo+HVb/d19EiM26bKag7jNfNBQFOOFq7GTAMAxoveuM3ZuNslLKH64Xzag9XhHrObdyaVwIyDRKxRt2VvG53hqJwes4X2L99M/v0n0+nVEm+YRvXxl7BA7kPQgUs1TgVZs4+I5PumF9LjrCZWd96BeLgJ9PWMRWeRS4JzQVm9MNHjtGmNNUQx64/+M4zMTVvMchxDvVMC9VdxrJRB4gEdn1IZaook3RoWUmeMjhHgnoXgLUUwV+oW6vavbtr4CQUFB6zMNFFsXE3W1GW4mtoT77vNeY3xGaBaUJYzlqhsZ/XiQDlhD0afMQW5+Fe+3f090ywii9Z8n9rqaPRRvfbwZLL1D93FPwoZy6EZgmtNMvKFqc5GFSWzz9gQV7zSGq7XsIHroRKL/Xm7McPZcH03xxlrxOC/uq9ex4TPjM1RJPUcmB997VrhaomFg6v+11Hu/BNWW18YrWM3Zk1y/ylBll7xuvL+wH4N7Zen/Yr8vwnDNhCIqfKahjRPTr+G+ihm8nnit8XKG4gXVMUDiOdn8weOJPvhrhCvh7824JzPW/RyHEO9UIL25gqQVb8dFUZLNE4KkcKdvPZl8CwQFiXRZsrm/G0pjLHtrrIA1HsMDy6bb74DahMR09fc+dxDvOOFqK983+jr9WGidLXWAWyI2281hM3c+X6izCG2COu+Wwp1uqzmeD/9udgf4neFt/Y6yNCXFdxE9fQHR1iXG11sW+09959nu6GP2spm7jXvK0R7vhBVvWKN5v+RmjV75gfEegDvELVtABwoZTJpB+vqPJ7rwf0RTzjHu++Av8UkiimFMgDMNPSVeu4brGThxw9UQ2mdZzRvc36frzYKOn35pdurgfY9zE3qtv/Zn476P7/V2KeD5i+ItiAu2eAnxFsRBd6web0CKOMmHgUlPcmCODIasqaBgYdmHO7PX3+0VsGYlmptKnBt0u3kiije/3npTXU9lhjdj91MMBXK/86K/B4LEJNHNbp5uq7n63f3sJDbRHu90uSOm3WCoqwyE0Pkl3tw7v2Zm9M+wm2Gwj1T9bMAthdsPScSxq9RlLQzMi3j7VWcZIw80Pk8+k+jCN43C2UHfN1R1WKzXmeGBTnB7SDZJojbuTncOdCaqeMcqZKhCXdgoSvjpZeccAhynF79LtNvXjI8+Y4zC16ePuv8c9r4IxANE8RZ4wrzghYUsCfwq3qHWaKs5ICPFkh5/1SqKd+CKt6ypoGDhpxc63YnmXoq3H+LNAWvOljfrdXm8d2FhV39rTXI93m6K937nEv1yBdFwkww6odvNdaCn2bIOp5F4O5PN/c7wTuc4sS+eInr/TxGyB+xIgHhzMWPtTKPP2E3xHpKjirdLT7I/kmiq3RbxZodgvXewGlLd/eDrdxFd8h7RKXdH7PlwlexxqnGb7dKetugAgsCCKGRo13BfgXUW8a6MXchIdD2nXkJ00VtE570aOVfh3HTwZcbt6X9zL3qy2o3zGYp2BQwh3ingqbkGSQq31McOYchDfLZ6B/3kidm0od58cwpSAl9kasmDeIvinRBE8Q4Wzp5uWVNBwSJd864TmeHtaTVfYA99iqV4M5yKtxdJZNU2UcW7KYbiHQ+jDjE+8ygiBivPeM686U/rLG/u8U5W8Q7oWFn3KdF/fmDcPvQnRAf/yF3xBjFBD7gb8YYiC/KJvcK2pZH723ZGrOv5YDXvToAksi3aSbydRBHhXfw+9DtGCmTbzSHA/zdznzXG9zmRC7ZobZyYfg33Zd/Xrfv8HnRrdWQHgd/1BMlG3oM+ehDY+9vGsbxjFdG854q2vxsQ4p0CSsxkzBLq9o7hz1M8Mn0lPfvpWvrv5+aGQJAy8cZxUhMye7ydmw3p8U4IksKdXsVb+uYFBYt02Iex4d+50QhaiqVWx7Kad7ZHiJNbonk8xTteQcGymjvmhscDK69uinc8MKHBZhvE0C04LJ3jfizFe2tyPd5BKt4g0k+cbSiN444l+tK1RL1HRAJ69T2kCuzFOTkU+f/Vn9OQvaP7vJHEjZ/pMVhL/s5lq3l34kFgpZVG776XQsstDWj3SOZ41QHXAGZWw+L+4Z25SRS1wpBu2fcVWMfjxGIVMmCnR2gkQgrZvZIsQPAPuDjSO+8UK3OhkJEhCPFOAVVVNdQWLitIpZI33o2tMlc6CODaUs3BaoAo3sHNnRaSmDKc40ekmCEoWMSzZCcDVtn6jkksTVpXvEG6QZqxCWZC7kfxtsaJxevxNq3mKBCA5Kc6x9sP9PAqHpOmE+F02sxtPd5sNU9U8Q7IHQGSgfRypGfj/+/Ue43jEASSibVuN7fWp7d7cNfw/aL7vDkAK1dt5k6ruXnJ8dXjbdmiq4zPXmFgW00HwJDJwTzfQ35sfJ71SPT4tlwgitrxqYsRHc4WhFj2fVvPvHM9zUIgQur4PJMKDrjQmNiAY5Ut7LlUyMgQhHingJrKMmqg2oIkTLwRb+kQUhMEUN3lYLVuvO34AsKQHu+U5niHC6zVI/vEW973ggJFOmYzWzbzBPq7deINogUbMieax1KB+3hZzeMUFCyFH+nBPp1s2MBbvcZJKogDJhifNy/MbLCa/py5eJDoCLOgxokhUAqWZRDP0x+wk5i6EdF283iFCSbe6POOSjTP0WA1B/Fma3Ritmhz3+QVBsb5BTzmLlWgrxnridCvj++zf4/fQ7mgeDvGiflSvG2p5h77Tw5wDGo98b7b5zvG7ffNpPMo4i2KtyAGakG8wzUFSby5CtnUJop3EMB5kIPVOktrojdWltW8sI6jdEHvZwLnlvFXwRLvVunxFhQq0jFOzApWS5D0QHlFqjDAM4PjWdXxM5Um2QZ40xzPQq8HGvnt84blmdOknb3GfoFCgt6/nkyvdeBW8wR7vFNJwMeosJd/Ydw+6lcR0sxguzns+PGC1RjD9oscdwiqU7c50TyHFW+tHaLTVGX92aI9FG9nax63UcRyjCQC7NO413vWP+z2aFa8/SR9Z6DHO6E53ngdluIdI9WczxO9AiLewEHIOAgZ5zvd5cHEm4uRBQwh3imgury0YBVvJjYt7aJ8BbWeHKzWXuqS2Mh2swI7jtIFpz1NrNGpQbepAaJ4CwoW6SDeySre2NjzRtMv8Qb6mLO8Ydssq0jMap5InzcrxVDV+e8EongnmC6eLPj3g8jCCcDX1+oMKd7oo33qPEMxHX0Y0SGXRz/GUrzX+CfeUCDRy42iCGy7KAxsnJc/irdSaCnxHm9Ou/ayRget0AITv2qMf0WbAFv74ZbhtP+sKt7lyRFvnCPC3S5zvD2Id5Dr2Wd0JHQRLpBcsu5nCEK8A1O8zQTKAiM2zUK8AwGqu0y820rMY0aHWM0TgqRwBwvndVrWU1Cw0FSiQIB+aSaViYwSYzDxZvs1K8SxwH3eevCW3o/s1nqjk0e3udGJzvAOQvFOVkVPxmquSLe5Ln77VVNtS8C8bijRIPqn3hNpB3BTvN2s5l7rg4KN1ef9sdE/39VGVNHTmJecD1Zz8xjFXjNuq1iHNvoKYMdHJohiRQ3RhBOM23OeNj6rIEXz+Eh3ToHvnnnNah6vb56t+84e71avQkZADgLGHqfa19NGvKXHWxADNRVQvA0SFebRDwUCrp41tYvVPChiU2NazdtK3BRvCVdLBJLCne71FOItKFAErXhvWWiQWpzDWb1MBE5b7MBJ/lQj/boB6KSO1Swdul2aN9TpDFZzEu/tKyIb/kyFq+lWc/6bKHI7Rx2lo0iD1zv9DuP21+/0ttDyMWMLV/PRi673eVs28z2M1O+8sJonQBR1W7SX4g3SyF8HZTVn7HFaRKGFc0JXZ7O53lrqfldXAoo3OwjipZpb1v0ACxnApJOJQqVE62cbgXhoOxDFW+CXeNeHDat5Z3NhEW/uvxGreTBAdbfWTDVvDTmC1QAZJ5YQJIU7zQ4CKWQIChVBJVU7+7thM09mNJauJqH32M8oqN4jXYi3ln7t9tpsVnOfPd5sp01F8Qb5VQQ7bPQ7ZzRczVSMYckGEU60rzzebPR4gWp4zQjomnC89+OSUbz1Pm/Yn61gtRzu73asp37NidvnzaOvYoWrcTEJ74lEJgv4wS5fMn7vzg1EKz8wphDkAkm0AhUdinfc9dR65nHOYuLd0WQPZ7TC6gIuZNT2N94XwJxnzFYQvMdCRD0GUaFDiHcKqKmIpJp3FRjx5mkEYjUPBqjo1oaMqm1LyEXxFqt5aj3JYo1OCdIzLygapEKmguzvZuhKKNRuP+QdRAAEcvyx7sTb7bXZrOZrE5zhnYIlHK/HaTe3wtXSTLxhTYb9GmDSnxDxTrLHG+6CTx8zbu/7vdiPZcUbih+PefNDvIfuY8xXBuFc/Fru93fH6kmON/6KnRJR48Qao4/pZFwn8YB8g91Oitijc8UW7bGeLJz5t+6b66nvQbG27MAM2kGguwjUeprBarUD/LtR8hhCvFNAaUmImkNMvM2wkAIBv3GbxWoeeLhaM7kp3mI1TymFWxTaQBXvVhkjKChUBDnHGyPAFr2afH+3c1Prp78b6D+O6BfLiQ77aeQ+fcPqVLxRqNTv8614s9V8AKUEK2BtQWYVb71osHVx4n+zNMkizdJpxrgpFBYmnhjn+Q0wCWU4otr6Id5QdbktgWek5/IMb6dCqxPveIVeP6nm7BhIB0nUieK8/xhBazlBvN3HibV3JmjdR2GB15aLGVzIQD89OwyCxMQTiUoriDbPjwRLZttBkCEI8U4RbWXGCSDcUliEid/EongHt541ptW8KRzDag47IFcjBf6t5qJ4B9vjLespKFSkmlSN98ryd4ge+TrRPUcahA4b4JEHBaB4+0g0ZziVcfRMMpxFBSdxbKv319YURLia/ro4hI6FinSHq+l/IyXFO8F90KxHjM+Tz4yoirH+HzkMjMmjH+INDJtif64DEjh+stzjnVQYmJVqHsNqHrQtmoFUehRJUDT64uncIIqe6+lT8WbrvpuLIF02cwYCDnc9xrj90d9zo5CRIQjxThFtZcYJIFygqebS4x0cUeQ53q7EW9nhzI2UqN5J9HjLcZoKpGdeUDRIJVwNm9vHvkH08NeIlr1pkN09v0l08buGCp0MdIUuEeLtBEKeYD12e216kaG00n/AGvd4pxKu5lS8UQQA8QcykQjNRQOLePdNb5GmcSPRwpeN2/t+19/POAPW/Ka+6zPB4ZZIduRbFhRanWzHDwNrcyjeJvFub4z0RQY9w9vN/TDp68ZtuBlygSjqDoKuZHq8tbZHp4vAmuGdpvXU082t9RTFW+ADHeXGwRoqsN5cPdU87qgHQVygGlljWs0bw5XumybMZAUw81MQE87rihDF1CDhagK/uOOOO2j06NFUVVVFU6dOpRkzZsR8/J/+9CeaMGECVVdX04gRI+gnP/kJtba25ifxhiK55HWD4O5/IdGPZhGddi/RIB9J5F4AuUKgEDbBg3anYF5bh3ewGiei++nzbvKpvMYDW+i3LYv0x6LQ7HesVyrgogGCsZJVvBOxmn/2LyPMbfj+/gspesAa+rx5PxnPFo+/wch1m7lznFhC4WoePd5Mvm0KbRp6vBl7nm7/OttEUe/xDieRaq67MZwuAqtnPuBEcx0IHeR9by4UMjIEId4porPCOFhLC5R445OQmmDWs4epeDd2eVSl2Ualz1gU+CSKcoymAhknJvCDJ554gq644gq6/vrradasWTR58mQ67rjjaNOmTa6P/+c//0lXXnmlevz8+fPp/vvvV7/jV7/6FWVfdUuCeG+aHyGSJ94aIbGpAFbj814luvB/iZHCRIoK+mu1iPdq/1bzVHu8UVhAjgnGnK0xCzX42m2uddBwktdkerz9FmlwHmWb+b5n+/87uuLN/e8o7uhz2t3Qf3wkPC7Xg9Wcc6e7U7BG4zP6g21EMc3WaGD4AfbRWl4j4rIwTsxWyEjUuu82oi3d1n2gotae+N9LiLfAB7rNKlFZe2HZg/WTotjNg+rxNi4e9d0uVnNAiHfy4WoSBpYSZD0FfnD77bfThRdeSOeeey5NmjSJ7r77bqqpqaEHHnjA9fEffPABHXLIIXTWWWcplfzYY4+lM888M65KnrOKNxPvVCzhbug7JjXVPF5PMivgeO2sYMWzmoMMWanmKVrN9WTzldMzF6ym/o7juadT8caoqW1LiSp6EO1u2mgTId4ohugzzuPNiEbhYveTDSV416Mp56H3JCcUBhbHGo2CB4/4Sqc1Gv8fe5ySQ4o3n8u6UrPu6wG/bU6reRoVbz20DhDFW+AH3Uj8A2fq3BlMSmqOQH8Tw24uCKDHm4l3PMWbbVUCT4hCGyykx1sQD+3t7fTJJ5/Q0UdHNvglJSXq6+nTTTLlwMEHH6x+hon2smXL6KWXXqITTjjB8++0tbVRQ0OD7SNdm/+EwancuRpipfV8ulrNoRKyghUv2Rx92Px7gghB4z7vVdMzF6zmVjRIZ483q93oXU1klrRuNfcbrMb46p+Jfr40+YyBTEIrZCQUBtYZJwwMa6YeE0q/Cr3H6ZHjiO3Z2YLWWqKPWO3wa913VbydDoI0E+9dj46Q/iAcRHkAbfCjIBmEqs0DhitFqVrFcgSieAcLnBRrTKv5jk6xmgd1fFaVl1BrRze1QaFdMs0IA5r8rWw/vbwDb4Ii69lNtGmB0c96wEXxk3kFBY8tW7ZQV1cXDRo0yHY/vl6wwCSkDkDpxs8deuihKiuks7OTLrnkkphW81tuuYV+/etfU/rJaRKp5pvmGZ8H+hz7lWnEs5qD+Fjqahzi3d4UCWML4v3PivfGuZkLVktZ8S71r3i37CCa95y/2d1O6P8nHGjnl3jDDl+aAMnPkcKQbo2OSxSdc7ydPcl8LPcYmP5r1dC9iU5/0Gi/cE4WyJFxYp1dCc7xdhJv5SDIgNWcn8NZ/ybaviJSnCtwiOKdIiorq6mZw7IKKI1afxM3CfEOxEHQw1S8d3RVRPUoK0i4WsLHZ02FceFRxPvf5xA9e7G/0CCBDd3O9US42mtXE712DdGC/2b52QnyFW+99RbdfPPNdOedd6qe8GeeeYZefPFFuvHGGz1/5qqrrqL6+nrrY/VqH73ISdozEwJUuc3mvGSen5xr0DbiNnCRASSNrbjxiLdbH2gqsDbV4QxbzR0ENpG/q4VXxcW6WYbqCtVOH/PlB1Bp0dMNZwKPXMvU+mQSmtukMxGi6JzjbSPe9ZlJ4NYBR8OYwyhn17M7wTne+nrCuo9UfV7zTKzpyKlEk8+gYoEo3imipqKUGqjGmNFcQMRbf+M2i9U8EGLDPd4YJ9ba2WWRHAuiePsG26qqy40KelnL5khv0o6V6a/SFhh438Prqazm9eb4HVSiBUWP/v37U2lpKW3cuNF2P74ePNi91/Haa6+l7373u3TBBReor/fcc09qamqiiy66iK6++mplVXeisrJSfaQNySRVAztWGBtWbP5z1RJphYF1xbCac4/3OqOY4NVHzAVgPXU4CMWbkSnFu7Zf8oq3Fl4VF9w3C6KfqBKKv4P+VqiM62ZHfk+hwUuhjUsUW2NbozvNEMBiu+7zelKYwlqAou8eby/rPgcvQtUXt1vgEMU7RdSCeIdrIlajAkGX1nMjVvOAxonxHG+qcl9Trj6K4p2A4m0QxeomTb3hkBVBwoWM2kpjPTs6OiJWs4b12XxqghxBRUUFTZkyhaZNm2bd193drb4+6KCDXH+mubk5ilyDvANZG1OZbLgaWi8A9NJmIo07XVZz1QMbIupqi6SWu6G9OVjFG8oZJ3ADNX2yYDUPRfpJg1a8mZxz2naiYLv5+s8KmHhH1lPvSW5Pxhpd5WI1T+cosZwm3vZiW1zi7Wrd11LNLZt5mvu7ixRCvFNETWUZNVCt8UUBKd5iNQ8WmFNZC1cEE2+31GhL8c7ijNt8I96VxoWntlmzlzcKUUwUHG7DLozatk2Rzaasp8AERonde++99PDDD6vxYJdeeqlSsJFyDpx99tnKKs742te+RnfddRc9/vjjtHz5cnr99deVCo77mYDnTACZ7/7uHLWZxyTerHiXm+rq4Ph286AVb5VsrvVwZopYglAw4Ut0hFki48T0NU4GHLDG88YLkniXeljNk7FGa6nmTBQzZTXPSeLdkcB6tsZONa8v0vXMEMRqniKguNWHC5t4t4jVPHV0d1JNyCDezWEPxdsi3qJ4+1ZoTcW7R6tGvEXxThhcIGcHQd8Oc/PnZ+yQoGhwxhln0ObNm+m6666jDRs20N57702vvPKKFbi2atUqm8J9zTXXUCgUUp/Xrl1LAwYMUKT7N7/5TfZeRLKp5laieY4GqzlSjt17vMsjG2oU1EC8h+2bmR5vXru1MzNrNQfhR7I5Xm+ifdOJtCUEpXgzCpF4a+8929zppKzRbop3kRFFrchjt5qnaN1vyFCieZFCiHeKgEKEHu9CI972Hm9RvFNFRXdExfZWvDlcTXq8/R6fTBTrWjWyLcQ7hXA1Yz37dWoqt1jNBRouu+wy9eEVpqajrKyMrr/+evWRM0jVah70DO+MjBPjOd7lkQ01CHCsohpfhyoCUrwBm+KdwfCwGpN4Jzp1JpFxYnoffSqKdyETb73HWx9/Fa/H27JGexBFS6EdXsSKd6f/8WyWdd+rxzvDYXVFBrGaB9njXaCKtxDv1FHRbVw4OsMl1EblcRRvId5+iWK1aY2ua9MUWrFGJwzeBPF6DuzUArR2bkw8iEogyFUk0rfLgJq0ZWEeEO9yj3A1h+LNSlYmreZOt0CmFG+d5Cf6N71S4tNhNa8bWQTEO1LI6OpKJtXcZfxVy/bINb/YFFq4OUJGsS3Ex18ic7zdUuJh3edCRrGtZ4YgxDtFVKtUc7aaF1C4mlaNlFTz1FEZNk50zYQTXYiaY/V480lREPf4rDFTuPt16AqtKN7JFjLYuj+wW0+uDhvkWyAoBCQym5mxfblBrEBCnQQpl+Cl5ncnQ7zTYTXPkuINqzmQtOKdQLgak8tE4SQ5BTlOLJK6r+8x4/Yks0KrH4vck7x1MXzWxrGPOd7FBj5Gw92Jz/H2SjWXcLW0Qoh3iqhFuFqBKd7YhOuBs6J4p44qk3i3hIwTXaso3imBnVQofJVQN/Xt3BT5Jqrf8axWAvdChql4Dwlr6wmI3VxQKEhmjvem+RHi6DV+K6fD1Ryk0M8sb0vxDpB4o4956L5EA3cn6mHkAmQ02bwmE4q3WM0THSfWntQcb5Mobl1qfO45NHenDWRgTUNaO0SH7/V0se5D+CnWsLoMQXq8gwhXK7BUc+dMxeY2Id6pogpW8xKi1pBxoovd4y3havHAF22MvxpI26mMOo0LEDbT2HRiTE4xVr8D6pkfSpuNb5RWGmOHGsVFICgQJNK36yTeuZxoHkvN97Kax+zxToPVHEWLC/9nqHOZJEl7fdMY07XnN5K2RseFc40TRUWtYYVv2Wb8XSZCBdrmYZvjHYsoooiOa5AX8YbaXYzBag7iHVbHaIW/nnlX675pNTd+mWFh5+kHgkCRw6XbPApXK7BUc32+IuBqixYkpXi3ldR4uwhE8U5KoR0R2hxRU5hsSxJ3kj3zpaqIMYS2Gt/gxGOx7wsKBcmEq22en/uJ5raiQpc/q3njBqLOSG9o2q3m3JeaaWVy+H5E579qfE7GGq0lRqdN8dZVb6jdWKcCfu/ZrOaxiCKTRK9Uc0ax2qLNNS3p6krAau7y3saxrhfZehWpgyADEOIdRLiamWoebimMHm/nSVDGiaWO6rBx8egoNU50rW7FDK7mCvH2P8e7opSGM/HuPdK4WABijU56PYeEtlJpKExhHI9D9jYeIMRbUChIZo53PiSaJ2I1h/UabhbkN3iFUaZD8S7kID6ruJEC8eaRYoVoM9cKGeHuTls7Y8wwMJ14u1mjGcVqi7Z6vLVU87jhai4OAueaFut6ZgBCvFNEja3HuzCIt542CTSJ1TwwxbvTJN7uqeYyTiwZojhCJ97o8wLEGp2Uy6WqHIWMLep2V8/hkUKGJMULCgXWbGafxBuKMAKcCoF48yYdlu+6OH3elipWxMS7NINWcxvxLsBgtRg98zEVWibe+Fl2IACieHu+5+NbzT3cLPqaFqt1PwMQ4p0iqsv1VPPCsJo7ZwCK1Tw1hMNhqiLDhtZVZlrNY6WaC/FOaJyYpXj3GUXUa4hxWxTapAoZpSUhGltqrGdnrxGag0DWU1CkVvNtS43HYlOa6yqQpeZ3xLaa+wlYS0e4WiEXaYKwmvcda3wu1N5aDwdBzDAwa4Z3DHUWyPX3ZtrD1TTi3el3jrfW4w2I4p0RSLhaisBGta3MOFhDuFChkpdKxTMHoPfeAGI1T53UVJrEm090sRVvCVfze4yi1WOApXiPIgqZtUSxmicENrmUlYRoVKnR393WYzhVCfEWFBoSGRHlTDTP9b5br8R2JoX6qCtWVxtE8Y4//ioDqebA5DOImjYT7Xk6FTRJpLCaRtJtan8xFVq3RHP1dYVxH3+/WBVv83xWop3PnOKZr1RzJ/Hm84MgcAjxDgDh8p5EfJxj+Hxtfvfn6GmTgFjNU++ZryTjwh0yLx6uPd6ieCdhNdcUbxBv3nCK1TwhdJkXahQS1XqGiVpqh1NdzyERqzmKHblOPASCoHu8rUTzHLeZx+pJZsXWpnjHycNIV7haXireGbKaYzb1l66mgoVmFS+nTmozU7h9Wc3djkO4UIqdeHMxQ+vxjtkzb1tTRzGjSqzmmYBYzQNARWUFNYarC6bP2xnM4Dr6SpBQ/2xlyCTe5okuZqo5998I4vYk15SFVRhYJFxNrOapFDJKQiDexgzv5pphREy8caFu2Z7NpygQZMdqbiWa75a/r83Nas6b7Pad7r+rvcn4XNSKd3kSind+Ox4zcnximSy1Kg5R9LJF6wotlNvqPlSUcCHeMRVviBN8rEbZ9zXiLVbztEGIdwCoxUgxM9m8EIi3U/FuFqt5AFZz48JdUhFrjrco3okm7/dq30RloW5qC5dTZ82AyMVCrOYJga/TULyHhA0HQVP1MKMizgm7UswQFJuKaUs0z/FRYrHUfDcbNOZGxyLeonhrc9Ez1ONd6NBaHTC20hdRZCHCaYvWiTfU7mJ1Y/E4Md1q7jslPkbfvFjN0wYh3gGgprJUSzbP/4A1Z493a0d3FBl3xeoZRMveSt8Ty1Ng7ThcrbQ8ltW8JnIB95u4W6RhdXyI9mg1yOCacH9SHRGs0LY3Gm0fgoTe86XdHdQvvE3dbqgy19JKipdihqDIFG+obQhXAwZOovxJjfYaJ6Z1F1b0sCvbTsg4Mc26nyGreaFDO/7KdMW7Mxx/9JXTFq27NorZFu2SWdEe07pvrmesVHMQ8kJN1s8BCPEOABhpVEjJ5kyyEVzl226Oi84/TiV67BtEbY3pfop5q3iXVVbHt5oDYjf3hF4Eqt5pBAOtDfc3ihmVPSIXDyGKCa9pj9b1VEJhag5XUmNJb+Obln1/bRafoUAQtCrso4UKY8TC3URVvYl6DKK8DY7jr3VSaCneXsTbvAZVFDHxLk2kx1sU77jAGDszALWMIu+/ju4kUs0Bvtb3KtL+bl3x9jvHm9cTRSU+FzoVbzgHi9VBUAzE+4477qDRo0dTVVUVTZ06lWbMmBHz8X/6059owoQJVF1dTSNGjKCf/OQn1NqqWSeyAAQ8NYQLh3jzmxYzyvm919wWRx3AphwqIy4+0gsapSZyj3cpW83diLd+YRG7uS9HRlnjavV5dXggtfEIDUniTr7Y1mKQ69XhAdTGVfN4IUwCQaH27W411e7+4/JjI+o5xzuW1TwO8S5qqzkXKsLxCzVCvBNaU514+7JGuxFvFMSKOVjNNk5MX8/u5NazWtaz4FPNn3jiCbriiivo7rvvVqQbpPq4446jhQsX0sCBA6Me/89//pOuvPJKeuCBB+jggw+mRYsW0TnnnEOhUIhuv/12yhagDFs93i2F0+ON0UI15aXU1N7lrtDq2GEQoJgX8iKFrngz8Xa1mmNjhz4mqN1CvD2hF8dLG1apz2tAFJl4w26+eYEo3smkxDevdVlPtppLIUNQZFbzHSuNz31GU17As8c7ltXcpccbxU2xmttSuNWaOhXCeMnxgmjgGOxqo7JQl6pnxO3xtgpALkRx//OIOpqI9j6LqNgVb61nPuZ4tljrOeEEoj3eJtr3u8E/T0FuKN4gyxdeeCGde+65NGnSJEXAa2pqFLF2wwcffECHHHIInXXWWUolP/bYY+nMM8+Mq5KnG9VK8S68Hm8ELUH1BuITb4MAKbTLHGqvOd5lJvH2XE8JWEtI8S6tXx3p8e7scii0Yo1ONCW+ummttp6seEtSvKBIw9W2r4yMKswHeKaaJ2g1x9qEzfOpKN7+jhdRvBMqZtis5jEV7zbvcLVhU4i+8RBRnzx5f2ZqjrefHm+39aztT3T6/URjjwz+eQqyT7zb29vpk08+oaOPPjryZEpK1NfTp093/Rmo3PgZJtrLli2jl156iU444QTPv9PW1kYNDQ22j/Qo3oVjNeeZvkrxNvu84yabmwQoZkpqkQLLyYp3udnj7dkzz+oCqw2CmD3eIVORUlbzDrFGp7qmVU2adZ+PUVlPQbH2eFuKd55s7IOymkNFZBS14q0R73itCTJOLKFj1E68faSauym0Aq3H228hQ9azaK3mW7Zsoa6uLho0yB5Ygq8XLDDHdzgApRs/d+ihh6pk487OTrrkkkvoV7/6leffueWWW+jXv/41pRNQhesLsMe7pCRElWWlSSjeYjV3KrRVIeOiXF5VE4d4i+LtlySWw1pl2smjrOaAWM0TdhFU7YxYzfuI1VxQ7FbzvFO8yxO3mqPIiyKEbqO2ApjKiptI6usVb9KIlWouirefY7Tcb4+3NcdbiGKsY7RUC1eLWciINRddUBzhaongrbfeoptvvpnuvPNOmjVrFj3zzDP04osv0o033uj5M1dddRXV19dbH6tXa8psoKnmBWQ113u8LcW7y+hfd4wacyXeotZGOQhY8a4wFe/2To8RbVyFFOLtCV63oaEtFKIwtVIlbaFekb55sZonjG5zTSub1kTC1az1NAsZCE2U41JQLOFqsCrxdS1vFO84Pd5uVnO3a7bVB1rEajfnrliFGrGaB0oUfSveQrxjwnxPh/RU81g93rHmogsKW/Hu378/lZaW0saNG2334+vBgwe7/sy1115L3/3ud+mCCy5QX++5557U1NREF110EV199dXKqu5EZWWl+kgnlNXc6vHeUUA93iUW8a5d+x7RUxcQHXkV0ZG/jP4hsZp7AtcUi3grxbvRUr17mD30FnijI+PE4vYjjwxtVp83lyKIMeSSai6Kt190mjkEFS2box0ESI7FcYnNOfq8++2S3ScrEGRC8d65UYVAUag0f8YVWa/N4ahi0qiTQhAZjHbCuDS41HiUECDBavY1xbESt8ebXQVF7BBIssc7NlFsLcisAWTSVJSWqHDooK3mECfgCnb93bHmoucxOs3iTVlp7uvJWXuGFRUVNGXKFJo2bZp1X3d3t/r6oIMOcv2Z5ubmKHIN8g7gIMtquFoB9XjzSRDHLxPvHltmGyM1lr0Z/QO4yNcbSpmChKt5ppqz4u05Ukys5r4V75ElW9XnLWVGoc4KV2NrdNNmok5ThRDEVbyHm4WMttJaqqfaCPHGxVvs+4Ji6/Hm/u66YfZ063wg3k6S6EYK8b62ks0d7WEySiy+fd8J6fFOYZxYcVmjV29rpn1ueJ2ueW5OWqzmMfu8Y81Fz1N0dnXT8X9+l7761/cs914uI6ulAYwSu/fee+nhhx+m+fPn06WXXqoUbKScA2effbayijO+9rWv0V133UWPP/44LV++nF5//XWlguN+JuDZABTvQurx7urSFW+zOtm6zfjmlkXRP9C4wX5Rkh7vaOJtzvEOlVdRdXlpDOIt4Wp+ifeIkk3q89Zyk3hzuFpNP/PiHibauSF7TzTPXC4jTOLdWDXUdBBox6fMRhcUW6p5vvV322z0PqzmtoA1h0tNFO8IuOgiqebBhqthnJiJ9q7iska/t2SLat/8YKkhHgQzTsy+n/S07xegdX/F1iZavGknLdjQSNuac19syWoZ94wzzqDNmzfTddddRxs2bKC9996bXnnlFStwbdWqVTaF+5prrlHWCXxeu3YtDRgwQJHu3/zmN1l8FUa4WiGNE+vUeryrTcW7tM200DdvJWraSlTbz72/GxCreRSp4XFiuHjARQCbuWvAmijevq3mrNDuqDDUWEuhxTkDfck4LmE37z0ye082T4BrNK/nzuqh9kIGIMRbUGxW83xLNI/V490dj3iL4h1f8fZpNRfFO3GruZ/xVwVkjV680dgjb240X1sqMI83vWc+ZmBdAVr3F5vrCWzZ2Ub9e+S2OyLr/qnLLrtMfXiFqekoKyuj66+/Xn3kEoxwtdrIQQ1rTB6fJLq1Od5Q84GKtu2RB2xdbCfeen83IGqtp9UcdqkqVrzdiDdXdYV4xy0MMVGsVwotRcLV2G4O4i1J3L7f88NDW9Tt5hqjn7VVV7zFai4oFDAxQk8krnVePZaW4j2a8gZePd5e/cdexJu/LqDNeeAuAifc+ugFvsaJxezxtqzRhXMsLt5k5PzsbOtU+xbeE6aynnpKPNBhjgUuhpT4xZsixBvFjInuMWFR8OyDTzNyvws9DwDivZOqqJtCBaF6Wz3eISjexpu6skMLjXPazVkZYIjV3Iaurm6qMq3mONnFnI0uindccA/PUNKt0ZrirSdxi0Lruzg0PGRY99t6DIuheEtSvCDPoY/NikWm8lLx9kjg9rSa9/CwmkuqeXTfvN8ebyHeesCXnx5vf6nmua1iJqvQ+lW9569voGufm0Pbm9rjpsTHVrwLr8d70UajkMGKtx+s2NJER9/+Nj0+Y1XGM8KEeAeA2ooyClMJNRaI3Rzjr4Cy0sg4seqO+hjEe3WktxYQq7kN3WyVAsoqLfu+TaGNIt7iGohn3R9IhgujuYaJt96TbJBHId6JEG+jkNHeY7hLIUOS4gUFOJs5FvHOxx5vLxu9WM3TO34ODgOkw+uPL2CAqLz0xXpau8NbILjsn7PogJunUWNrR3zFO+Yc78I6FhtaO2hDQ2uEePsgiljvyx+fTf/4cCX994v1/hTvrjiKdx67cp1Y4lC8/eCed5fR0s1N9Nq8jRlXvYV4BwAmp/UFMsubT4K61bymSyfei+0/wD3eA3YzPkuquXvFFiiriljN27tjhKuJ4h2LJA4NmaEk5bXUVdk3miiKNToJ4m1YzTt6joguZHBSvKynIN+h2629ArNwf8OaPFa8O1OzmnPhV5/1XazwE8bHaneRKN7Tl22l7z82iy56ZKarWrhs8056ec4GRYKWbW7y7PGuKCvxoXi3FZRCq6vdwBYfRPHNhZtooanqtjpDec1CDxcy4q6p5SAojEJGZ1e37RjbsjN+uNqmxlZ66hPj/H7JEZkfjyrEO6BwNaChQJLNucfbCFcrUxaWmu6d3oo393gPnGh8Fqu5Dd1mhVG1IpSWx7GamxcXId6egCGjB5nrU92bKs1Cht0azVZzIYp+UBLuoP6hBnU7bK6dq3VfTTCIM4ZJIMh3xRvXNCiY2Oz3MMJeC6LH23eqeWGpjIGkmncXDvFu7+xOyV671FQY565rUB9OPP/ZOu/+bU3xrvRFvAvLGr3E7O9ORPG++61l3r3bDus+r6ln33yBWfdXbmumdu348VPIeOj9Feo9sO/I3rT/6D6UaQjxDgA8HiqSbK71Q+ch+A1bEjKs5r3JcVHeviJShcTJm2d4D2DiLVZzHSGTeLdThQry4ePF3WpeY7/YCFyt5lVWSnwVVZaVxrCaS0+yH/TpNs5Z4ZIyKjFbRmyFDJCPUKkRSLXT6AUXCPK/x7srjs18pHf4WkFYzb3mePM4MSHeEcU7RluCrobnuNV8R3M7Hf77N+nsB2Yk/Tt0q/TTs8z9nwkQ+udnr4sa/xlFFEORULHY4WqFZY1eFKV4x1ZoP1m5nWas2BY17td5PmPizWvqbTUvrKLaYq2/208hA60PsOwDFx+xi4Sr5Stgya4qL4kkm+c58eYTJfd49w6ZJ4qq3kSVvQwlYJtZgcMmHBW0UAlR//HGfdKfbEPYrDC2h4xKuDXHW8aJJZ1BUBUyL1bl1VRZbpzGWjvcrOYbjOKQICb6knHO6q4ZQJXlZdGp5ri4s/InSfGCfAY2Wl4hZM5gtXzq77YFgTnD1do9rObxiLeEq8U9VmzrW5bzhZp3Fm9RxPn9JVtij/GKgQ31EXIDkq2TvDlrG2jZlsjx1OlUaC1rdLfaN6vHxJzjXVjWaE7gHtDTUJw379RaEV3w97eX2r6OKlLwOLFQF5WEiCpK46xpgVr3B/B6xlG8/zVjFTW2dtIuA2rpmN2y42YS4h0QaisKZ5Z3pMe7hGoqyqgvmRUlKGH9x9nt5mwzB9Gp7m3cFqu5DWGzYtvBxNuymsdQvKV44Qlc43XFu8q0Vtl7kk3i3dVG1BypFgvcU+L7m8Q7XDvQqpjbFG9A7PuCYpnlzYp3PvV322zRzh5v82uxmieO0gR6vPPAZj59qZHlAf7mpx/WDRs1xXtrUzu9tdAI5gSem213mXV6KrSdllsN9mlP67s1d7pQiKKxnz54l35xFW+Ehr0+f6O6fdi4/h4Ogki4GkRACGauBQ9GZ2G9txeZhQxrPWMo3rCX3//ecnX74sN3oRJUKrIAId4BoaaylOotxbtweryhePcJMfHuG1G1mXhbysBI7+p5kSPU5SDeoninBFx4LOKtFG+2mmsXmrIKotoBxm2xm8e17g8I1VvEu9KtkGFLNhfFW1DggVnWKLE8muEdq8c7aau5KN5xizSxeuhzEB8s3epqGU8E/HO7D+2lPj/1yWrr2vyC2d/Nwr+n1VxTvLHljHocf8Oa453/xBs25/X1rb6J4j3vLFVLcMykQTRhUM+YPfPIYkJ7KPbtQHtnOM4c78qCLGRsa2p3P5bMotDGhjYa1KuSTt7H3M9kAUK8A0JNeQEp3o4e7z5sNbcp3ovto8TqRtgTUsXeG2Xt6QgZFxxrnJib4s0XFz45ClwLQ5bVXPV4M1F0VHhZ9RaiGBO4SA1gxbsHiLdLIUNPNpdChqBQ+rzj9njnmeLtmWruocjyNbtNFO/448T8EO/cVrwx/mvl1oibboNJAhPFRvPnfnDUrurz/xZsUvOlP1q2lTY1tlFddTlNGtIrTrhaRPF2fZx13IYLhnizzRzEb+yAHjF7kvF/8+yna63k7VJTyeZxv26KN0h3OVvN4yneBWDd79QSzQ8Y008Ve3AYbW1qc3X2sW3//EPH2I69TEOId4CKt9Xj3VIgPd5K8S6jPqbVPFzdx0XxXhVRvLk6jgAmfXZ1scO0SnWK1Tyw47OSzI1OuRau5nQQcJFo4xeZfop5V8gYEDLOWaEeg6ye+Sjiba3nnIw/R4EgoyqmpXjnK/HWlHxswHnGdKLjxETxTmycWI4T7+ma2u20jPtFU1snNbYZ75vDxw9QqndHV1glmf/HDFU7Yc8h1vSWKKJojROLKN6eYWD6KNYCKAItMfuRxw3sSf17VMZM4X7g/eVqXZG6PWVUH0vJ9uzxpm5lnS732+NdANb9VWaiOVyko/rWUL/aCk/7/hvzN6q53T2ryujMA0ZSNiHEOyDUFmKPdynGiUWs5l3VutV8sZlobirevTXFGxC7uYWQeaJrDxknWrGaB5lqXm0p3q1Oojh8f+PzmpmZfor5p3ibVnMEqPF64n7bZmj4fpH19KqmCwR5pWK6kClcu5o2F47irb9G7gGPspp7Kd7FQ7yf/XQNvbVwU5LjxPLDav6B2d/NNvBkrOb8Mz0qy9TH6VOGq68f/3g1vTTHyP84ee+hqt843jixKl3xdiOKlvMvlPNFDT9YbI4SGzeoB/XvYbyepvYu19GyL35urOUFh421Mpfce+ZZ8e609XjHTTUvAMV7sekg2HVgD1V0sIoZLi6Cl74w1hOku2dVdt+nQrwDAghqAxUG8QaxsfV4m+PEOip6E/UZY4wVwoW6cX1E8YbVHPY9yyotxNsCAr5wwiyx93jHHCcmircnME7DUrzLKiMKrXM9LeL9sbQ+xAA4tKV49xxkhatFqd6D9jDe35jasM2etCoQFIzizde0qrpIYGg+93jHmjHtqXgXl9V89uod9JMnPqPLn5id5Dix3Fe8EV7Givchu/S3WcYTAf8M7NLASZOHqr3i/PUNKi16cK8qOmB0XyoziaL3OLFOpc5yESBqPrVzhneOp8UnMkoMijeKFqz4OxVahICtqzde+z4jjXNQuY9ChrKalxTPHO/FZn/3uIE94iabY943sM+I7J/ThXgHhNqKUqoPF0a4GluD0OONE2O/EuNk0Vrexwit6jvGeODmhZEeb1YGvC7kRYyShKzmonj7Ury1cWJMFHGxsmHwnsZGqHkr0XYjyVLgEa5GxjmrpOcgaxxJVDEDas7QfSLFDIGgEHu887W/26ugoFuk/VrN+esiUbyf+NjYx4A4JuSOyCPivWJrswr2wvkdVvBUFe/BdYbI0q9HJR01caD1/ZP2HqrUR1a8YZd2J4rd6jFMFKMeV2C2aE4pB8YP6qHmR7NC6xwptm5Hi9IKQMwHmI/x7PG2xol1G+Fq8RRvKyW+cBTvcWbwXCzFe/U2Y089om/2z2lCvANCTWUZ1ZNp22rZTvkMrpRxT4lFvMuMsAzLbr56RkTZrhvuuJCLYutMNXcq3jGt5lDJxc7rCoRk6OPEPMPVUNEdMtm4LXZzTyCEhRVvEG9smph8R62pZTcX4i0o0L7dfO3v9rSad0YXHBiieCubLydxQ52NGmvlq8e7w77+OWwz33dUbxrdryZl4j2oV4QMs92cFXB9/+jd492lrjXW+Cs3olhAtuidbZ0q3I4Vb7tCa1e8V2839s/D+9Qogg549nhHWc1jFDLUN1jxriogB0EP9Znt+07Fu6W9yyLjI/oI8S4Y1JSX0vZwzwjx9kpLzRMrr15h4x7v5rLe9pClJW8Yn3sMilQkyz3mghYxQqbVvKuk0qZ442QQBX2jwzYrgXePN8aJWSncLuup280Frgi3NlFtqC3yXibyLmbIegoK3WpeCIq3bovW1VinXVfv8dYJZxH1eL/8xQZFihjRxIbdEfltNecxYgfv0p8GmWp1MlbzTQ3GtQKWcsZREwbSlyYOpFP3GWaNGPPu8eZxYvYUbnfFu3Bs0ax2D+xZSXU15TEVWkud7RPZD5bGse4jXA1rXhGrkIH3uG7fz2N0dYdp6WZ2ENgLGc71XGMWMhCsxmufTeRueS4PFe/trHhj/EHzNqIe5hzhPO7xBnqbqeaNJQ7Fe+3MSH83Q6zmnuFqbDXntE9XxVuv7GLzowfWCaLneOuKd4fLhUYU2rgIN21Un5vClVRbaZzD0DePonFUMYOJ98a5xntcjk9BPiJWYFa+zvC2vS4Xq7nTZg5Y719zXnKFI2OkCBTvJ2aa7XLa9UWLuYhYzfM41RwusQ8t4t3PIs0I9sJs6UTCpngEGVvNgYqyEnrgHPPaYIIJdTRR1BRv1c7IBD2G4l0Ax+Ei7kcexDzBuyeZFW/dFu2teJda48SU4s3Wfbceb33aUJ7b91ch0bzTSMYfZhYoIoUMdwdBLqjdgCjeAfZ4d1EpNZWa5LTZsPXkI/hEWaqG4nVRz7BRVWosdRBvHlGCUWLOC7mEg1koscLVjJMC9yS7Kt44aVoBdbKGced4Q/E2A0paYyneG76QvnkPhHYaxHsLRUJH2EXQ6ixm9BpK1GuY8d5f92lmn6hAkM4QskJSvN2ItzPR3Kloc7Ecj+eCBBPxAsXyLU00Y/k2231RvbFcsMjjVPNFmxppa1O7anPba3hvqq0so56VZUmNFHOzmrvBUrydSra5RiDe4OZMFF1TzZko5rk6qyvebDOPrXhHE0VeT3akRr7BineX2rPHtO7r49ny3L6/2Cxk7DKgh7U2XoWMVebs+hF9c+M1C/EOCKxiNpbUGXc05S/x5oqasra01lMJquFE1MCKfr9d7T+AUWJRirdYzZ3Eu6vUxzgxwCLeidvAigG4QFdZqeZV1kgSWNWiqutwY8A+jY3o+s+z8GxzH6GdxgidrTrx9kqKd44VEwgKyWoOt1fB9Xh3eKuxuMY728P0AmWBW83/bardh40zUr6BqGuIm4sgzxTvD5YYavf+Y/oqdRpgu/mGevc50l7Y6JN4R3q83RVag3iXWEQR85ij0FngirdHT/Lq7RwEVu2ieHd7OghKbdb9GMQ7VJKzRaJEg9XYZh6zkMHrKYp3YaGmwjj465l4Z1Lx3jSf6K3fBmbvhi0JUCdEJEKDdIdrqKnDPFxq+hLVajZ6N8VbrObRxNuympd5K96AjBSLq3hX6j3eJkl0TTaHa0P6kmMi1GQS71C04h3V4w3IegryHV6BWchnaWuIvq7lG/EOd0V6tmNZzd2u2Uy81eY8N4lkEIAi+PSsNdZsX+t+jx7amOPErOJGeY73d/ez7mO7eSIBayDRmxqje7zdYKWaRxFFTuE2FG8mijHneOd4j/c97yylyx//1HtPpxTaaMXbsyd5m4vVnNcpRs+8YTX3SJNXd+bHeLY3F2yicx+cQSu2NMVVvDHD20m8tzW32xR/dhCMNEMFsw0h3gGhttLYqO6gXplXvP93E9FbtxDNfyFgxRvE27BhbQ/3UOmfFthuDtS5EW8hjYzSbnfFG+vsWpWUkWIxgSWzrOZlVfbxV25282FTjM9CFF1RYhLvbaE+1n2e4WrAMK1vXuajC/IRXoFZrHarwNA8VNn01HJ+bfFs0FHEWxsllsOb81TxzuLNtLGhjfrWVtDRuw2Ka432ZzXPvUIFCMhHy6KJNyvWiVjNt+5sU+QbS8UJ0l5gJTvKGm2lcBvWaKvHu6OdaNqNREumaU+eiXduvxf/Om0JPTd7Hf1p2iLX7zfZEs2jieJmjXjjsWgL8Orx9nQQhIyeeYugY91nPUL08X15Z91/ePoKenPhZvrZvz+zhECvRHNd8cZ7GcuEbck2cw0BUbwLFNWmirk1nAXi3bjB+Gz2agba420q3tupJzXrtlNONncqA5Jq7q14m+PEqioibzv3kWKieCeSao4LDV+UYiu0Yo12Q2lzLOLtcnxiRBs2Tzjf1BuKkUBQEFbzfO7vdqra/NriqbF6snmeBFo99+lamrnC3pudKJ782Dh3nbLPMGW/jqRwe/R452m42tx1DdTY1qkSnXcfajoyVThapS0szQ9YHYdSywTPC56p5rYeb1y7jd9TvXk20bu3Ej3/w0hB15o5nbtEEddIrC9w37vLae66es/+bhDtPrUV0Yq3Nk6Mg8DqqsuplxZ6F68whEIGih2cat7d2U70358QvfhToh2r8sq6v9UMR5u5cjv962PzuXskmuuFDKxR31p7MQPjASMOgtx43UK8AwxXA7bySLFMWs15bnhA88NtineLpni3aZvwfjrxllTzWCgxFe9uU/GGQssn0ZgjxUTx9jXHWyeKrW6FjKH7GLbJhjVEDca8VoGb4q33eHuEq3Hg0qA9jNviIhDkIywV00G861fnr83cOUfaqXgnajXP0c051NvLn5hNP358dtK/A9beN+YbQsU39zP2L+VeimJCPd65ZzX/dJWxLzxgdF9r35Gs1dxKNI9jMweYUMfu8YbV3HhOodYdxvcb1kaIom6NzlHoyipe66+e+SLqNc9bb7SvjNf6u3XFGwIMlG7bKDEHSfRWvCPharrirdaOj9mV0/PKur9NW9PfvryANjmO0eVbdiqRBfs+3RXgFrBW39JhFUYwFz0XIMQ7IHDf7saunplXvE1yTC3miSsNPd7boHjrJJGt5tV97SOFnONIBFRqXpS7SoyLRygUigSsuRLvqugESoH7ODFzc8hE0VXxxoisgbsbt0X1jkJZy2b1ebumeFfFUrwBcREIClHxbjNV36qIMlgwxNu31ZxHieXGJtUJWHqBdfUt7snNPvD+ki1KYMDM6QmDe9p7kqOs0X4U7+z1eINY3/HmkmhCZmLBBqMXdpI5XzsVq7nfYLXY468iindJSYQohnWhYdWHDqt57hNvpMTDVfDZmnp6ZPoK6/uvzt1AN7wwT92ePCJS3AaQLs/BzEwU3RLNAW9HhmbdV+sZit6DrzKJtzXDOzeLas41Hda7mhpbO+nX5vpxb/e5DxkF/72G19mKSQC3QPBIMS5kgJDzRKFsQ4h3QOA3z8Yus6JlEta0A+NQmHBzxTBF8Btb7/HeEe5JLR3aJmX0IUQjDyKaenFs25rA6vHu1mxo1kgxsZonDGwwKkORVHMbUXRTaAGZ5+2JsmaTeJdqVnMuZHiupwSsCfIYTFCdZCpPrJi+ery7/FrNPVLNc5B4Izzz5Tnr1W1nH2ciWGP2fE4cHCGjZXHmTsfu8c6e1fzqZ+fQH15dSK/NNVsOHZhvEm/9tepzuJOxmuszvL1Qyj3eTqKoWc1Bzpmg2xx+FlFszfn3o0US+1TTL78yUd2+9dWFtG5HC9399lK65NFP1D4PyfmXHrlL1M87k7jdZnjbeuY9HBmlnGpuOg1CfC6zFTLact6639LeZe2Lb//mZPWaXvxiPU2bv5HeXrSZTr3zA0WmR/Wrod+etlfUzw/gvnkuZFgzvHPnGBLiHRBqzHC19R21mVW8W9FPEg5U8Xbr8d4W7klNutUcF+vzXiE68kr7D4vVPAql3e02q7leqLG5CBhiNU+ox9uueItCmxC6u6msxThXNZT4DFfTCxnrP4tczAWCfJ/jbVkxc3djGhO4ZjvV/LhW8x55o3i/u3gz7WiOEGBO2E4UHHQFshR3XBNbzX31eGdW8cb1jsdUQWl1cy8uYuI9JBJCpdvFQfj8Ogd49Fhqirc2/ioUssab2Yn3h3nzfmTi3aemgs46YCRNGdWHmtq76KS/vads0igQfffAUfTgOfvberadCm1E8W5xJYpqvK+rI8O+nkzQQ7pjcvN8Q0SzrPu5Q0Kd2NpkrANaEA4Y05cuOHSM+vqn//5MJZ3DNo77n/v+IWqGtxPOpPhVLgnx2YYQ74BQ6wxXy1SPt97XHZjirfd4G79/ByHV3HtUggW+WEuquYUyR483wFZz155kUbx9WM1Z8a70SRRN4r3u09gbqGJDy3YqCRsb9PpSfZxYHKt537FGmwmCAzfMycxzFQjSbTW3FO/c3ejHRRTxjkMK86jH+z+mzZzhHMOkw/PcBeJtKt7De1f77qGN3eOdnVRzjKji/ZpbqBdIB9RDnM9H99NaAhHT06NS7fHw42zL9Ws199PjzUQxKgzMPD5LQ92G1dxcd5tCy0TRskbnPvHu26NCvZ5bTt1TkUasKV7ar0/anW78+h6eYXROorjGVGiHO4iiZwaBY5wYj2cr6XTsH1d/pFn3c7fHe3tTh5VQjrbMHx89job3qVYFN7z0b0wZTo+eP9UWUhfTQeBh3c8mhHgHBCZSEeK9TalJGSXeAYWrdbn1eIfR4x3jwsMQq7mn1TysneyqTMVbwtUSR3dXl2Y1r/ZHFPvtavRt4kK+cW7GnmvOw5yEsC3cg8Jm6n7cOd6AzEcX5DO8RkRZClvukc6kiTd/9ku8+XOOEW/sP16ft9E+hslD8b75pfm01/+9Zs369aN4szU6SlH0CuLLAas5928Dc9bWqwRn+/c51KtnVC8svh5okj6/AWuJWM3jKd7l1GlYzU2iGHLudxRRzH1rtEW8ayqstf6/k3an3Yb0ogfO2Z++d/DomD+vH8v4/0u2x7s0FKayUNgKqytxZgTBvp8H1v2tpuINBwHnZ/3xjL3Vel59wm70+9P3irgkXOAMV7NGieVIojkgxDsgoNIF8o2xWwrhrsAU6Jgwe7DTYTVHQqLV4+1X8eaLuKi1FsrYal6iWc3NQo1tRJv1A+ZFRoi3K0LmeDb9gsxE0TWFG0D1XZ8/LbAR783h3raNWWV5jJR4hkW8Z6T5SQoEGZrjnSc93nhf3v7aQkW24r42JoVeVnOETwLtO1VieFNTY05azUG6od6it/Pw8f2j5h/reGfRZlU0nG7Or9YBcsOKN8KbGNwb66l452C42nwzLRvY3txhFRScxHyiGSDnBFvG/fZ5bzQf58dqztcTrx7vUjIUbyvVXFe8mSjmUao5FFrGt6eOopd/fBgdOWFg3J+3iOLOdvV/CJs6AJU3kR5voLyk20qTj17PD/PCur+92VjPftqc+P1H91XreeHhY5UKHgtOxdsaJSaKd2GitrKUOmD4qMjgLG+b1bw+EJWdK5TqDcxzvBGu5ot4s9VcerwZZWHjRBLWTnbVpuLd2h7Lau6DeDt7FIsAJfoFhRVvkyjGshfSiKnG5+Vvp/cJ5hN2GqPENofrjEKbiap4ijcw4gDj8/J3M+PuEQgCD1dzEO8ctlnrePHz9fSX/y2h219fFP1Nrx7vOHO8t+/YTmfc8yG9Nnt5Tq7BC58ZNvOTJg+lgT2rYirerMyu3BotAIDccHjTkN5V8RVFX+PEsmM114k3MGet/esF6w3izcntTgxOINkc4654LJMfxZsJdbTiXRpJ4UZPskUUzefQc0iEKOZRqrlOFBOBThRZ7R7UKzqB27Lue4X/4a0c6rLWvazLsZ5rZ0XEwBxez61m2wPP404U/XtGeuaRccBBitLjXaBgMtVR1Tdzfd48SkwhTNRmP/GmFq4WIfYqXC0hq7kQb6fiHS7ViHfMVHOfVvPNC4l+O4rozVuoqGBejLuo1NoUWdZoL8UbGHeM8Xnpm0SdyaXhFqziTb0jY0j0Qkas9cRUA7zfMQd8ffIzdQWCjMOrbzcPFCGdcO00iVDM1+bTat7abJC0tla2mufORnVHc7tKNAZO3nuo1hfb7uoG4AC2lVuj9yGsdsNmzdcNG/FOapxY5q3mUO75OJg0pJdrnzdbzWHTdYOVbO6DePNjelSWqY94YKLo3ZPcaetJLu0y9zu7fClCFNnFmWNFIB1btXC1ZKBbzSMJ3NHvvbgZBHgrU7dl3S9h4j1wN6Ieg4y2mpUf5JF1vzypn+dUcxTYMHKwvatbHWdDfBSLMgUh3gGi1gxYa68w04GbjAtFxqzmQAD2dn5jV3XtNCzzptXcn+Kt9Ys5+o2o2Im31uNdHTPV3Ge4Gnqg2huJlr1FxYSSbuOC0qlZ9yOKdwyiOGRvotqBRv7AyvfT/0TzzGquK95xe+aBsgqiXY4ybi96Nc1PVCDIZLha7m70gUWbjAwV1zRqz3C1Cl/jxEpZZWT3WhZI9qMfrrSR5pfnbFC91yCYuw7sqSVBRxNGXb1d4aJ4r93RHNXfDTABjLbyeuQBZDnVfGNDmyIXIBWn7DNM3ae3HqAnfqWpoMazmrOF3J/N3J8SGa/HG1Zzg3hzT3JLNFFEGKr6ZblDmpzYzoq3R9hXPOjhalaiuYs66z1n3m41jxQyuJ+7hmjkgfa0+DywmvdNUvFGAYTXavZqgw8N7V3lGW6XDeTOMykA8IioVot4Z9hq7vZ1KsS7wzhou8trqZ3KE0s1B2GXMUOq+FAeNsPVXFLN3RVv86ToDMdwgqvBRRZkV2oeVzbi7YcoogI//ljj9uLX0vws88tqvsnZ4+3Hag6M/4rxebEQb0EB9HjnieLNI6KiSKLttXUlNE6sxHSplZuFzWwVHzCC6Zrn5tBRt75FP/zXp0rF/c/step7J+091DVASYfer4xUb9hNdaxx6e+2W83D/toSsmw1Z7V7bP9a2neUsef8Ym2DFbC2aONOpX1AUUWCuRsG1/kPV0skWM3uIHDv8Ua4Gh7DTis7UTzIXuzIB4U2Sau5PnfaGn3lMnOaCxRRPfMlJeiWj7aad+vrebBjPatz32reI7n1RG4AF0FmrdyRc/3dgBDvAIH0PaC5zCTeZn905qzmwQSs8YWn0iTeYYwNMkmi8yLmWT0HxG6uNnY4LSq49XinMk6M3Q0BtBfkE0rMcLXOksh6xg1XY4w7zvi86JU0PsN8VLzrVL+ds5ARM1wN2NW070OZaNyQxicqEAQIr6TqPFC861s6LBIUpX7ZiGKHw2peFvOazeOHrN7QLFjNQRrfWmg4BbHVQF/3iX95jz5cZuxzvjbZIN4DYxFvjUS2d3ZHkUqLeDvDq7yIouUg8KF4exU30oB56yM2cjgB8PShmvJs8wXW993Vblu4WgLE20+wWmxrdGScmCLepiXdclrgvcfE2/pluUm8sR+2FNpkreZmTzKK3FxMcY4Si9njrYJ7zaT4UCRcLfI+rooo3oxcHifWnNp66vb9WasMIVKIdxEo3k1lvbOneAdiNTcuPFXtxu8K1fSL/Ll4G3FU23kUS4cQb5tqrVvNOdXcrW/eb483F1na3EemFCq4Mt5ZmqDiDcAajc3RtmVEW5ak94nmU7ga9VaGgISs+0DPQURD9zVuL349fc9TIMiE1TwPFG99RJar4u0sKvi0mpd1GcS7Mpw9xXvp5iZF8DAu6OlLD1ZEm404B4zpa6nUA3oY/z8NrZ1R53xnUNgKR583J3/rM7xjKt6luZlqzonlIN4o5O86sIfNbh4v0dwWrpaA1dzPDG8/DgIOV2OFtlR3WkQRxeqcLYLxy/OaK+1HsKs1ucO8dQ2J93irdKdSa5Y3OwgizpUaokF7RPKXcng99Z55PSU+UfQ3C3PWeubQKDFAiHcaiHdjae/MhatxjzdXWgNQvPmNXWEq3qHavmpsr/pzkmyeGDS7vVuqeUt7dwzi7Vfx3llU/fQcGqJbzTkBNGYYGFDZk2j0IcZtUb09x4n5SjVnjBcXgSDP4BWYlQeKNyzEjA63aQJeqeZxrOYVZrhVFfHs5MyrRO8vMfZM+43qQ1NG9aG/nrkPvfmzI+lXJ0ykW0+fbD2uV3UZVZg9m86AtQ31dhXcmWxujRLz2+NthdXlVrjafIeivcfQOvX5C4t4G9+fONg9WE23jWOEVWNrR6BW83g986XUZY4Tcyq0TBS1gkGOWs2ZJPasKrNeRzLg1gkEgXkRRc9CBtbYfM/breb8Pq423C48hSSH19NrPFuy9v3IeoriXbCoMZMed4TqMq949xlt/zoI4t2+3VK8Yyq0sQLWih2m4t0WLreFO/B6xraax1G8MT6ONwRF1E/PVvMu1x5vP0RR+pIVkOxutqooq7kmeUdSzbv8E2+E/BXRcSjIYzj7oPNI8V6kKd5RCdxur82n1byy27jeVIfas1Z8YOJ9yK7GnG5gVL9auujwXWhkv8jmGbN8IwFrba6KNxPzKOJtKt7Detd4hFd5jRPryhnijX3Dss07bYnmewyrs0aKwbLPirfXKDFWW0Ea/YwU29DQlpDV3DslPqJ4Q8XlfVGkJ5mJ4v6Rn8nR96M1czoFkqhbowGsyZC66uQUb0W8S6IVb0C37+eo4t3Z1a1cBKkr3vafHS5W88IF20V2UK8M9nibRLvv2MCs5lxRK28zf1d130j/uq+ANSHeFkwi0kblth7aSKq5SyGDLzK8CfSC7m4oIrt5KRNvbTybrznejHFmwBpGa3DxohhhTl3oCpVRPdUa4wMdPfPokYyLwZONFFpJixfkC9z6duEashTv3NqoeRFv93A1x2vzazWnTqqgDqq2FO/qjG+6py8z9kyHasTbC14Ba6zM7j3CcB7q6egYv8Ybe68eb0/F2+GOWLJpJ333/o9o5opt8Ue2peEYwNMEOeF1YOKNMDoknmOkGsgvW9C9wNZxp1MgVat53B5vWM2heJuPi00Uq3J85nRwxHto72qb+4xRqq0nB+gxcA0HykMoZphBa2HH+1i37+doj/eOlg7LvNknyXFiuuLNEKt5AaPaJKfbmHinW/HGhYCDtZh4B2g1LzcVb6rpZ9no/VnNhXhbMFVrEG/YqvylmicYrgZgrFiRgHvBumw93glYo/vtQtRvV2OzhJneRW4zb6vsR2EqcaSaJ+AgwIWeZ6QvkrR4QZ6Gq+l5HDlsxdSJd5Q6m4zVnAvluNRTK1URK95aUGoGAIt0Y2sn9aoqs0ik3zFMbqnm6Al3jhRjm3lddXnULGrujfXs8XZYzV/8fD29u3gLPTlzdcYVb91mDvUfmDS0l2oJXF/fajkHkHjObVhe8DPLG3vCzeY6J5pqHtUOYR6f6Ec2Us3Zat5mJ9k68c7R1o/I6KvU/t/5WI5FEplQux2j3aFSa443W82tQgav57D9IueGXF3Ppnbr/ZnK+C99PavKS6KIeLYhxDsNiveWcM+I4p3O3ludZPcZFfgcb0vxroHiLVbzVBVvrgADvJ4tbj3JiYarqT9QPMSbL9DdLlbzuCncUXbzAiGK21cSzX3WsI8nGKzWUmmoS7Y53uVJrif6vAshbwDvp8//TdSUAddSnuGOO+6g0aNHU1VVFU2dOpVmzJgR8/E7duygH/zgBzRkyBCqrKyk8ePH00svvUQ5F66mn29z1Iq5dWebrafZrd8z0pPsIN5eVnPcb27Oa6mVqkPZUbyZLB68S39Xxc9LJdQVb6RMbzJne08d29dSvFkhtGZ4O4LVdGLjmWruGCfGPdENLZ1ZIN5msJrWv41Cwpj+xt7rqU/WxLWZR83yjkG8UdzAvhD/L7o6GwtcyPDq8XaGq/HYVeu4GzaFqKo3UWWdkc2SRbg6SwLqRwb0NfVK4Ob1dHs+rHgb4WrGcVxprWdNJHtplJlvUzeCcnE9t6Y4E91tPWEz5+JUrkCIdxp6vDd19oxUSNNpZeVRYlV1SpU27guOeJe1bnMh3gko3pJqbuvxdlW8XVPNzRMlbI9eJAb360UWBKwVCUrN0BBd8bbC1fwotLrdHMTbLaAon7BlMdG9XyL69zlEdxxANP8Ff+TXVLxbKoxzR9LhasDYI40N//blRFvzPC0e76VHTiZ65gKiv+xD9MFfpXfdxBNPPEFXXHEFXX/99TRr1iyaPHkyHXfccbRpk1HEcaK9vZ2OOeYYWrFiBT311FO0cOFCuvfee2nYsGGUVXAfdJeL4g2i5UVScyRYjd+qUSTRtcc7/ozpsHnNrgm1UbWleGfWbv+e1d8dmaKSqNV8W3O7GrGGfTbC2bBO2LNwscIrWM1XqrlD8W4yr92wr2c61VwfJaaDA9bYsu/8fmyruTfx5u9BOfRTFLGNv/Lo8S4JhdUH9yRXOK3mIIoXvWl8ZDAt3gmMpNr7htfo9tcWelrNk000d1e83d93+rp7Kd7o8WaBJ8pqDnzjIaIL3yQashdlU9U++va36dv3fehZyAhyPUfmWLAaIMQ7QNSYm/+GrtJIdH86+7y5vxtztlEZ1O9LAfymLnXp8W4Rq3liMDdzrVRh6/GuilXI0G2Ouv1RB9ZWV2vais9q3q33eLM1Ol6qOQM2tspeRp8zZlDnK+rXED3ydXOCQsggvk98h+ihrxKt+YSofi3RpgVEqz8mWv6OvUBjKt7NJvHWC0MJ9cxbafGHGrcX5XFoHQj242cRrf3EWM+2eqLXriG6YyrRvOeJGjcaY+jWziJa9nbRzS6//fbb6cILL6Rzzz2XJk2aRHfffTfV1NTQAw884Pp43L9t2zZ67rnn6JBDDlFK+RFHHKEIe1bhVIV1xTsH1O6lm3fSv2eujurlXLzJOM/vMqBHDMU7Qas5HmrayqF412Shxxv7ilkrd0QFqyVKvJkg9qutVHsWDqniPu81VrBatX+F1qPHG7Z49bkts4q3Ck7zIN57Oiz6sUaJMQb5sJpbM7x92sz99HhbAWulIZUvgJ5v407t/wYtlGgNyxLw3K99bo76v35tnlGoTk+4WkVc4q07JrscxYwu4sC6bjWKz068td9X05domDn+M0v44xuLaPmWJnp/yVZqcCTpp8dBkP3zuRNCvANEbaVJpnAiZgXaDDBK6yix6j7GR8BW81JL8e5nhYFxlTcmhHi7h6tpJ86+NRWWhQv2OBv0jZ+X3dz5/1yEVnNbuJrfOd7WL6kwZnrn8xgsZEiAdDesIeo3jujHs4kO/7lhG135HtF9XyL64ySiO6cS3X800cNfI3rsGxGVz1S8myr6R13YuWce6pGXLazgxophXZ46j2j520bh9PzXiU6+wwiOQ0Hjye8S3Tae6G9TiO49iuiRk4juPtQg40UAqNeffPIJHX300dZ9JSUl6uvp06e7/szzzz9PBx10kLKaDxo0iPbYYw+6+eabqavL+33a1tZGDQ0Nto+MWM25yJkD/d2/fOpz+vlTn9Ozn6613b/QTKpGP693qjlbo53hat7Eu6vU2Jz3DDVTZajDt+K9bkcL/WP6Cn8F+Rj4eMU2NfpnaF2VZZeOB+7b1Hu82S49uM743uj+NbY+b1a8h7tsxsvizJ2mcJfNSdSEfR5bzn2scVBYV9+q5peXuQSn7T7MTsT9WM2tWd4xiPcmXtde/ntlI+vpTImPrFEpUrhLSiIuixwLNnzqk9U015wFvWpbc1QhLDJzujI4xduDKNoVb/uadlmKt3Fc2McC5g7xxPnr0Q9XWl+v3tbsSrxTLWT0Ro+4uQ65NkoMEOIdIGzJ37X90x+wxuo2qljVrHinbm03NtphKm2N/H7uX/d1gZVUcxereYXtxAmrG75u7eimTY5UVmVz5Mq5V8Cas6WgiMLVeD6lTfFO1GoO7GoGguVjEndrA9GjpxJtXUzUazjR2c8ZIwW/dA3RZTOJ9vwGES7G+EBRrvdIg5Cv+oDovdvtxLvc6IXUHRlcyPCdbK6v56oPY4/eyUVgI/PCj4gW/Nd4733rn8Y4m32+Q/TDWUZBQ53XQkbPIdYcLiMUVp+7NP/bFXxgy5YtijCDQOvA1xs2uCv/y5YtUxZz/Bz6uq+99lq67bbb6KabbvL8O7fccgvV1dVZHyNGpKEf0c0+bI0Sy+5GFYFpn5uzmJ3Ee/FG+wipKFLjFhznI3G7w3zNfUkrcvjYsN/66kK69j9z6fnP7M8zlTFifvsx+7PirRFva9a0SSYxikxXvCOjxKr9W6P1tgNN9W5qM85xO1szazWfbxJBkG5WNxm7m1ZzoGdlmevrTMZqziPZ/Caax3YQRNazLGwo3hZJDJVk1VauAwWVP7wasZdjX89Em7GtyXjefWvLg1NoPYgi3hd6srmOLh4nFo6ME4v0eOcG8UbR4sb/zlNp/PGId6pWc7j3+pkuglwbJQYI8Q4QtgCyGpN4Kwtomnu8das5rJEpbnrxpu5BLRTiTUl1XyuxXVLNU1G8I3fj5MiVTdhuEg5YK2LFm0NYustSCFfTJwHkol0Y7+FYfdpQZtd/ZpxnQLrrhke+13sE0Wn3EV2ziei6rUS/XEF0+RdEX/uL8f23fku0eoZlNW8qN8PVXFLNE1pTEH8QU5w32I2TKwBBibWe791GNPsxo1Bx+oNEY4+IfK+yh1HQuGo10XXbiK5aRXTFXKLzXjWKGUunEX10d0ZeRr6hu7ubBg4cSPfccw9NmTKFzjjjDLr66quVRd0LV111FdXX11sfq1evzswcb2uUWFXWbeZc7AIhZSUSG9dFm+yKNzaxUY4p67X5t5q3lxib0/6hhoRGOC0xZ0mv3RFn9KXP/u5Dx/mzmeuKt24155FXHBg2yiQxTBxj9XhzyFdXVAq3tm5aoUb1dls93pmzmkcSzaP7t5EGPcqcdz5RSzyPhUF1EeeAa2aA1jO+7yjTWekDViHDy7pvWc1LqMqaHV8Dhkm5gL/9b4nKBkAy/CBT6YfqrWN7U0cgiveQuipVTDtgdN+Yaq9XDoEVrhbqtgoekekEuUG835i/Sb3PK8pKaN+RvV3XMyjFGzh6t0GqoLHfaP/HbKYgxDtA9KgyDn5UxcKW1TwDireympvEG0gx0A1V9N4hsxcUlfCKGquokJDVPN44rGKAuZkziLf97cbV+BXanFHfI8Vaipd4s+Id1jaGCY2/YvQYaHw2CWjOYNVHRDf2N0K93IBzypLXjdvfeZqo/zj3x0Gp0Tcxk88wlHBYJp8+n2iHYfna6aJ4YzPEF3nfa4q/B/eN+qU5ZL9GEeD2iUbvuxc+e8L4fPzviHb7qvtjQGj09/DAiUTH/ca4/cb1ROs/p0JG//79qbS0lDZutP/f4uvBgwe7/gySzJFijp9j7Lbbbkohh3XdDUg+79Wrl+0jcDjt2DbFO7vEe87aCPnF/vqFz9ZZBBOzmfG21C3EntZoLir4sEG3hYzX3M8k3h0lVfZj3QNrTCLLY4CSATbbHBaGRPNE7bkQA9j2HUvxRhsSu8vcFW8ef+URruZUvM29UEt7h+YqyADx3hAZJeYGDljzYzMH+tdWKlsuXrZbn7f+/3PQLv6C72xW86hwtRLqRoHWnOVdURrSAv1ygySu2NJED7y/XN2+5qu7We0Pq7TRdMBWU/FOlSjievvfHx5KT1x8YMxiideaWoo3wWpe4rCaZ1/xxXvvphfnqdsXHDrGep97Ee9Ue7yB35yyJ8341Zd9p/BnEkK8A8TY/j0UQUUQgzXLO53haqwqYbOLiwNbvFMIWENVHSfgvmQSObOAkJDV3FK8iydp25fi7Tih8skcJ/ko8OaPN4NOOIsrRZRqXs7EW7OaJ5xqrhNv2PTjjW7LJOY9RxTuNsaDuWHj3IjCPHTvxH73ibcZtvMdq4ga16u7dpZFh6sBVYn2zQPohwaacqiYseJdoxCw8CX3/+f2ZqJtS43bu52U2O/e73yiCScY5ObpC4zfVaCoqKhQqvW0adNsija+Rh+3GxCotmTJEvU4xqJFixQhx+/LqXA1S/HO7kZ17rp622ae7eacaD66X61tBnWU3dwi3h2+reYtIYPw9CONeMcByC5vlJEmniymL92qzCgTBvW09brGQ21lmSUIcJ/3hoY2WwiY3uO93lTlMdfXbWPvHQamK96RcyGTfai2FjJhNedRYh6J5ecdOlopit850BwxGwc477ODgi3/Xv8/A3v6L0p5psTjPtJTuNHjnVu26N+8NF/lmxwxfgAdNWGglYytE0XshdEqGIQ1mv8f4jkUvPrmuce7VJvjnUuK90Pvr1CuE7y/v3/Urtp6tqTFas5w7mlyBUK8AwQsFPuNNhSfpc3VGVC8tXA1/XMKAWt80enDineN8TvZas59TTEhVvPoVPNwRZSAMNq0hCWleBe11dw4OYe1XsxIqnkCJBGp5jySLJdUb05Z3zTfvW2EifegPRL/3Rg9eOp9hqXaRGOZ8R7XWyGS7puvHWB83pnGUMlk1xPFDKypE5sXGN+DbZ+LMX6BjdJJfyPqMZhoy0IjAb2AgVFiGAf28MMP0/z58+nSSy+lpqYmlXIOnH322coqzsD3kWr+4x//WBHuF198UYWrIWwt9+Z450a42lxT8b70yF3URhvhTos2NtLCjcY5ftygHra8EBCEVFPNm8g4D/YLGaS/3QfxXr09cm3aps0WT36MmH+122uWN1vNWfHmDX59S4el2kLtdiM4PP/YTaFVvcceVnPMTraQZsUbZJ/3C17Ee8qovvTM9w+hidqMbz+2XOB1l+Ru/v852OeYt+hCRvT1gxXaUrPHu1q3mmcZKD5gHfAeu/aru6ljxY14s9qNfT8LU+kGH6NePd7l1KnaGKF8V4RcUuKzABTF/vo/Y8ToL46boIqG3Me+yrH3DdJqnssQ4h0wDhprnJzm7CjPQI+3Nk5MfeaAteSJN1cn+zgU79415VFBJp7gk2cBqz/JKN5sAWKMshTv5sR7vPn/mAlUWxqSf3Nc8e7WrebJkERsvnLNbo5kbfRuswK31VRidWxi4r17cn9j5FSiI35p3K6so7YS41hzHp8Jj2gDrPXMIas5Rn8xNs6J/v4mwwJHgyYl119Y24/oFLNneeb9+T1OLQ7Qo33rrbfSddddR3vvvTfNnj2bXnnlFStwbdWqVbR+veGkABCM9uqrr9LHH39Me+21F/3oRz9SJPzKK6/M4qtw6YPWi5xZDFdDvzYTxMPGDaAjJxjvp+c+XUuLTeI9flBPlQTN8Ayvsoh3/P7jprBxLu3PxDsUX3leo6lVPFYpGcxcYQgIBydgY/YaKWZZzU3FG4G3A83HsJo7zCNsyTOF22WkGHqhWe0E2ckU8V6woVGpz3hNQVpoj5lkvH/fXbzFyCjS8MFSs/8+wcKIVciIpXiHDaJo2aKz3OYBPPj+CvX5O1NH0q4DDbv+CBfibdmiayp8BwKmCi8XAa8nrPtGWF3upMQ//ckaVaTafWgvOm1fI4tmpCk6oVWFz19w21qKtzn1p1ChxTUKggBfPGZuLqHz0q14N2s93gAHrAWieDfaSP34QcbYikXmOJOY4BnmYjWPpJo7wtWAMVqPNzZcNluMRbzjKN69hhLVry6qtS5jxdt1nFi3OoH7vhCCKGL9csUavWWR/f984xdEA8a7K94DJyX/dw77qZpcQP12pc61xnu+xLFmCY9oy0WrOXap62ZHvt4wJ1gHAQOj6Q7+IVHDOqIRU6mQcdlll6kPN7z11ltR98GG/uGHH1JOwZn8nSPjxLCxxyYV771dBtTSKfsMozfmb6T/zF5nkUwQb1wrcLnA5ToqEMvZ421Zzb23e43dxu8eUGJc39tMBdy34p1kjzcS3C0F17Q7JwIrYG1nmwqBhLKth6uxNR+93R8sNdr+vJK+Y1mj1fGCMZam4t2ktdxVMPGGKs4FnTRhntmGABITJDDvGyPWQIRAvo/bfbCVOg2LMNbmgDGmwOMTntZ9XfEGUSwBUfQ/wi6dwFzpdxYZbq0zp4607mfFW0/hDrIfOdU11ddTH88WphCFMpA7EAsvfmEUYr91wEhrjzu4VxVVlJaoEYLr61tU8jjeU/ga4ETyQoUo3gEDJ0SMcVjTVpv+Hm9rnFgfh+K9PXXFO2RXvHGx54pyfbN96H0UxGruqng7iQ0udDiRgixubHT0cvMFiDeDXoo3p1kXkdW8whqTEU28E7dG55jizbZoL6KIzfSmBakTRWzCj7ySaM/TrVTkKKu5OcublZ28tJpvW2ZMemBs+CIG8U7SQcA4+tdEp91vD7oU5CZcw9Vasq54zzGJ1cQhvZRi+OXdBqr9BMZgzV69w3YtZodKh1/FO4bVvL7LtJqT8fdbQ/E3vqsdirdzxrHfQgOs8tXlpTQkgVFVDC5GbGlss8ZhoYe7lxl0C3DKN08PcZvhDfAYpq6Ys9E7bf3d6ueYeGeA4LAbgnuygwIK1ax663ZzVrv3HtGbelYl1r/up8dbEcWy3Onxfn3uRkX+MKoNPe0MDunD/penfFi26AySxHiKN9oeQG5rQmYODtYziynxCDX8fE29KhIev8dg2+sYbr4P2UXA7Sp4//Jo5kKFEO+AgYvl1LF9I+FqULyTuCAlPE5MV7xTsJrzJrwPcY+38btx0uVK8QIzVdMTFXH6k4sJ5mYOc7ydVl4cK8O9RooxqYw3TqxuRBH3eOvEO6I0JBawNiA3iTe/l51Ecdtyw4IOctB3TCB/kqvnUeFq5cko3jlmNXeuJ0i2fj7Gbbafp+IgAKB25cgoHIHfcLWunFK80c+tK5oIjTx+z8iGFYVaDuW05iR79XhzUcGaMe1NEHZ0Gt9ji2qLD8V7jaZ4gzxzz3MiWLrJ2GeMHVCbVBCSZTXf2WZLNNcdT0y8GfEU746Ys9E7ool3qDNuYSP44yMyrzsoMPH+34JN1jXhvSWGcHRIEm0AkQTu6PXsMM22lkJr9Xhnl3j/93NjgsBX9xpiO4b61JSr3mRcLjjJPxu2aK+++U5tPYHa0s6oHJxs4L+fG2o3UsydrREjHC4CDmiEdb/QIcQ7DThwbD/aGjarZbAnpcMGjCAYJrZWuFrqVnOupPXleZ48Fs20I3GfkT+ruSjeNsXb5d022qvP2+84McxsVn9gZ1Er3kjy5H1bXlujmSju9U33nmSLJE4MzNbYZRJRZ+o+FzOSSopv2pxb6znpZGNjDPUbie4MFFzgSoJNdMDErD1NQS70eOeA4r022kr89X2GWbdBuhHmFJMosqWcX5sPq/l2k3gzmsN+rObuicSJYOlmY48AhTEZ6OFqPO9ct5nraiXDbYZ3PGu0s5ix01XxTi/xBoHlvRdmPgcNzJDGHHD8P85atV2JMB+kEHzHx6fbrPkuk3qUhjuNcLUcGH0FJyds9ky8dYCERxHFLFjNrfd8l/t6lmFUKDoQSztygni/aBLvEx3rCTgD67aZYXV9C9xmDgjxTgMw67CFqqglXJG+TSjbyRGuhaTigMLV+KIz0AxZ0VN+Jw7xS7y1cWLpUvvzLdWcKmxJtHr/GVtyEgpXay1mqzmHBVXZLoy1pj2pwezzyzurOTZ1rHDvY86cxsivpq0uQWAp2qI1RKzm9uOzptIgJ9w3mXfrCXB/N/qumVjrxQwOqus7NuLUERQ+nCO3ckDxhlV7nqlo8ixm4MAx/WiIGRY2XpvNXO6Zwu01x9t7Q7u1w04am3nvEuO5rjE3zFyvS4Z4LzEV710GJEe89XA1tppzsJrzGhtP8Y6Eq7kRb3smgD7dpSJDVnMUKdo7u5XyyqQlSMCB96WJAy27OVL0tza1qzaAfUb2Sfz36QGAjn1gR9g+/ioy+ip7bpNX525Q//cQmDhUTcfIvg5rdBaIt9UOEWU1N97zJax4lxjPrSuLxHvZ5p2qNQLvq6+YmQE6RprHMDIEgK07iyNYDRDinQbsNriXSgHfatnNt6bRZt47cuULIlzNPEEOsIi3qQgS0QRzPMXCeFZzrlpiRI+p+BYtYszx1keKRVvNfSredSMjs6iLpMgRUbyrXd0DSzY15afVHKOu4JCprCMavJcxp5sD1qKC1YIj3p0exJstrWwH9QUu1GGag9sotEwCSuB6k3gP3Ydo8B7RffNB9XcL8gtu4WpZVrxhlQbRwftwgkawYcHmmcx68rdnCncS48S2tNvV8Kbu2OptQ0snNZqqL5PmZJLNl24Ohnhv2dlus5rr4ARlXjOnIs4otQoZblZzp+LdkfEe73nrjT3ZbkOMcL10QB8rxinwCFVjl0Ui4FYId6LI48Q6FUGvyoFxYi9oNnM3RCu02VO8o3u8WfE2jsXakHF8dmviRLZs5nBLuM3lHtnP7iDg80ehjxIDhHinATgpokq9je3m6Rgp5hwlpm73SV3xNqvnA2hHFPFmq/mijTtjB6mw4g0Uu92cU83DSDUPeVvNnYo39y/zbFknWuvtVnMUOYqkp77SrI6HHKNHMN8W4LE7eWc1Z1v00L2NYtrgPTNCFLs9rOYc4rQoEeKNWdgUMo7HdAZL+sHWJYbrBpu5/uO19fw88piN8wIvZAjyAE5VOAcUb57fPW5gD9XbreP7R+5Cr15+OJ25/0iXHlovxbvDl9UcjpfNbfbv7eyu8JVoDqv3UFNB3taUgDPGVM2ZeCdrNXdTvJ3EGvZp9OiyGu52HY5vNbcXanZqinemrOZ8fKSjv5txxIQBKm0aQsA/PzJacg5JcH43Q19nrzCwkhwJVwOJ5tT7E/ca6voYp0KbjZnT3j3ekfXUFe9sEu9YNnO3QgaKjkDf2uDG5OUqhHin0W6+LawFrAWN5m228LOgwtVQPa+mVqoNtUZZzaGAwRaE/iYOmPDsn2PVoIjGXMVVvF0u+Kwq4mRu64OKNU4MygyUUaDnYKM/tVjs5l0wVXW5XqTHmfawxYkQRcsanQM9yevMedPD9jU+D9rTbo1GH//25eb3giOKXuFqIADAkkQKGdjccy5Etl0EvJ5DJhvPi1Pgdas53xbFuzh7vN1SzbO0+efgLLfEarTSQAXX36OROcndsfvX41jNd7Z30k5zjrd1X1dsEskqFcJBmXhwj6ZfgCw3tnaqbA5nAJpf8N9GEvUi8zzltJrrfd5eNvO4VvOY4WpdGVK8G9LW382AjR17V2CZ6cJLpr9bX0+3AMDOcKTHu7wEPd7ZVbxfmbNBXQeRrcB7MidGmseQs8fbTc1Nu+IdtZ7sILAT784sEW+IH2hVAF84blK0zRzgnvntzR1qjBunmvetTX9IYbYhxDtNgCVsKxlEoDMdm3pL8dZ6b/h2inO8+7PNHCdBDkoz+0vYErYwbp+3JJsrIIHaY5wYbwR4pBhb5exWc5cCBxdW0N9f2YuoomfxBKyZ6wmEKuybKGvWfEKK94CIVb+9OUcU732Mz05rNKzorNLXJrcZcgM7K52FIS5krKtvpcbWjvxLNo9aT7OQsX0FUWuDMRpo80LjPiHexQWHgpkLVnMeJeZX0WQrb7Ti7Uhsj2M1R6hUs4N4N3aVx3S1ceEdm2fuyUxU8V5iqt34HU6F3y/wczw6jImim5Wcib1XsFrM9XQZJ5bpcDX8X8QqzKQj3Zxt1GidTAb69UQPAMRr6WCFthvharCaG0WbboeLLfNp5u5qt1OhxWvgFO7MKt7uPd68nihkANWm1byrNDvnshdMtfvwcQOoznSbuBV5+plrh2IGW81F8RYkDVinWsoMIrxpw9r0jxILKlwtHKYB5ixPtYF2kEW2m6OaFRMyy9uheFfYep4YuOhw5W+F3ucdK1yNCysI1cP/TyUT7zi994UAzXofclhCmShiA+bap+cGFC74Yp9NuzleF9uemSiyQrt5AVFneyQILGCS6GU1xwVzoGnl5BCkvEo2dxJvuIN6Do2E1G1bajhHymuJehs9tIIigW7HZoKZZat5JFjNH9HxVGj1Hm9FvsMxiSHUpiayv+amcIVSkeNZzUf0qbYUqu0JhqtZieZJ9nc77eb83+imeB80tp+V3O2F0hIPB0EMxRvENBM93ih+IuQS/+fcUpUJ4g31O9l+crg0mHzrRBE3dWu0kWpuhoGVZP69B+fFh8tMm/me7rZoFklwiWzp6KKNDW20o7kj53q8rXFioewp3ihKvGgWMrxs5gw9KT5iNZceb0GSwEmnVz/DYrFjs1H9SbvizVZzqHe6hS4BoNo7IBTd3+0MWJtv2p48gc2sei5FoML6STVHj7fHjF8OWFth9g7FDVfjwgqn2VvEu7F4HASqZ96uksD2iNnTSH7lvqG4wP9JLtjNQaqxqYNNm2ez9x5pBK3h/i0LtWC1FOdNO8CbIrdWCO7zXrwxGft+FgsZUKbWf24n3jYXwReazXwSfPZZeJKCrEEnocgjyLLiDdK6dkdLQoomq18xiTfbzGMQbxC6ZgfxVlNZ2rt8WM1rLKstK4B+waGNuyTZ3+0k3nw652Khjm8dMJJmXnO0+uwFWJ7j9nh32Yk31PVybn1KI/Gea46ZGzeopzXmMV3Aa9p7hLGXPHxc/8CJItY3Yo2G1bzESjXvyoLi/cqc9aoYMHl4nS2IzwkEzA2tM84Nn6/ZYR1vvTM5x5tdGc4eb3M9SyzF2yTeJZlXjzH1CEU1rJdexHHDKHO90WrJhTsh3oKUMHCwsYFurd+Uxh5vnXjXRYdvJQicFCOJ5pH+budIsfhWcybexW01D3O4GlV4Vo65/8wWsMaqC6swboo3OxwqexRPkcNUvFtdeuaxvhzSk1Cft5VsnoQ1evUMoj/uSTT3OQpMneUCDT6zug27OSvirIRngHhH1rMxM1ZzFBT/dgDRG7+mlIBCBYo0aMPou0vk/kE68Z6XlkKGIA+gF+3Ybp5FxZttxCjC9qzyZ1lG/yQQ5e7R+9f1AryH1RzjFzuoTH0wMAq1OQbxjljNq6mvSTwSV7w50dy9pzbRWd5Av9pKa+RSrMcloiYa3yxzDVfDmLeKDFjNM9HfrePWb0yma786iU7b1xxXmmoYWJeDeLPiHe5Sx7GleGdBoX3xi/VxbeYMHO/A7NXGHqx3tXt2T7rgFajY7ghXqzat+51ZcBC8ZK7nkeMHxD2XjdTs+6J4CwLB6FFGdbWsdWvM6nFgijcuDtzvm6TdHBcdS/Fm5crFag47b1tnjNckVvOocDU9bEQHh3nYRor5Urx7F63ijbnobj3z4zlgLVPJ5oteIapfRTTnaQrUFs3gvmSos2kKAvMKV7Mlm2/MkNV89ccGaf70UQosIV5Xs23rOTcthYxcRXt7Oy1cuJA6O7W+5mIFq8IAk9MsKt5zE+zvBnjD3+HsSbZs0V124h1D8QbaSiKvu4UqPYm3muHNxLtPjbVRTnSONyveySaauyneg+uSV/j89XjbFW/Y2jPR482FGYR/ZQL4Pzn/0DFWgF+ycBt5h3bGCPHuVMdxhChm9r2HNouPVxh76eNcZk17EcVPV+3IeLCa3g4RNZ5NcxAAXMjoyALx/t+CTb7Xc4S5nijCIWgREOKdAdxxxx00evRoqqqqoqlTp9KMGTNiPn7Hjh30gx/8gIYMGUKVlZU0fvx4eumllygXMWjwMPW5b6jB6olK6zixAALW0O/pNkqMgRmZCDPBG39prHnJTLw7ip14s+Jd7ql4WyPFEu3xri5G4m1coFvDFe4KLY8USyjZnBXvJIgij8zasZJSwjpt3rQOtkYvetX4f0eg3oAJFCSwEQLcWiG4nzChHu9UrOa8niiCpOKW0Ym3Dot4zzNU7yIIVmtubqbzzz+fampqaPfdd6dVq4wxQT/84Q/pt7/9LRUldPU3BxTvOUkEZzEp6orZ420Sb0y+cLTmOIl3h0Z6UNj0EgswMxt9rjhdDOldFSHeCVjNQVzRtwyM7R8g8faY0Z2Sdd8WWGcS73aTeMNqHkp/j/e8DAWrBQ23Y9SpeKMt07JGl2bWGv3uoi3q+cB1Ectm7nQnfmFa/zM9c9or18EKqzNTzdm635Hh9dzY0KqKRDg3YDSd30LGHHNUHl4eXASFjqwS7yeeeIKuuOIKuv7662nWrFk0efJkOu6442jTpk2eFftjjjmGVqxYQU899ZSq3t977700bJhBcHMNITN5uC810nrzIpPWcWJAdV1qindXbKs5TpITzT7vhRtj9HmL4m2zRrf56PFeuU0bKRaLeDsV74oiIt7memBj6FaMZ8U7KYU2GWs0jwpEUnayAMHkxPKh5igxBquxWxcbn/uPIyoL9mLKx5zbevJIMfSf6km+/qz7yRBvbfRiKsUMi3g71rPvWEPRhHOiYU2kx7uAcdVVV9Fnn31Gb731lipwM44++mh1DaZiV7w5/TsHFO89htWlpCZG93jHTjQHGlqM93VHWYR4tISheLu/39eYIgJIJ/qNWfUDgfcbarnMDFYDcUlVNRygWcjdEs1TnZFsU7PN9eRzoSLepuLdHWONU8GO5sT7/3MFnj3emuJtU2hDmS16vbnQuEYdNSF6rxtLoeX//0yrs6WmKyMq1dwcz4aUeKDKnIvenuH1fMtcz72G947b2qETb15PTEhINswvn5BV4n377bfThRdeSOeeey5NmjSJ7r77blWVf+CBB1wfj/u3bdtGzz33HB1yyCFKKT/iiCMUYc9J1BjEuybURpu3mkpOOq3mOhlLUvE2ery9FW8A80Q5RMETQrzVhi5kVsi95njrI8UQCraeR4rFGidW1Ip3q0a8SzwVWliXXENygraas0KLTAV+TyYKKK+oVPcYTNTLkQI6cLfInPY0qbOseLtZ9xEcw4qSb9U7lfXkQkYqxQwkwLOa7XQQQPXTiXavYdHn0AIDrpd/+9vf6NBDD1WFUwbU76VLl1JRQp07zLVgVThNijfU3Vtenu+Zi4L7QUTxX+M30VxXE6Os5vocb2uGtzcpZMW7WyfeVEHNHe6K92rNZg6wQoXTCP+ueFiyuTGQYDWgf0CKt9eMZHsxo8serqb1eOs98uno70Z/cS+f/f+5AreeZJ14h5gohjKv0KLgzETxSxP9EW8mioy+uaJ4h+093pbiHarIis38Sz4LGYN7VVGFVvHPtHW/6Ig31OtPPvlEVd2tJ1NSor6ePn266888//zzdNBBBymr+aBBg2iPPfagm2++mbq6vHuN29raqKGhwfaRMVT2pPaQcSJp2mKqK0EAVzi3cWK2kWLJkQBUzyOKd2ziHTNgzUo1L2LibdqiI0Qx5LmB4hO6ZTfndE9X4l3v6PHuUZyKtwtRRMpuZVmCyeapWM2DIIpe/d3sfOg3LvJ1GoLAuEDhNu5OV719z0dnqzmKEqwmJqN4J7ueGBUGwoH3R5/R0d/Xe7qLIFht8+bNNHBg9EaoqQlkr/DVBU9YvdCdxjWVz7Vc9AwIj364kv7+9jK69NFPXBXhv79tFD9O2GMI9fOhEkWncMdQvNlG74d48zXb7PH2sppHEs2rretXnUm+eRZvPHCb2i4pjhKLUrxdRoklWshwD1dzjhMz1gavu7rUWP/OdBFv7u8e4t8NkXuKd7etndFJvKtNhTaTijfs4mibwDzp/WKMmcsl4h0pDnXHVrzDZrZQBtcTmU/vLTau30dNjG8zB6BuDzcD64qlvzurxHvLli2KMINA68DXGzZscP2ZZcuWKYs5fg593ddeey3ddtttdNNNN3n+nVtuuYXq6uqsjxEjzFE9mUAoRNtqx6qbZZvNIJ8ggMAtrmR7Kd5JWs27u7upvz7H2wUcsLZgvSjeMaElkrdD8Y6xyeWxClayuR6uxgNKGS0eincxpJpzz3wYPfPuFyYridsvUUzFas6KN7A9SWv0kje8ibfe552mIDArXM3j+OSANd+KN0aiQU3EmCa9MJFIC01Q6+n2mrjPuwj6u4H99tuPXnzxRetrJtv33XefKmQXLfTALFUkNc+zAY80+njFNiuQ9OlZ9gI8LMTPf2bMvL34CGOvkHK4mtWP7M9qbqnUfM2OE67GwWrDNRLCva5bd7YnlGiearAaMDCwHm//48TYGtujspRqy4zHt4fTS7zzzWbutaYobHAYGBcyWKFtz2AYGNvMD921vxp95Qd9asoVUY98nRuKd7tjnFilZTXPnINg5ort1NTepSzmeyQQEjlSO4/whIRCR1LEe/Xq1bRmTeQCgkC0yy+/nO655x5KJ0AKUbnH35kyZQqdccYZdPXVVyuLeqz+tvr6eusDzz2TaOpjKCq9dpg9nEGAN6cI89AulkGEq0FNreSwEA/iPd4k3hsaWqm+2cNaJsTbUrxhA+oOlcbsXYkKWOMeb2wGNeXc9n9bjKnmpirVFsNBwArt4oSt0Qkq3lBzdWdJMgot1O4lrxt28j1Pd3+MjSimT/H2Ws9dE1W8MV3BzLdI2G6eqoOgbSfRh3cat/c6w8d6Fn6iOVxhv/rVr+jSSy9VieZ//vOf6dhjj6UHH3yQfvOb31DRwiKoXda0BPu5Nxg768yVkXPEn99YTK2ahfu+d5epTfTBu/RTfZGJgMdmRY8Tc5njHSP4i4l3qKKHbZxYS5we7xGm4q1bRP0q3lzES3WUGKtkXF9DyniyiBQy3Hq8eU07VKo7E+/ayjKqLTX+P9uYTOZ5onmQcHMR4D3RydTDTN7nPvmODM6dfnNBYjZzLlpynzfQr0eGibdHoCIr3iEzXK0ynHnizTbzoyYMSKhPe6ROvDO8nnlFvM866yx688031W2o0wg8A/kGCb7hhht8/Y7+/ftTaWkpbdxoV5nw9eDB7jH0SDJHijl+jrHbbrup5wDruhuQfN6rVy/bRybRPcjY5A1qNsORgoBlM+8TrehYVvPkiHdZs0E+doZ6eIY4oc8IfcnAgg0NwaaaYyzTqo+o0BLNY6nd9pFizdGbP+dIMafibYWrZbCNIus93t5rOs5UaH0r3mw1h2MgkUKRKoCFUyOKb//B+LznN4j6afOmdZjnEKrsRVQXvGMH1j+gNI7ivXhjBpLNU7Waz3zAcCH0GWOsqRt0lbvAg9UA9HYjXA2ke88996TXXntNFbDR0oUCdtFC74U2QzDV1IAAx0JB2d3R3EFV5SVq5jOSvB/7aJU19/rxGYYQcMkRHu99P+OvolLNS12s5mUxRyqpH6vq4UvxjljNa6KUv21N8Xu8UShgZ1cQVnOQkW/tP4IO2bUfjTWvo8mACxmxFe9Oauvsth6jiHdZd9qIN4o0S0x3QKEo3kaPt+Y20drp2igzRHFzYxt9tsZwdh7pI31bx0ibNboyt3q8zfd7uUm8W0KZL2QclUAhw0m8M50Sn1fEe86cOXTAAQeo208++aTqtf7ggw/oscceo4ceesjX76ioqFAX/WnTptkUbXztZX9DoNqSJUvU4xiLFi1ShBy/LxdRMdwYZzO6c2n6R4nZrObJ9XiXtRjEu740duAQ280XepGbZBRvWEufOo/o8TOj7dV5PsM7XgWQx1SsZKs5Nn+sXGiWdbviXedQvAvfah7mHu+wd/plwoo31o/tpYkQRZ0kJpPCvf5zooWwAIeIDvuZ9+PGHkE0+Syio//P3TqdxjnezmRzDhVKW7J501b7eiZyHkA6/Ad/MW4f/jNvsoH/7y9dSzT1koLv8e7o6KDzzjtPKTWYAIIC+bx58+jRRx9VJLyoYSnDsJpzf3ewieY8I3ifEX3ox182shrufHOJUkwfmb5SjeWCknnYONMhkmJitN1C7zfV3HhMmUa8kaHhRryhVnLCNsK+GH1r/fd4I5wN9ngUI7iAnypuOXUveuyCA1OaO+25no4eb326Q21FmdXjnQ7iDWcAzs+wOKdio88W3NYUt7ssxRtFL+N46g6HqD1NffJOvL3I2OfuMawXDUxwXXmvlg1rdKlHrkO7pXibVnPu8abMPD84NdFKg8LAoQmey0ZoxDvT1v1soSTZizmUZOCNN96gk046Sd2eOHEirV+/3vfvwSgxbAYefvhhmj9/vrLCIfAFKefA2WefraziDHwfqeY//vGPFeFG3xpsdAhby1X0HrO3OqEMpO3UusO9dz2wUWK6Cpqk1byilYl37LCJuMnmyRDvHYYSoBSrVMYz5QrMzRyIN1cqvTCGibdtpJhHsnlL8VrNw+2RcDWvNdV7kn0lm4PMcltFInZzZ/9yosfsO6bavcdpRAPGez8Om75T7iLa/3xKB7hF1Evxho2UR4OkNdkcaeRtZr4EOz0S+f/45CHj8b1HedvMGSDmx/8uLYWMXEJ5eTk9/fTT2X4auR+uxop3wP3dM83+7v1H96HTpwxXzqatTe10x5tL6OHpxvni4iN2SSrkrtwMuYg6x+mvK47VHLZptppX1Bjnzc5QBXVTiSoKOLGxsVWRZhAAnQiy8uenx5vPIZjfnUujgyIJ3N0x8wC4+FhdXqrWobrEWKfW7uCJN/fTg+zlYxCi25rCYWUlwGtFLyTpd/qbRheczdxn+rYXUcy0Ndq7x9sMVzOJd3k3uy0rM9ovv//ovgkn74/qlz3rfl4Rb4whQV/1u+++S6+//jp95StfUfevW7eO+vVDsI4/oEf71ltvpeuuu4723ntvmj17Nr3yyitW4NqqVatsRB7BaK+++ip9/PHHtNdee9GPfvQjRcKvvPJKylX06tWbVpJhnd+x7JP0jhILIFytvNmf4h032TyZVHN9k73hc/fHbFtmbLDdZm3mqOINdTae1Xxo7yoqL3WOFKuOtprjd7I6Y4Wr9SiacLXuzgjx9tq04cKIZHNYArkfMS3WaA5WqxsZKRz5TfHeOJdo/vOG2g0SmEVYc7w9Us2TchFYSfGbEm+hQb97z6GJFTNQnHr/T8btw34aqF043/H1r39djRQTkIcluyt9ivdK45ieMrqvUmOvOMYosN311lLa1tSuVOMT9nBvrfNrNY/qSXZNNXdXEkGuOZytosawMneWGoTabY736m0t1vVKV5cTUbw5WC2IUWJBwtO671hTvb8bYMW7pSt44r2+3ljvoJwBuTbHW733TGEB7Q1RM+nTALxf3jEV7yMTtEVnOwyMR6h2OQIV282iT8jcf1Sw1TxDxNvq7/aZZq6DxxIWk+KdlK/jd7/7HZ1yyin0hz/8gb73ve9Zc7Qx7ost6H5x2WWXqQ83vPXWW1H3wYb+4YcfUr4AVcoV5WNpTOd6alvzGdG+Jwbb4+1EiuFqla2GitdYFlvxZlVxmXkRDUTx1hVE2HAnnRz9mBcuJ1r+tmGzn2Q4LfKhxzteZR+bmKG9q2nl1mbVQ6cutBbx1hRvq6ASIqqsKzrFm9q1Od4exQxc7NE7iPmnizbutFnDAk02Z6s5wroa1xvV+4a1RL1NIu5H7cYxjlndWQRvimIVh8YP6kHTl21NIil+U+Lvf7y3+44lalxnEO8RPq4psx4x/u/QAz/5TP9/swgwbtw4lb3y/vvvq/au2lr7+wEFbCr2VHMk8AeseG+ob1VEFaf+fUcaRdIT9xyiSDfPZr7osLFJ26PdZiRHFRRY8fawmrPajXNmRbWTeHfFCFazj1WK9Hj7IN5m8W7XAPq7g0SZl4MA4EKeUryNdelZZRw/VSFWvIMfErTOtPUjHyAf4bamBvEu0Xq8m61relRCf4oEe9r8jfTC5+vVyLnvHTxaOU4+WbmdGts6VSjf5AQDDQHOEehdU07VFekJ1Eu8x9u0mnfbFW+saVCAOwZr9++Za6i9q5vOPGCkcvKgePfRsm0JB9UxUMDC8b2+vlUV9IoBSRHvI488Uo0Dw0zsPn0i5O+iiy6imppgZ2AWAjbWjCdqeJ9KNnqouInCCtdyI96pKd4Vbf6IN9tttjd3UGNrB/V02ksqapIg3ptiK944Sa+eYdzevICITsqbHu94VnPezDDxPnBsP3erudXf3QtNuZHQLVa8UTF2m7NVIOjmizRcBDHWdNwgg3gv3tRIx0xyn0dvQ1JW862RfmaQ7W1LjZyCeMR70wKiuaYCefjPKduwFO8Y67krB6yl02rOhQwkomP+9sr3/I0Ug034vT8atw/9CVFZcVTN/eL++++n3r170yeffKI+nIXh4iXeuiXbnBxRHtzGb6apdk8c3Mu6PqIA+/OvTKBzH/yY+veooG/sNyL4udN67zr3eHtYzRtaOq151CHTOdVVahR83eZ4s+LNM7yd83f9KN4cFrbLwNQTzdOlzoJk2Kzd2rHCVvPaSoN0VZYYXzd3pYF41xsEakihKd48ek3r8cY13TVRPkGs2tpMj3+8ip6cuYa27IxMhEFrxzG7DbKe05HjB8S85sXa+972jck0QBtjl8256Po4MdXj3dVJpablvCWc+nPc0dxOz8xaS/+ascp2/X/207U0eXgdTRnVVxFxuHeSDUv80xl7qx7xXQeaIlKBIyni3dLSok5MTLpXrlxJzz77rEoYP+6444J+jnmPht67ETUQ9dg+P/093mw1R5o4eiYT3IRWmYr3zrLYLQOYZYjADxBvXIwnDXUS7x7uidy+reZfRH9/45yIJTAfesAtxdvbFq2Dw2oQPqPAirdevGitt/8/A9oYGEW+QcoLFR2RVHOvudNJJXEnZTU3iWKNSRQV8V5BNOYw759BQezlXxhp6BO/ap/RnSV0mQFmMdcz0ZFiltU8iZ55Xk8/73MESP3vRsNx0GsY0T7f8f/3igTLly/P9lPITegElXu8udgZ0FxbAKqQjqMmDKQHz92fhveupqry0tSt0SlYzVnxBvFml1p3WbWn4r3aS/Gu9ad4o8jHincQieZBAq1eOjnk9XWOE7Os5hXGfZUhY/2bOoMn3utNxXtYniqBvIZ6GBiuN5FxYpFUc9XjnaLi/fGKbfStez60FHZkk5y27zCVKzBtwSZ6bV7E0ZaMzZxx2pThlM1j1OnKaOsORRRvbTRiczi1liucH4669S21z+dcg69NHqIs70/PWqOS4TkdHue1ZHMIpo7tpz6KBUkR75NPPplOPfVUuuSSS2jHjh00depUFeICFfz2229XIWiCCDr670G0iqiueaVBopyzt4O0mnPSNaujHrO4vVDFind5bMWbe122N9eri3HUqAvLar7TSCb284bUN+nYSONrTkcGVn8cuZ0XxNtUvMPxx4np41nWmONalHK69hND3Z94gvsoMQBj31CRx0UMdvNCJt5aMSOmQmv1JCdqjd6YBFHsR9RnVPzjcumbRP/5gWFHx//XkbmRTeFH8eYRbQj7Qe9njbnpDNa6vzVSUPSznluXEj17CdEa0wVzxC88RyAKDKBgDuRjUFPgsMgUeryDD1djxXu/0dHXUmxS02U7tSv5/qzmvUC8h+6jCrrbBx1EtMld8bas5lqfqz4GKB7xfn3+Rmpo7VSFex6hmSvQz39Y07JS93FirHjjNQAVIePrpnQo3jtMxbsuPxVvt3YIW483Cqdaj3eqivenq7ar3w87+C++MoG+vNsga0zckk2NdN+7y5V626u6jI4Yn3g/crbBPd76euKczuPEQlohA2jtTo14I48BpLu2opSuPH4inbzPMCs87afHjqd/TF9Jj0xfod7TJ+89LKW/VUxI6kwxa9YsOuwwQ9V56qmnVBgaVO9HHnmE/vIXc5yLwEKvAcNoc7iOSqBybZwX/wfiBTTFGieG/i7u/U3Cbl7Vbmx+m30Q7+HmxZfnetrAygF650wCGhdOm++Gz+xfr9GI97Y8UHHME6Ca4+1L8TbXkwPBhpkzdkG+o6zmGvHGJpoD1gq8zztszfGuUL2TXtCTza2U+KCt5kwU2RrtRRQx5uqlXxD94+sG6Ub/8rkvGb3hOQBWvGO1msJKCmus72RztppjjbC5CnI98Xw/vo/o7kMN0o1Wi6/fTbTv9/z9nSIErs0YH1ZdXa0+EE76j3/8g4oaujLMzqyAwtWgis5bZ/Rx7+dQvIPun40KpLL1eMe2mlvEG/3KdcOJfrGMVk75lbqvuSP6fcujxIY5rOaseEMlx+xpN4Ag/GXaYnX7nINHp6T2p3M9XYsZLuPEOFyt3Ozx3hmw4g0nw6ZGtprnp+JtEUWH1bzLClezW81dg+0SAM+RP2LCAPrKHkMs0g3Axvzb0/aij685mqZdcaTh8iiAuei4aRUywl3Wuaw5XEkdKY7l3W4W0sYO6EHfPWi0LbEcboKfHDOepl/1ZZp+1Zdoyqj0nOcKEUmdKZqbm6lnT2Nj+9prryn1u6SkhA488EBFwAV2DK6rprndo2OndTO2LCb67SiiaTcmZzV3GymGBOW/Ton9O4HuLqpqN0h9U0V82wfbzVyJt67q++3z5n5QWEY5YE0HK1sAgpfYHpjzPd6x1VkG981xH12EeM+KPMhN8dYD1go82TxkXqTbQ5UxVTu4MSrKSqi1A8nmjnFsQaeaK8V7tPssb2x+HzqRaMbfja/3v4Dokvf8BYZlCHwR501SXBeBH/s+1gTp5Cg28jolYzVHoQItMzpeuZLoxZ8aG4wxhxNd+gHR3mcW/GiwZMEutBNOOIGefPJJ9YFJJHCs/fGPZm98sYerBTxODMob3lY4p6dLrfQOV9Ot5h3+rebqZ0utwCg3qzmPC0NYlY6elWXW8/Hq80by8dx1DVRTUUrnHzqGcg36NdqZGm0fJ9ZlI94VZCrenYmff1CMYHLtxMbGNnUMVZSWUH9zXFu+wc2VgUJ4h0W87eFqrqPckiCKsdLGcazX1eQf6faei95tEe9QwNZ9drBwhoMbUEAb2DM/C0N5Rbx33XVXNZ5k9erVarzXscceq+7ftGkT9epVwDbXJIF5l/PCo7x7l3Use4uovdH4HE/x1lVPr4A12LX/+S2irUuIPrwrtvrctIVKqJu6wiFqLe/je6yC1ZPsrLqbvWK+ySBvvHf9cnSRAq+D1S/eHPHc7zxINfeleJuFDMxKbevsIhoy2SAvKDI0rHMo3lpLgR6w1maoLAULc03b46R1crI5sGBDQ3pTuGMptHArrJtl9OF/52miE29LvdUkXcQ7DnFlF8FCP33eeP+DfCdiN9fD1dAjrlwzYaL61ZHHgCB98rBx+5gbib77H6LeyQdUFQP++te/0l133aWmkZx00knq4/e//z3deeedxe1Q0y3ZAY8T+9jq747vHEs1XC0qCVovKMQNV3MQb9S9TOLttJpDyWYy7pxfjCJorD5vXe0++6DR1mNzCXoAapSLQJuN3mSOWethhquVhY01bOxIfDv952mL6YDfTKPX5m7wTDQfXFeVU/POEwGPqOzSCHWnTfG2jxNrT5UomkWfTM/XznzPvF7IIGsuuhonFqB1n4tosYi3IEPEG3O3f/azn9Ho0aPV+DCM+GL1e5999knmVxY0cOKc120Q7+54xJs37rEIFH/PSb4YTMh3biB64ttE9asigWurpnv/XnODvI16UYlHhdw1DMxN8daTzf0ErMGOywR9ly9HK95sMx8wkajfuPzo89Z7vH1cOGHlRXgF3EGqtwsEbeAku+rNirez6FJRHFZzi3iH4l8I9hpmvD9mrdrhn3jjPeLHoYH/JEvx7k/Ue1TEqt6mFZqWvGF8HncM0a5HUy6CL+LxwvD35PVcaRb+gk4255R4pZaHImu6XWsrWfWBQZJ6DiE6+IcFneAfFNavX08HH3xw1P24D98rWuiW7IAV75kruL+7TwaClrxJokW84/R4uxFvp+K91STU+LtQuJ1gldGNeL+zeIsKYaoqL6ELDss9tRsAueXLtGdSfFe01bzMVLx3diROjj9YYpzzPjTHMRXSKDEvxRutTZbirY0Ta4HVPEWiaCm0BToPmveROqHGena5hNUZKfGpFTL4PV8s87UzhaR2LaeffjqtWrWKZs6cqRRvxpe//OXitq55AMEjC0NjIrbvWD3cTCZbPYg3NggcmOIVosWK9xu/Jlr9kdHzPdpMWl78uvffNtW+zeHeCSm06Enm0J6kZ3lzb21pJdHoQ43bSIlmIsnEe/j+/oKXck3x9mGDhWoQsZtzn/e+9j7v1jhWc530FSBC5ga5wwfx3n+MoTbNWO7D6ozCBTs0/KjeSJdnGyeIIv4/uBiiOzGYeOco6Qa6rR7v2MfoAeZ6frZmh2cfZ0rJ5lZKvKmUWy4Czb6/ZFrEFSPWct8ONdjLnXjiiSfUjO+ihZ5qHqDijU3xp2axb79RfdO/CfciiXCL8Jg0j0K6m+JdbQYnOhXvbTsj6pdbmw+rYk7ijb3Bn99YpG5/Z+oo1Ruaq4j0zXsF1nXQzlZ7uBqPbqpPgnhz+CdCrJzAXGNgWJ6OEvOa4w2reacZBma4TVothTbVHm+2mueioyIIlLvNRe/SrfsRxVtZ951FuWSt+7X5ac0vqFRzYPDgwepjzZo16uvhw4cr9VvgXklt7TGSmlorqRYXeNi+B0xwfzCHhnkp3tb9IaIKj5l3TACwkQ2VEn3zIUMpXfGuQQSO+01MxRtBcHrQiBeG9q5We1/00W7e2Rbd58Eq7MwHDfUXfa1cjfci3tisw2rac6hhsUahYuSBduK9ZVGeEW9/48Q4YA2zEm0Ba7MeiRBvL8XbIt6FrXiHuswe75L4m7epJlH8Ym292kRy76L7Lw4ZCfogzSDefeOoMqx24xjn2b8giutnG8floEmGgstOBXZx5CD8Ws3RWjKoVyVtbGij2at3GLPmg0w218PVADf7fh4UMnINv/71r+mMM86gd955hw455BB13/vvv0/Tpk1zJeRFA10ZDlDxRqhaS0eXCiwbZ+YipAPWHO+ocWLaeY4TjuOFq+mKtxl6htm8+N38d7Y2GSS+r0e/sTXL20G8P1i6VbmOKstK6KLDx1KuW3lRb4jq8ebCBVLNu+2Kd6lZgG3pKlEtYpW2OHRvbN3ZZo1pWrZlp7finafBal6KN25bYWC6Qkupz/Fmqzmn7BcaXOeiQ/EOuzgIAunx7oj5nhdkUPHu7u6mG264gerq6mjUqFHqo3fv3nTjjTeq7wmiMah3LS0IjzS+8LKbQ3niTSbePG5pwEysQLS8yLE+Zuz43xHt8iWiXY4y+oUxmsqrN5qJN/lTvBFeNbTOEQimo98uxufZjxI9dALR78cSPfk9ovq13sSbx4cN2StiN8c6MIEBefc74zeHFG+9fywWRngFrK371Gjm8VS8i8NqHjLXtDMU/0IA9wDyFWC3+nT19mCt0XqwGsPpxFj2pqE6DdqDqNcQylVErOaxj1GoXNyzOmN5tDUypaR4HNtWaGR/9/Xcsdo4f+E8NvbI+L9ToHDaaafRRx99RP3791fZLPjA7RkzZtApp5xCRQu9FzpAxRuzhHmMWDp7c8tdEo7tirdGvBOwmusFymbN2cJKthep6WOqYttMMqn3MQNnHjCSBvbKbRIZcRE4ixmRIo3Tal5i9ni3h8us4DU/QIGdgQBQp4so30eJ2Xq8nYq3TaE1w9XCqRFFFIn4eC5Uxdutxxu3WfFWc7y5xzscZI+3KN5ZJ95XX301/e1vf6Pf/va39Omnn6qPm2++WYW4XHvttYE+wULBIK3Pm9Y7xmTpYU3oMWW4qd6wuOoKpxtUYnKI6MAfEB1wYYSMj5ga225uWc3rfBFvgK3RPN/ThlP+TnTqvUR7ftMgKHg9854jmvlAbMUb4FFLGCm2aZ6xLggQ6z+BqM+YvCLeuKAkongDluI9YDcjZAprt3VxDMXbbDtAMF8xEG8fijeIItujfRHFRJLN9WA1hrMgZKmzuat2A3wN91Mcmpqu9URBCaNQXK3m5nounRZxvejFRUFcTJkyhR599FH65JNP1AduF30ei2U113q8AyDeM81gtXSP14n0e8Yi3uZ1xMNp1tAaTbyhTPOpQLebx0s45r5aXfH+bPUOda5AMvclR5iF+Dwb1+QcJ+YMVwuZffQIuGo01zNR4g3NZeVW+x5qfX1LAVjNOXnf2ZOsK7SRFO5UiOKOlg61jkDvPBwVlpjira2nHlanxok1BecgkB7v3CHeDz/8MN13331qRAnmgeLj+9//Pt1777300EMPBf8sCwBDelXR3PDo2Iq3HiLkRbz5PiZabph4ItFVq4m+crP9frZnMiHwULy3JEC8mSiuclw0rB7vvb5JdNq9RD9bQnToFd6EmTfnvFkfrCnebDOH+guVn23A+D0pzinMzDgx9Hj7+5HhZt/8Gu7xhsVtyN7GbdjNufDi2eNdwMQ7HLaIN8aJ+QH3ebMKFRPstvBDFK1+ZBfijZFiuDBa/ci5bYvmi3iJj55pXs9Zq7bHv6gnYjXnQgbyKMrMi7xzRJvYzJPCSy+9ZMtiYeC+l19+mYoW+tgtVrxTtJqjn3nmSuNcw0W/dIFnFEcr3hrp4IJCqX/FGwXLGrPPWw9Y2xqHeLulmr80xwjvO3b3QSpkNtcRse97rKk2TqxHZeS+CPF2cSl6YIljOsQyR593IVjNXa3RHuPEjBTu5PdzXPDBscz/j4UGt8IQChmWg0DbAwbRM+9nnJggcSR1dG7bto0mTpwYdT/uw/cEsZPNFfF2I4xOQuoWsMb3eQWrMdwUcSQrA8vedh8rpoWr+bdGOxRaL4Aws31cHw/kpSDyYzfNJ1r5gfnHzAyBOowPChmVPT821pywmvt7q1lJ8fqINj1grbWIU8272ikE67ZPxVtXaGet3OGDKCZgNbdmTutWc02h3fiF8XvKa4lGHEi5DC6e+ym2jR/YU21ssCHHTN7ArOZWIUMjK5xqjmITAtpw3soDB0Gu4corr6Suri5XkojvFS30cDW2ZKeoeK/Y2kxbdrYrhZenAKTbdhp1XlPXGo7nTtxqDkRmeXdGhat5Wc2d4Wo4vl6dY4zJOn6P3G21ce9JdibFl7lYzVm1NV5vO5VZ30tE8YbDAFi2JeJ2hNOA+7/z2WruShRt48Qi+QqphoHFa4UoBJS6hP/ZrPvaHjDVVHPdui/EOweI9+TJk5XV3AncB/Vb4E68F4ZHGLH/2GQ2ro9PvN1IlB/F2/NJ7GWQC6+xYlaPt3/Fe2S/GD3eTvQ2e9zdesyZ7PBmHZtujEvDpmjBfyMWUwCKWN3w3Leba4q336lH7CDARaSJL+Lc573qo8jINafVthhSzXlzrFLN/RHvXQf0oN415SrsaM5a0y0QN4U7gR7vWo14W+OvVkbaOcYeEVFwcxSomAN+3vNomdjfHJH0cTy7eSJWc2ewGo8j5N/xxb+Ncx8KHUOK3CKdIBYvXkyTJpljCR2F8iVLllDRQiNT1rklRcWbnTWTR9RRlRlSlsngqqiighWuFk28EQSGYFSgV5X9+26zvC3F22NGshWuZvaFLtzYqAoRyII5coJ5bs1DhTZa8banmiereDPxPmxc/6hkc7aZ428gpC9fYTkIHOFqkXFindo4sRQVb/O4K9T+brt13yOsThPnjHC11Kz7AIxwzsKcIAvE+/e//z098MAD6mJ+/vnnqw/chs381ltvTfEpFSYwixHp1itDw6JnVDsTzWNazRv9Kd5uwDuIbZpufd4m+d2EcWKhgBVvoM4k3o0bohV3Z483/j7bzU3l2CKgQD4ErLHi7XOON2+A+CRnSzYHoKIynIWXYghXM4+Z7nCIuj0UHHei6LMv2bJGJxKuphFFODEQ/AWV6bN/5Y06a4Wr+XzPs4X2I7/ribVyC4p0dRBo66m/z2feb3xGUKTM7k4ICEFdtmxZ1P0g3bW15sjHog5Xi4w0SlXxjszvTq/NPOboK5/Em9UsvO17OshdtVk00K3m28xUc89wNccc71dMtfvwcQOsILJch6d931y/cHeHtSbWazIV744wFG9/Pd71zR20udFYz2MnDVafl25ucglWq3Id3ZbPijcUWiuFWyt6taZIFIth5jS7XJzWfVfFO0Wr+bYisO5nC0mt5hFHHEGLFi1Siag7duxQH6eeeirNnTuX/vGPfwT/LAsAg0270BddbDf/PDWreaxwtVjwIt6w+5j9wypczWdTMiu06EeKa+WFmqVmJYeJ6o0xdBZ2Oog3wMQb6DfObkMNcpY3LNxv/z540mpaqFSPdwJkwbKbs4sAToH/b+884KOotj9+Uja9kYQkBELvvSMCKoJi74o+xPpQURSff30+ffbysOuzPHii2BV7f1YEBUWqICi9hhJSIJ30/X/Onbmzs5PdzZbZnbkz5/v5xGwKyeY6O/eec37nd9QBCY6R085ltYO5WpNrgw5kIxjd1c8+72Ck5uoKLVa202QlBo4MNPkYMX4I4vjbXsITGdjLqv73rcDqNCYi8PXOpeTe4F9XKwjUgTdfT+rvDpizzz4bbr75ZtixY4db0P1///d/cNZZZ4FtUfd46zROjBurcVVIRA7hnvZdHmj7cDWvPColw1LjY1uZf/KKt3vg3eDfOLHaBiYz54H3KQOlwFIEXIZ1nke0OeXqtlLxRrWQHHhj8MNnfLfF9hJpn85PT4DBBelKjzeuG3JArnh3ENhYzasZmFPb462PuZodZk7z9WxWrWeL0wktEA0tvL1ELtgddcZBQ1Po0n2SmetP0GmM/Px8ePjhh+HDDz9kbw899BAcOXIEXn5ZrkwQbuSkxrPM8u/NXb07m/MgMq1jaOZqvuBjxUq3uEu+5WCjKcoBlZDs9yG8fUo861HC8/dBOUvrFVyAjALPcnNtxVvtbK7u79az4o1utj8+DvDSSQCLHwZYvxDCNcfbX3M1pFOGrCLgBmu4bupqv9ZYzS7makovGEr3/V9QXqFdtfuI70CRV2grD7pGW7XZk6wNFOWEEJLVs+154Aajzoj7u6YDO6azilh5baObM28r8LDKX8+HNvr+oTjz3ON6yq9zDla8iYAValjZRml5t27d2Bs+zsrKsrdCTTUiSo9xYljB5H26IzpHsOLtSZ7LZ3n7mOOt9HcntQ5UuLna0cYmv83V+OdRLoz+D5uLqligMLmffF8VAK+u5vK14myS1gz/LtabjWcI2XcEe7wr/Qy8tx2S7ps9c1Oha1Yy2+JRpo7+AAg/S3UU2FjNmzS62cs4MSY1D6lCa/2Z055ULnxtlTVVzNVC65lXEhkWVhAYBekHIihhyk6Jh40t3TwH3rhBVh2QHncY0vY4sWCk5rw3uNPo1lVvWV5bGYMHhii/Zad4WOcjxfySm/M+b7XBGkr9uHSXBz9qgzWk00j3nxPqSDGsuL92JsDih1xjjLyNeQtRGo0mF/5KzdUVb5ztqaAOvLXGanYxV1NVvP1thUAG5KexCg4eNLcW+1gfvKZyBwE01wMseSRwqbk28BagOovZco6/1yjey4Z3ka7BlW2pCPqdKb1f9IDLxS3Y9cT7ovr+QPgtNf/ll1/gyy+/ZNNHsNK9ePFi+OGHHyAjw8O9xC5Eq6tuoVe818hu5n1yUz0Gs+GTnbZ4r+bzhIJWIcUq3o0e+7vdzdWkvRErZ7x/2ZvUHHvaeaX87ZVSYn1s9yzIEOjg7knKqx0nhiTHxUgScLnazXu8/TVX4wnLXjkpbN34yDDubK44mgtsrObNDMzNXA0VBHzsaohSc94KYY+Kt7PVHq6sqRw3SOvpDF26TxVv3aHAO4Jgv86fzi6uwJNXedQVYKxkK26+vireITim9vIwVkw2VquMlSRy/la83UaK8QptoAZrR/HAgjeIKIBEVaUgu7fkCs1+yTH6Bd74d889FmDPz1LAOuhC6fM4LzxMruaBBd4e+ub9rngbYK629nWAOZ0BXjgG4P0rAX56HGDLV4rpjO4V7wDmoiMoS+czdX32eeNBasrD0uNVLwGUbPH+vfy1600aLUjgrd7AA0lmjO6a5V/f/Al3SPc0TGrxvnefUnMvPd6CrKeZWL58OXzxhWRMiUHCySefDDk5OazKff7558M111wD9fUeplvYBSWYatal4o2KGmRUt8jMmA/IXM2D1Nybo7knczVuXIX7mC+jJd5f++lv+9n7KQLJzN0CRW/jxFiFW22spgm86wILvHvmSAnz7u2l91wxoUjNBRjBFoyruUtqrjJXw57kEALFw7ILvKV7vL0oCDxXvNGsjireZoQC7wiSm5YAVZAElUly8FmkqrDyABIrPLyaXR/CODFf9DpZer/jB9dMcTnwroiWDg0xAfTQKgZr/gTebBQYBt6qijc3s0KZqTozjwejCxYAnPEMQG5/zwfyygOuaoW/fP43STmQPxzg2p8Ajvu7a3RZCNIcn3O8Awm8Pa0nHymGoNu7t8AbD5B6B7xtse4dgPoKgJJNAH98BPDDQwDvXAyw6H59f498OGbS/QDvXH4brKELeZ/TJBXEt3d5/h48zOJkAI8VWjkhFBMP0GUcmB3uaI4E4lnGgwt0Nud9iR7BQPq4W11Vb2+JobbM1RAKvAPigQceYL4rnA0bNsCMGTPgpJNOYmPEPv/8c5gzZw7YFk893iEE3txYjd9rDJs57RZ417YtNfcRePOKd5ksgW6X5LvNh8vNaxqapTxmf9k3Q7hA0cs4MXlvdRmrufZaDCar6hoDmuGNFW+ke3ayW8X7YAWXmote8fZsBsam+2h6vNn4qxCk5q4e7zhbVbz52ioVbzlGwPUMyVyt1vcUAyJ4ArKaRAM1X6DJGuEdnr08kNgb0mr3SlUg3rPIHc3xoMn7tz2OE6sKrcebm5Z1nQCweynAG+cBXP2NEvxWMKl5YBXvzkqFNsiRYp76uzl9TvH8c9BoDU3G0EwMf1b73v49WVy/Cvl3T/9Ikt6j1B0DJTykHNkFkNUD9K54+yvd10rNMahhkjb8ezGow+fnq+LNfmGVuxFdOMGg65B8uD/9SYCGGqmFAa8tTGToiWreZyDVWXWfNwbeypp64+SHpL9h27eSOkIb8PEgEQ+zWpPDruMBUvIkiTWOwzI56p73QNZ0WEE7cMREQVFlHTMB7Jzl428dcx3A6gVScvHnfwOc+E//xrMhqfkAncdKlSU+TpDwi3Xr1sGDDz6ofLxw4UIYPXo0zJ8/n31cUFAA9957L9x3331gb1dzlLvycWLBBTo473qjPNc+Eo7mPmdOuwXedV6l5ujR4C3wTnTEugXe/hotqWWpwwoyICdNrIqtVxWBXPGOwiSNOvCWpefNUfhxlF9Sc/yeA3JgzSvePdrzwLuG7U+K1FzwwBv3CG0iQzJX460Q9YpqgJmrkRlYwO0litQcr0GnylyNKt6mJTrQXjFfb126dIHLLrssfM/WArO8ke0xPVr3FCsV726uarZPqXmQruYIHrCnvin1s6Kp2hvnKpXvcl7xDiJQ9Kvi7THwlgOZlABmfeLzC8Zg7fBOV2WNz8LGQ0n7PvrLzXnF2+kIKJHRSa544wbND0dufe6eerxRHcD7E/ms70iA/x+x2o0Hk2GXAYybLb2pVBT6V7wDUxAgQwsy2CGguKq+7ZYITLyMvkZ6/M0/W4/CUhuraV8nqXkAt24BOF0M0yo3qXkAa4o9oIM6pvvX5x0bD3CSHAD+8qy72gXBg4NS8dYE3liGv+prgBk/eByJRHgHzU5zc10Vxx9//BFOPfVU5eNRo0ZBYaHm/4WdUMuxnfIB1RFcoLhubzl7LaFLdaSqlC5Xcx8Vb/SrYB+3fu1sPCD5xXSTq62epebSva9M6Z/1fQhX93+L5GauXVNv48SinbgfO1tJzZ3R0t/tzxzvHbLMvH1qvNL/3kOWmuMsb3Sb5wkP0aXmnqT70jgxOfTgY/y41DwExaEtAm8vPfPsPbivqeQS7/StSPMB9XibpOL9yiuvhO+Z2IA8Ofu7oaULnOE18O6q6tcNk9QcwarppR8CLDhZ+t3y7z/CA+8gAsWAAm80ksNKA25ofHyTp4q3L1CWj7OtAwm8y+SROtqqdu5AacQbVm+5IVQo4M1OJY0OpCcZzVZwU0aXXOzzVm58GAziDHTek64F+9XxphtJgzVe7W7fVxqnFeg87CB7vAMNvHFNh3TKgNV7jrD5012y2phffPxtUk9yyWaAta8CjPpr20ZgAuKa4S31AQfC6G5ZsHZvOazcVQYXjJDHqHkDX1NdxgPsWSa1IJz/kutrqJLgAYIF1tQsYNC9a9cuVtluaGiAtWvXwv33u9o/qqqqwOGwcTKDB6fq+2WQFW+efIpUtdvvOd4cjdQcgx8+XnGUrAbyZa7Gg5qsNhyj1f21UwbkCRsoYsDibT1joEUVeEuJcaccmPsTeKuN1Ti8xxtVg3sO1yhJDNy3RMaTggAfKxVvFZhQb7XufoJeBEcbmy0fKCqtEB56vJs1a4rnJP51nlAKBO7r4M1MkQge6vE2oOK94miBq/rKXcpRQozg+CGfUvMQx4mpSc0FmP4xQLLLKfhwtFRNDeSFys3AMENW05bUCn8XyrqxwlC5XyM1D9CxOKiKtxx4Z2oD7/7ugWSoqExXcPxVoNLognaaWd7sk6MBrvgCIH+o539kxEgxPiYqd4CHedglihmN3q7mgUj3OSPk2brrC/1oiUE1BBqDIYv/5b6m3ozVBIT3eAeayEBGyoZ16wvle5gvFOO6KIAN7wPsX9NaQYCKjbg2EiKE35x22mmsl3vp0qVwxx13QFJSEkyYMEH5+u+//w49eujUViN04C3vqThmM0hVhTK/20MQG24Zr0cn6FaBt/vH20uqmZoqwRENA/PTvfd4y8GMv9VE7ijdr0Na28lNE+Lw2uPtui5ioVnV493g9nV/pObb5Mka6sA7Ny2eOaVjkPTrTml/6SD4KDFvPd6s4q0JPZpj8LwTFXTFmweJ+JrAufRWxVvPPHsf5Z6kqQMpSRZsn/cReTyblRMZRkGBtwEV761VceBMlytEKPHGw6+64s3Ns7RSc8yucrMUTwZbwZDZXep1ll3SD0TnB3wQxx4x3ifmNgLLE5hR5n87l5xW88A7O/yBd5ksNc/q7v55HjjqJTVXSaiw4h1oxtGjs3lbGOFszs358ga6PseqllFScoVXh3We4x1MoNg3T1ofn7On1Yy8UlJo4N+wc4kHqbmVKt6Br2cfeT13llb7NwYGE0YDZZ+QjR95mOGd3Vq6TwQN9nfHxsbC8ccfz/q68S0uznWIWrBgAXM6ty08mOKtOVjtDuL6w2t/7V458JaTe5GA3wM9GlJpe7o1UnNuMjm8czuIw3nUbbiatzXDm3PaoA4s6L7lJD89VwQIbLTr54AmSImP0QTecX4H3tv5DG9V4I1qo25yn/ey7WWWGCXmLt3X9ni7B4ktcptcsK7mPDGEiotAlVuit0K4Am/31zxKzZFg+7yVZBv1eOsOBd4GVLxRvtWUI8+oRrk59sJioIYZK3T9ViremkqSuuoWSo93qyc2CODaJQDTPoDdMVIwG3CFVu7zDmqkGK94BzqjN5iRYt4q3jkDXFL0hgCC3Tb6u50QxTaZQAObgJziOb5aFMJe8R7ofujjSRQ9+7x5xTsIqTnSK0cOvA9V+df3hAfz3rK5nzrw5v3IgSaKTAg/DwWzntjLigd0lAfuLvPzOkXHeMRTIsMCCgIzkZ2dDT/99BPr9ca3c8891+3r77//PjNXA7vP8eaJyiD7uzcdrGJ7empCLPSW7zGRwCG7mrfqR/ZDaq7IzL1I4xPjuLmaFEgell3Ns9pwOEbJ9FezJ8BJgrmZt9k3r1pP94q3VBWMUqTmjW3uLag2QHpqrpXu2VIgjq07VnA0d0tkqNYTkxpNGll0S0yCPkGixauzrsRQS5tS86PO+KCTGe7SfRu3I4UJCrwjSFJcrFIZrsjo7wq8uaM5VoLxBq6WDKtv4jygciTpbzSEle9eJymZ3kAP4gEFihkFmsA7yB5vlOXzwNtfAwlvPd4Y9DNjJ6fU16tTxbuJma5EBb6e3LDOH6d4o6TmeGDl16468FbLzfUMvFWu5sFUaNHABv/ZkdpGpYLTJt1PkN57rHhbSGoexHqibwGv2myX5ZN+rycmbLgHgDdjNUIX0Pg0JqZ1r2hmZqZbBdx28Comv18G2d/Ng1hsvQjEy0PPGcmtgr1Wgbf7eQHHAKqnPWhJcrhXvO0S2Hjtm+dJGlbxbi01j5L9TTAJWe/DmbuusVkpTvTKdVW8ke5yxbuuscUSxmrq9WxuQ2rulMf4BdvjzaXmVp7hrV5PXE4+kYTv4S3YKqOiLir4ijcfJRYXE+3yMyB0gwJvg+TmB5P6uAJvtcxcbZyGUl00HuJw6bme1W4N/AYZqDTaNVIsgIp3RaGmghhg4M1mgkdJM5V51dwX2E/PgyZMNKjBwENPublc8W6KkrKOwVa89wVT8Y6UqzkbF+aUgmytI304DNaaXIF3IC7xasMgfp1uleeotgmOB8MNrWy7qzWi9rBlAkX+eo8JwnxFrSLYKssn2wRVAqiwQXb9ZDmzOkIgeHDaEHzFGwPen7aVRNxYTX0Ib8sMTBt47ztSy8ZZ4T10WGcPEzI8zfH209VcdLzO8cb9W07UYMVb62oezY1F25Cbo2s5xkk4D11rWsWdzTmijxLzZq6GcaDWXM0pJ738alnygJIYsvjMaXUBR5nfLb9v0UjNm6NlFUEQPd58lBhWu60s3TcKCrwjDO/d/cMpB9mlWwGK/3APvLGizY0S1LJhPY3V2jqIqzZ1f+jEA2+1GZg3Mrq4Kt64C/HgLNDAGzc73i/uj9ycV7sxUPSUvOBycz0M1nBEjVLxDmwuutopfl/5UbdZyz5BV/NIVrzRUd5TtTtcFW9lLnpgLvFquKHNdn/7vNFLoeMI96q3haTmyus9yM2VV2387ptXV713LNZIzcVfT0LkwDuwQKeithGueWMNLNkiBd4TekX2+lUnx5t9VGiljx2tKvQDOqYzFZ4ngnU1Fx2lb95T5VVOXsREeZKaxynBeLUPZ3O+72DCUhvQ8Io3p6MVzNU89iS3QAsWTFQ4Y5OCDhLtNHOaGyq6ScyVwNv9Nd8st5cEk8xQ98wT+kOBd4Tpny8FzWvK4qXgBKvam75wl07jDdnTLG+9RomF4SDucuGu9bNSzWdAV7lGCQUaeAdqsMZneGv7uzm5OgbevOIdLR1UApWao6Mp/pOGphYoqZbXx2xSc75OakfzcFa81ePEgg4UeYU2gDXqPtE98LaiuVqQiYzePPAOaD1V8n02w7vMMgoCQiC0BmQBSM037KuAM55fCt/9eYjJMR86ZyAM7uS5ehyJwLtRW6HVzu1WVby5sdpoH0ZwPCDHPk+8R5QfbbRHxdtn37xDkZq7zNUalR56Hnj7Gim2jRuraWTmnuapW8JcTUlkuJuroVLRzQxMVpsEW/G2y8xp94q3tFYtstTcbT1jEyFGTr4FI99XEm0WVxAYBQXeEaZ/B+ngv6moEqDDEPdRYjyI9BZERaDiHXSPt0pq3qZxFZea4zgxnEvNq7Vx0s8IeJY3wnuN/erv1sjMtSPFdJGaS0Fio9xnE2hgg8Y5fOP122DN1xi6cFAkG6tx6XDYK95HQ3I1V1e8+QEo4EARNzsL9STzTTvoRIYsNd9ZUuP/oanzsZLZU+U+6TVpoZ55QiC0cmw/pebvrS6E8+f+wtRd6MXx4cxj4dJj5H3IIKm5LzMwb4G3N2M1d6l5E+uf5Vs6SqStjCdptDZR43mcWBwz10Oq6uVg3McosZ4aWTlPduTLfd34NHJSxVcX8H3aveINrSq0vMe7KcQe70zLX5+u1zxfU75mLWqneEeiYr4YzIg2qniHFwq8IwyO2uA9kc25srM5xy3wTm/tbM4DqghUvAPt8e7ULpFtFihNO1jhGqXlkdQ8KXvc0gRQ9HtoMlMuD9+9NABHcy+Bd/t+Us849ouHWqlVeryDk5ojPeQgccN+P+YkI/ERlJrjzVypePuSmntZx69uB/jsRv9N8bTmakFXaAMcKYZ0GgXgSJYCxIPrAOrKLSONdrWWBLee6Lyb6IiBhuYW2ONvgggTbAVjpMc7F1tKuk8IRHTgFe+a+ia465ON7Ho/uX8ufHHjBBjUSafRngGCr1meL2t1uPYiNS+rrocdJTVtBt5cao5GX6Wy4iojyaFUhK2Ky4W7xUfFu6mV1BwTGykJvqXmWJDYuL/So7Ga2hWeewFZYa09mavx/nm3nmRsr8Suj5B7vMVPVvhCvU03ac3V1PczR5ISeDc2OYNPZFhcQWAU4r+yBQNNs1CShBLiomTZYE07HgvxKDWviJi5WqAH8fjYGBjUUTqArJDHYXgFDwXpHaXH+9dK75MDHCXG6Xu69H7Pz64DfFsVb29ScwwIeFAeqtxcW/EOoqI4trtUAfx5ext/lxHmahV7ARqqpMpldi8fUnMPFe+jRwBWzANY+zpAxb7gxokF6ffBnc1xo8ZDqN9eAl3HSY//+Fj+ZBRAYuRm9oYLvmkHaOng0dk8aBUBmasRRqCVY/tR8T5QfpTt3WkJsfDf6SOUKSWGV2j9rHiv2n1EaRHxJcvlFW/+N9vlEM57aD1KzWO8m6v5IzVfvecI7C8/CslxMTCyi+ekB+/ztoKxmre56Dy2dqoC72he8Q66x1tuhbB4hRZ9AdTTDJAWTz3ejkSleNaqDcUPqOIdXijwjjB4UO2bJwVIG1tUFe6EDIDEDN8zmRWpebopzZaO6SEFir9sbyPwVsvN968Jvr+bS807DJV65TfLvfJtVby1o8TCITfngbd8uAumosjNen7dedi/kRCRNFfjMvP2fTyPtvMlNVf34/O++wAr3oGa/6krOdwx3m8nbnWguPEj6X1SZuuqkoDwTVstYQvaYC2YvvldS10TCajiTUQS7evXj4o3Bk5Ix3ZJpnD7VcZfaQNv7T1ZCbzblpkjCbGutdknj7TUunBbEb6veAwAo31JzR2QluDw6Wr+0VopyXzqoA6KokDLwPx0r1J0qyQyWjxVaOU2Q4+j8QLq8ba21NzdALDF7Vp1VxAkuKTm1ONtOijwNlBuvqY8xVU1U8vMvfXrRsBcjUvWggkUj+0hHZyX7/Qj8E6XA2+U7iLacVSB0P8s6f2fn3n/HhwBhZVWX1JztWxar4o3xAW9nv07pDF5H27k6wtlebNZzNVwDjOS66G/W13xRpWGHDArHNkTXOAtV7zrWY83BI3L2TwIQzDsS7ZQdZZv2qGMH+Z93gHJ9/OHSo7x2ErDFRrU401EkphgKt7SvYz34hoNr2q1lpprKt7R7oG3t/ndyrdHR7EWEnXgbYeKt0tB0DrRzQNFyVxNIzWPdrhczT0E3ji/+4vfD7LH5w2X1X4eOGdYR/j3xUPhtlM0akjhK96u9fQUKPKKdzBmYBio20ka3arirczxdpea+7qW24Iq3uGFAm8Dnc03FVW5DNa4o7kvqXkEx4kF2uONjOzSjr3YcaNu0xCMV7zlADXoijfS72zp/a4fXcG1Fh7gpXYAiHN3D3Ujp7+ugXeDPMc7mMAbDz/j5GTGMn/k5pE0Vyva4N3RnCs45HEWUKPp8y7fo0PFO/hI0eVsHkCgiNeFuh3CIkEir3iHsp7c2Twgp3isNnY7zvUxyuTwmiEIE/d4c9l1vkmkwF7NwLTV/BgpgfvHgUq/Kt5quTnO/UYyLT5KzD2R0Tr444FNbFQTk4u3kprLPd6Vda3N1RZtKmYSdEzYHNPN+94RFxsNZw/tCNkW6VX2pMjge45TJY2OVhnrBmoGVlnXpJxb7RAo8t5/7RxvtXRfkppHBz/H20aJDCOgwNvAivefByrB2XmsZ4MqJYiqNMZcLYiDOMqvhhZIh+flO8r8C7yVfxxkjzeS3VMyWUOzti1fBdffzeGBZMlmgBZphmko5mqNUXz2Z3CBzXhZbu5Xn7dirqa6ZsIFT0zkeTBWQ/Dv9WawFmLFG3u8g+mZb+VsHkjFG38fr3ojydYIvJUe75DWU3Y2Lw3A2RxRryeT7tN2RJjb1dx0gbc3OamHivfaPUfY/o6GiP48fy6HtpPUXFtNVMN7aJNiWlzGZyqpua853h//tk+paAdrDGqdHm85UFR5LESpAu9AzcD4DG9MhiTIKg07XaNK5VtjrhbHe7ybgql4N9omkWEEdNIxgD65qUzaiX0pJYOuAfjLewBjb2hbNlwXuXFiwR7Ej+V93jvaCBQz5FnenFD7O9uSmyv93T5k5lzyjw6bWLEOJCj0WvEOXmqOjO8prctve8u99o4pcPnz0XKAJvlAEA7wmuQj8Dw5mrdlsOZW8fZjDJym4l0fYsVbcTYPpOLdKlC0htQ8VFdzPtEgwRHNTKf2+utsru7zttB6EiIH3m2PszxQwQNvc0jNHR6kvK3+NgwYo6MVmfmYNmTmHDtKzXmPtye5M5+TnOJQ3StVc7z5ODHtPo0mnku2lLQpM7dLIqPJQ8U7Jl4VeAdY8bbLDO/WzvvairfWXC24cWKoSOAVb+rxDg8UeBsAZpK7ZUty5z9LmwB6T2EvFM9Sc/U4scqIuZoHa7akGKztKPNtkqGtePMgLVj6y3LzHYvc5fmBVrxRote+b+hyc7ni3QDBm6vx+ehdspLYZrWird55TF7EoETNCVB1AMLGIdl4LiXPd8LEm8Ga1lzNXzMV1RzvUCq0PXKSlQ3bb2dzxK3ibY1AUZnjHULg7eZsHkifN3otcK8Hi6wnIbLUPIAeb5NUvGN4VatVxVvVvy63/GDyFhnph8xcLTW3k9GSywysdbDSBNL1kuxQrbWnOd6aivfn6w+w/RunvvSU1UF2wVOPN99znKrXX5RbT3JwFW87JIY8VrydHqTmsYnK9wXaM4/XL//Z6DFE6A8F3suDKagAAHZCSURBVEbLzQ96kQUrc7wrI2yuJh/Eg5zXNLxzO9anVFxVz6SnXknNlzLxnFB6vBEMlrN6SRvhtm+DczTXys03f9naGCzQirdsrhaKvGycXPVeuq0NFQEGo3xMWyBjuoI1VvMmM29V8VZJzXEDLt/rHkxXFQWUzECpeTCtEJykuFgoyEwMPFDEtc3uLf8Qi0jN5fNQKIE30psbrB0KVL5/vEtqThCGVrwT26wEHVQq3uYIvB0e5iS36vGWTeS4B0O/Dv4Ff1rnbTsENp6k0ZwmkNYjJVb1tRbVHO94aZ0rjrr3eH/8235bVrsR7qztPse7deDtNv4qQDOwwzbrR+Znc57MaG72vJ6OICvefD2xdQLHBBP6Q4G30QZrB70cVH2aq6VHYLxQcAdx7LEZ0bmdUvX2SkwsQFpH/QJvPMQrcvNP3b+GGcGynf5VvJEesgR2w3sAz40A+O1NV7938SaAJY8AzB0P8MZ5AA01bVS8pc0glECRy8396vNO7xS5wNuXzNxbxbu6SEqOYNKFVzv9kfTj/8MmfczV3ALFQAJvZNzNUvDd+xSwAryyE6wHgdawLuD1HH2NlDAbdFFIv5+IHC+88AJ07doVEhISYMyYMbBy5Uq//t3ChQvZCK5zzjkHTOlq3kbFu7S6nlWP8NaTmxpvLjMwbbCiPoRHx0JFbSNLhiNcneJPglKNHQIbX1VXHngnqwNvldScr8+aPUdg9sLf2PWyvbga1u+rYPvVmUPywW747vHWBIq+Rrn5U/G2ST+yYlinqXi3eE1kBLaeXOFih9e7UVDgbbjBmkpK7qvHGw/IYTZXQ2l4qD3e6j7vX/01WMMbhh6Oxlxuvu0794C4tkwaW+TJPd4TA84DOPs/UmIAx0d9egPAf8YCPD8a4D/HACyZA3BogyRr/+xGz1LpSknqXR+iuRpfT/znGNQcqmyjAp9eEP7AW3E0D6LizY3VMEGQ3cv/wJu738uBd6gGNT2DmT2NDJsGMGuVf9eRAPDzeqjryQ3rAnKKRzoMBrhxNUC/M0L6/URkePfdd+GWW26Be++9F9auXQtDhgyBKVOmQHGxxkBRw+7du+HWW2+FCRMmgGnQOn+3UfE+UCHdg/LSElzmWmbpSW5V8VYdwmPiYHuJdJ9DV+1Ued50oBXvLFu4mnsP/hqdsrlabItHqTmOaLvmuO4sMfPpugMw+akf4d7PpCT1Cb3bW8apPJhEBh6RWtp04Q6y4m3zHm++rqAZJ8Yr3rSe5sMcu4cNwRnNyK7SGjbjsRVaV3M269YZVnM19V4TSoV2rBx44zxv5abgy2ANq916OBrnDQbI6CLJl7d/37q/O61Tm4crBka5GGDduAbgpAelpEDpFukN++Ww2jnpHulws/FDgOXPu//7pU8CbJJM3nY6eocc2GQkxbH+MGRZW3LzcFe8MXDet1p63Glk4BVvbqzWrotrnro/gXejJPFUKt5RekmjAwwULQbPloe8nnLFe0dJtUdHYMIaPPXUUzBjxgy48soroX///jBv3jxISkqCBQsWeP03zc3NMG3aNLj//vuhe/c2zC0jiboP2o+KN3c072ASmbnPnmR1NT/GoSTEesqvU39I0jhEt0t22Cao8dTjXR8lXR/p0arkt8rVHP/tnaf1g09uGMfOd+W1jfDzdqn4cK4NZebalkVumqbsD9H6Bop27fFW5qK3kpqH2DNP/d1hgwJvg8hJjWfjOfA1swXnebclNecBOB4WYsOTOVX3ggTb440M7pTBjFnwhrjV18imDJ2NldRy8zWvSSqBQBzNtWCQPu4mgNnrAU57AuC8+QC3bQf4y7sAE/4PYMoc6fu+uwdgx2Lp8S/PASx6QHo86V5YHz8y5ERGQHLzcAfeq/GA7ZSMxtqq+noKvLmxWkaAgbdc8W6GGPYWcoU2N4iRYhZEjzneITmbE8LQ0NAAa9asgcmTJyufi46OZh8vX77c67974IEHICcnB66++moQeZyY2UaJqV+3rc3VVEFzdKySYOTKlEDM1ZBUm/R7ep2Ljjljh9QO195Z5kFq7nA7/3w6axz849S+EB8bzfxEJveT90KboT73tDID89aTHGigaLMeb9eseTmRwRWXWqm54tAfXI83VbzDBwXeBoG9bj4N1rjUvLle6hdWG6uFWJ3yhjrJG0qgiOZq3Dn1Fznj65Gsnu7yaD0Y8hfpBoQy8G/ukPu7/XQ090ZiBsDoGQCDLwJIUPXX4+eGXgrgbAH44EqARQ8CfHuX9LUT7gSYcItyc4zWKfBetr3Ut1t8OANvNJpb+7r0eNSMtr9fLTXnz5lLzXFsWxAV78boeF0qtLzPsbS6QcmY2xE9xom1cjYPVL5PCEFpaSmrXufmugcR+HFRkWeDxGXLlsHLL78M8+fP9/v31NfXQ2VlpdtbZFzNfQfU+8vNNUoMUfpifc3xjolTEoy95YSjPySqerwzbeBo7nMuOgrnYqQ9OKulzKPUXA0Gkdcd3wPW3H0SfHnTBFvMl/aEel9RepI9VbzRhVsTUAY8TswmPd68vUSZ392GWV2gPfPKFAMKvMMGBd6mMFjzFHir5OTY260Yq4XT0dx1wwulx9t9nrePwLvfWQCT75Pe9CK3P8A586THK+YBLH0iMEfzQMA1Ov1JgI4jAI4ekX4XctxtACfczh7yJQ01UBzepR3LnqNBjk8DK5TThyvw/uMjgKOHpUSJP+ZiyTmuajW/fss9Bd672h4pJle8G6OkwJtvKsGCxkFYpbV7oKhX4I30CtawjrAkVVVVMH36dBZ0Z2f7r2qaM2cOpKenK28FBTomZrUGn0FUvDuaqOLtNVhxC7wdSsU7kHFW6oq3baqJHuZOc0qipDNNu8ZinxVvNegMneZnT70V4Ykhtfu20uOtXjNWoW2t3iiurIMi2VvBG3YdJ8YD6iZv0n0lKee6N1TVNcLOEt/7M/V4hx8KvA2Ej/X484CHwBulYnEprlneERglpt5sQpVGj+0ubVIrdpV57/nEg874vwG07wO6MvhCgFMelR7/8BDA1m9Dq3j7Av+Gi95wubKPmw0w8Z+te2hDXE/MmKN5C/LT1hLv38jHiTVUuc+A14OVctVq5JWtD62eiEtyJYq4wRqveKPUHPu8IUp6rjVtSOjlsW684h1qYkjdl2znQJFfn3qspyLft3Eiw8pg8BwTEwOHDh1yH3Jw6BDk5eW1+v4dO3YwU7UzzzwTYmNj2dvrr78On332GXuMX/fEHXfcARUVFcpbYWFhhKTmST6//aAcAHRITzSt0ZKnv605KgaKZFNOfx3NtYG3XapfinTfQ9X1kFM606S5Bd6eK96ESwnFt5ZWFW/1OFkPPd7YtnTGc8vg1H//BOWy/Nl3j7c9EhwuHwLfFW9HrPR9Dap7wy3vrWemfyt3Hfb68+3mEm8EFHgbCJeaby6q8mxCpjZYi0jF2/UcQg0UB+SnQWpCLFTVNcGG/ToHgP5wzHUAE26VHjfWhKfirQ52r10KcNmnAJPvd2sFaNKxonhiX6mC/Nl6yTHdI3HJAImZ+le9968BOLBWOmAMv9z/f6fIzQ8BNDUAVEozTVnQjV4FvM2AqxK8gYZ5rOItbQZ6mArzfkc7B4quijfoVvEO2NmcEIK4uDgYMWIELFq0SPlcS0sL+3js2LGtvr9v376wYcMGWLdunfJ21llnwcSJE9ljb5Xs+Ph4SEtLc3uLjNTc3x7vBFPPSdb+bUdbpAAnNy0e0hP9D07UruZ2qyZ6KhYcACnwTq4vcUnZKPAOeE1buLpNU/HW9njvKathCr8jtY3wwRrPZxkM0ivrmtjjTBu47iMuZYB7j7dTbRap6vHmFW9sUcSAG/83LFi2y+vPt9tcdCOgwNtAerRPgbiYaKiub4J9R1yuzR5HivHAW91jrDM8+MfXNfagh9orNaGXJC/8bJ2PQDGcnHgXwIgrXAcRlDeHi7QOkuGYZt1c5lWh/4qzhuSzm+7v+yo8G/KFs8975UvS+wHnBmaGpzZYq8DKlVOqLHGFADdoa6vPm1e85cBbnwptqpL4siv8EKRHYoj3j24vqQ7Y0IUQAxwlhtLx1157DTZt2gQzZ86Empoa5nKOXHbZZaxijeCc74EDB7q9ZWRkQGpqKnuMgbypXM19TLzAySPoB2E6qbm3Cq0q8K5tinJT+AQnNbdJUOOjx7u4JR2anVEQ7WwCqJFVZ81NPqXmhNoAsMW7NDoWR/S5f9+OEtdI2Dd+3eOxOMWN1fA4EEhSyUoVb/4+Sm2oGKtyNZe/jsqAiqNSa8R3mw7BwQoPMYcNXeKNgAJvA8EMH5dn/nmwwrezOZea82A8DPAXKM+Uhcr5w6UA8JN1+5lsKOKwHuynACbeBXDGM2Fzg/evohj6mmalxCtV7w/X7vNjlrdOEs2aMmlsmr+mat4M1tSO5jxw9tdgTa54N8g93noEinxEGyoy1H1QdoJfn3okMgraJUFaQix7rW8+aN9khpWZOnUqPPHEE3DPPffA0KFDWeX666+/VgzX9u7dCwcPHgQh0M7x9lHx5jJzDEbNdMBXerx9SM2rG6MDlpkjiY5Y20nNXf2zrfeDo83RUAIZ0geV8v5LFe824edJrTRauUbxdRcd7epJlr++s9SlnNpTVgtLPUx0OVIjBZIZidI4NzugKAO0c9G1FW+NdH9nqSuRgf/m7RV7Pf586vEOPxR4m0RuvnF/peFScz2NlpDje7eH7JR49kJeskXVFxXpw9XxtwEMn27Ir1fWVCcn+gtGSMmMj9bu9x4s8j5vvSrev70uuet3GNL27G5fFW/1DG+Ov4G3XPFuUKTmepiBpbAxObUNzbatevPrM1RPB97PhyaAyJo93nvICLGZNWsW7Nmzh7mPr1ixAsaMGaN8bcmSJfDqq696/bf4tU8++QRMAd6TNX2R3jioGiUWqhpMTxQ5qQ+peVWjeyuIv9jRXE3pmfdQXa1vaoGDcp83VMoqPgq8A15TZfwV94mRX3faivdOueLNr8M3lsuJe5tXZ1tXvMGLuZp7Uo6bqvH1fGdlYauCGK49toci1OMdPijwNphRXaWD6s87Sv2reIfRXM1V8dbnYIEZt/OGS0Hg+156dGxjXqXTK21i3xxWfSitroeftpW0ITWX+6lDATP/bHa3XO0O9NDpVvFWGasFGnhXSNnZuqhE3QJvDBSHyYHib3uPgK0r3jq95od3ltZz7d5yXX4eQYQV5bAa5TN44qPEOqSbp7/bveKtScKqpM+VcmwYyCixVoG3TcaJcXlus9fAO1MTePt2NSda93gr6gxeoZVNDV0VWvdA8drjJG+eRZuLofBwra1neHtyNW+W1RlRXnrmtYmMc4d1ZH4PeIb8+o8ij+uJv8JMyh6rQYG3wRzXW+p1XV9Y3tq50VOPdwQq3nodwtUV2sWbi9kL3W606Czfx5vp2UOlZIY3wxFde7xLNgOU75U2x4HnB/7v/a14l+30PlKspRlgjVRFW5c0VlcFwfDOknRwzR6bBt68x1un9RyhVLztuZ6EoIE3Vt18vAYOlNeZrr/b0yHck4y+sjEqOKm5LV3Nvfd4NzQ1Q5ESeMtJbap4BzzyjvuKRKlfe2jeqEki7ZKl0ZP758D4ntnsePD2yr22nuHtVvFWzNU8tM44klonMuT1RK+HS0Z39qgiUGTmSXG6xgGEOxR4GwyOJsFMNO6by7Q9LIrUvEIKviM0Tkyvijd/kQ/plM4OBp/8pkMFVjBc48RA92TG938WK6MfPPd46xB4718tvcdZ5TgeLNjAu+qQq8dbbXLHH+M1jrPQPbH1Gyn4T8iA5YknsE/ptSkogaJNK94u8z991nNIQQbLlmOF8JA8woggTIu6z9QvR/NEMczAVLLTJoiF9qnxkBFgcJIU5/oZdqko+urxdqt4V2gCb61RH+G1x1tRE/AKbWyi2/c1tjjZuQbdzJFu2clw6TFSsv7dVYXM6NCuM7x9VbzdrkFHgspcrcVNQdC9fTILvPHnrNp9BDYddLW5Un93ZKDA2wQc10uqev+4RSMd5g7mETNXk16geptU8EARK7Q40sBO8AORHuZVnP75adC/Qxo0NLfA578f8F7xxqw8VotDYd8q6X2gvd2exol5kppjMJ+a71tuvvJF6f3wy+BoVIKuFdqhBRms0FV4+CgUV9kvUOQKVb0SGSnxsdAnT0oOrqWqN2F2NFU3bxyoMGfgrfRx+nA1b4KYgGXmSLJbxdsurubepeYNHnu8SWruv6u5xoWbr5mmxxsr3txYLT89gSWAJvfLYW0eGBh+tVEyb9y4vwJ+3Fpiu8BbUWV4S2QgsThOzNXjjWu6V5bpd2+fArlpCTBlQJ7iGM+Ti7w4Zqf1NAIKvE3A8X2kwBt7dt0CUzepuex6Hh/OcWKge8UbOWtIRzY2DQ2s/jjgwUTOwnBZlV5Sc20y4/3V+zxXmfHg5WwGqHLv4QmYfWuk9x2DDbzlijeOXzl6uLXUvK0+75KtADsXoy4NYNRfleyuXsmh1AQH9JHH7KzdY7++ZL2l5siILpJ8f61NVQSEBQNvXvE2WY83P4TzoMZT4N3gjA3YWA3BKvmkvjlw3rCObrJzK+NVut+qx5uk5sH2ePM9J0pjrqae481HiWGQyH5GTDT8RZZHP7doO5z9/DI447llSksTFiNsu57yuV1ZT9klXu1qXnjkKLtHJDiioUOadA/jKoKP1+6Hv762GsY/+gO8J58nsbBDhA8KvE3AqK6Z7AVxqLIethyq8uxqHhFzNekVrHdvR3qSA04akOu7L9miuPrm9f25Zw+VZnrjKKzNRZpkBvb68CpyKHJzTPgU/xlaxTsJZ37j9SQfZBIzW6s2fM3y5tXu3qeygD0cPgTDbWywprfUXG2wRn3ehOnRyF09gclw3uNtuoq3UqH1XfEOtL8bQff2l68YBU9NHQp2wVePd71bj/cBqVKhVLwp8G7b1VzuSW7xYq4mfx8q+bgRGMqiOVNHF7DrHXuV1++rYI/PGpIP7107Fs4YLJ93bIB2hGArqbnSM+8KvLnMvFt2inJ2OqZ7JpvscrSxGb7fdIi1u47tngXP/2UY3HV6v4j/XXaCAm8TkOCIgWO6SxKmn2TpTCtX8wiaq+ld8UYuHOGa6Y0bmF3Qe0Sbx5nenpIZity8jcAb5d9f/A2gdFvrrx34TQqYsWc8VZIlBQxmYZMx+AbP1W5fFW+87te/Iz0ePSNsqgw7B4pNYbg+ed88jki002udEBBuSOTwXskur21kh1Mkz3QVb3cZr7fAGw/YRPA93ph8Qan5IWgHTkwktzQC1JZK7xGSmgcw/spLxTvWlfRQ+pGzXYF3TmoC3Dy5NwzqmA63n9IXlt8xCZ69ZBiM7iYnQ2xX8XY3V3OZ1XGXeJd6w1MiAxNrd57ejyn+rhrXDb6/5Xh455pjWBKDV8uJ8ECra7I+75+2lnqZ4x1+c7VwHMI5E3q1ZyMM8BDzwyaDZnobAJdVhSOZcd5wKbj+34ai1r3z/jibNzcBvH+5NC7s+/v07+/Wys21xmptBd4YdDdUA2T3Aeh+gvt4tij9A8Xf91e0mmtpl1YIPV/znTOTmAsyVi4w+CYIs1LfIgXe9dD2KLHslHiWJDeluZqPincDxDKTUyL4Hm88G+Gn0KjOmZzjkpuT1LxNFAm5JvB2psjJ/PSOrfwKuAN3N1lqzrlhYk/4/MbxMPOEHuz1aEe0Pd5ctdaQJF+XaVL1Xy015z3z6kQGMrFPDnzzt+PgnjP7B6WKIYKDAm+T9Xmv3HUYahukAfaKJBeNqVr459KEGX2lBg/258uBIjdzsAOKNFrHQJFzfO/2EB8bzQ6Gbi0K/gbey5+Tq9oAsH0RQIP7jEzYxx3NQw285Q1Ba6zmK/DGgySXmWO1W16/cCgIumYlMTMRDLr/OCB7KdiEcFyfmEnn8n0yWCPMTNlRqZK9at9RWLGzzOP3HKzgMnNzVbvVwUorMzBV4O1wxJFLcRAKAnUyG/u7FdI6uvZWfi6jwNuP8VdyoCiva33/8wH+8j7AcX93CxRxrfeU1XgMFInWySGedDua1g3g8i8ALnjFPZHR7LniTRgHBd4mAW8wOCMUq0Qrdh52dzXnY5bQYCoufC8cnkEL1/y+acd0YaOGftlRBluKNIGiRQmX1BxBw5tje0gtCou0KoK2Am80LVs8x3VoaDoKsGOR6+u4OfLAu9MoHSvengJvuce7tgzg4O8AW78F+OEBgLLtAHGpAEMu9lChBX0DRZvO83Zdn/r+XC7fJ4M1wsw0OqULv7I5Fqa9tILNtdWqh1zGaubq70ZiYrxIzbmMF+PE5CDGQNoUh6rooM5lqJVQUelyPzEfj4mQ1NxvwzpFWRkbD9D7ZEXFyQNKnN+N1zMWFfBMTPhuL3Frv+s2ASCjwL3ijVJzWUHQPZuq2mbAFIH3Cy+8AF27doWEhAQYM2YMrFy50q9/t3DhQnZoPuecc0B08O/gVW8+IqFVdRsr4GGonEaixxvBmygfYfDqL6pNy8KEM/BGJvWTglo0x/AceBe2/kc4YuzTGwCa6wF6TAIYJfVPw6YvXN+Dc7NriqXKSYfB4a1443XN5Xv/nQDw9oUAy56WPh42zc2MLRzj2RClQmuzQFFJZOi8nly+v3rPEduNECTEAfufkdi4RBYQ3P3pH/CPDze4eROYdYa3OlD0VfHOSKUqV6CJDK18n18PaOgVxfdWt8CbKt7+mKvhXsC3A+2ZiF/LW2X1Hs7vDlcRyFo93p7PRDyRgbPOS6rq2WOqeJsDwwPvd999F2655Ra49957Ye3atTBkyBCYMmUKFBf77gPevXs33HrrrTBhwgSwXp93ied+7jCOEgt3jzfnynFSdfPj3/ZBea3cH2VhwtFDq2ZSPylgXVdYDqXV0s3VPfCWx56oWTEPYN9KqZp81rMA/c6QPr/1K5dL63652p03qM1ROyH3eCM9JkrvY+IBcvoD9D8b4IQ7pLcIrKfaYM1OgaIrMaTvVjC4Uzo7IOCGv++IFLgQhNlodEqBd/8uuXDHqX2ZIuvd1YUw6+3flNcG7/E2o9ScH66xj9Nb4N0ulSre/qIuOqidzesbpfWNj41Remip4h24NFqdIGoVeMsVWte8aQoSPcFbQVspCDTryV3NC4/UKuMBcXwqYTyGB95PPfUUzJgxA6688kro378/zJs3D5KSkmDBggVe/01zczNMmzYN7r//fujeXe4PtQDH9sxiLx6UhRTizQelOOpMahiN1SJR8UZGdW3HZgTWNbbAwlUeqrEWQ7kphkmp0CE9EQbkp7Es8uLNxa0Db5yd3SDJjBhlOwAWPSg9PvlB6fsKxgAktweoqwDYvVTf/m63wDtKckj3xDnzAG7ZDPDPgwDXLwe46HWAE/4BkChJwMOtIBjSKYP9TBzpd0Du6bQD4ZKaowkVXpd2VBEQ4tAkS82jHIlw7fE9YMEVoyAuNhq++/MQPPr1ZtNXvBUZrw9X88w0kpf6i9rfRj3LG1sAEbw2lB5vHnhjCyB3xyd8jmhTr6m2ms0DdJ73Jlm0fz3eLm8mzXpGa9eTEhlmwdDAu6GhAdasWQOTJ092PaHoaPbx8uXLvf67Bx54AHJycuDqq68GK5GW4IARcuXtmz+KpCy2Wm4eRmM1JBwzkj1J6q8YJ1U931i+B5q0mXoL4UtWFQ65uVufN/oD8OtFXfX+6napn7vb8QAjrpA+h4eGPqe5y8316u9GUjtI7zHojvUiycPNOa1DmwcYLqvSO5GB/fI8ULRTn3c4X/NksEaYnUZZah4lj+A5oU8OPH6B1Frz4k874Z2Ve1XmaiYMvDWO0Qqq+2hakvmet1lRBy/q6qyr4h3tqnhjOxZCMnM/pdHoDO9aU22gyGfSc6ji3ZZ0390lvnUiwz28665xiCdsGniXlpay6nVurkqKCsA+Lioq8vhvli1bBi+//DLMnz/fr99RX18PlZWVbm9m5rje0szjh77cBL3++RXsrXVlrp2qXtdwwHuawlnxRs4aks9cpFHCh5UFq+JLVqUnk2W5+dJtJe5zk7V93oWrALZ/hwM0Ac542t0voN9Z0vvNXwI01gEcXK/PKDEEK+qjr5Uq7CHCs7vhWE/FEMxGgWK4EhnuBmvluv9sgtCDxhbpCBQd5wpOzx7aEf42uTd7fNcnG6Go0ryu5t7mTkO0S1Ia66DA0F8weOG3QnVRgO+rbhVvGiUWsLma+kzUqidZ0+6EPd6E70SG+r12D2+VyKD1NA2GS80DoaqqCqZPn86C7uxsKUBtizlz5kB6erryVlDgRepqEs4d3oll+nhgUdHi2uy3lEcJbQSmlqH+ZXRn9vgVC5us+ZJV6cnA/HTISY2HmoZm+JU74ntyNv/xEen90EsAsnq4/5Bux0kV8uoigDWvSsZrie1co75CAR12T3sMYEDoJoiKkUgYK7TLtpdCcZU95ObhTGRwg7U/D1bC5iJzJzwJe9Ig93irA2/kpkk94Zyh+WxPxFsO9ktmJ8ebVnaqlZo3qY52jjjzPW8zw02+3KTmTaqKN1dwcai/209pdEsbPd7aijdVaP2qeHvxvdEmMkhBYB4MDbwxeI6JiYFDh9yrnvhxXp7kfq1mx44dzFTtzDPPhNjYWPb2+uuvw2effcYe49e13HHHHVBRUaG8FRaau68Ynb9/+L8TYNtDp8KauyZD906yrAlnjR5sgk/XeTDLEqjHm3PpMV3Y78G55VadnexLVqUnGIRyk7VFandznpmv3C9Jx7d/L1W7J9za+oegBLz3FOnxT4+7+rvD6KIfDHwWaDgqtOg/gD92e3E1HDvnB7jhrbXwy45SS5ut8fN6OObMozS3U7tEdl855ZmlcOG8X9j9y02VQRAG0iD3eMdoAm9siXrk/MEwUk4edchIMKXDsstoyb3iXS9X8tn3UOAd3NxptdRcCbxjpL2ST+Fg/4Aq3v70eOP4K7fAu1WF1nXNZqfEQXoiJTR8+zq0+Eyex8VSIsOsGBp4x8XFwYgRI2DRItf84JaWFvbx2LFjW31/3759YcOGDbBu3Trl7ayzzoKJEyeyx56q2fHx8ZCWlub2JgK4yWelxENyWqbyuSpIgts++B3W7FFVNQWseCN56Qlw6iApc/zS0l1gRXzJqvRmUl9Xn7cSKKor3kvkaveQS1xzs7X0ld3Na0v16+/WGW/ZXb2M6uZdOoJVajGb/OWGg/CX+Svg1H8vhQ37LJoc4sk2TbVBL3A9Tx2Yx/5/rdp9BGYvXAfjHvkBPl9/ICy/jyACYXlzP6hxxoPTg4kkKrP+O30Ea42aPakXmBGHl4p3fbPr9RzrzVeD8BnYqJ3ieeDNpOZIupzURqji7bc0mu/feBzy1ZNMxmp+mNW14WqurnjjfaKgHXk9mAXDpeY4Sgyl46+99hps2rQJZs6cCTU1NczlHLnssstY1RrBOd8DBw50e8vIyIDU1FT2GAN5y6EyVMvNyWGSp2teXyO5ngs4TkzNX8dLAeAn6/ZbsuodqR5vZFzPbCaDw775zUXSHEzFQXz7Ildv93H/5/2H9JwMEKvqY+w0AswGPwuFaz1xzvyHM4+Fr2ZPgEuP6QzJcTFsPc+b+zP898cdSqBqFXilLFyJoYEd02HupSPgl3+cyPpm89ISoLS6AW585ze49f31UF3fFJbfSxBtgRWj+U2nwuD6lyDGy70Ok9/PXjIMzhsuJzHNWk3U3JfqZAk9Ek2Bd0iu0QhX6TCpuVpNhlDF229ptLd+ZK3UnGTR/l+f3gpm6mR658ykVmZrhHEY/n9i6tSp8MQTT8A999wDQ4cOZZXrr7/+WjFc27t3Lxw8eBBsi8pQ7cxRfZjzcllNA1z16io4UtMQJql5ZC6LIQUZcMbgDqyH7l//22Q5Sa8vWZXeoCv3+J7Z7nJzXvHGvm2l2u2jZzs+BaDHia6PO46w3Vx0Tr8OafDQOYPg53+cCKcMyGMyuTlfbYbpC1bAIdlsyQqEO5HByU1LgNmTe8HS2yfCTSf2ZPOSP1izD05/dimbQU8QkYaPiGqGGIh3GH4UCrl/Vk29upuDKrIhVRTdpeY88Ha1AFLg7W/F29Xj7Wm/UZ87KfD2z6zO7UzkQ7pPMnNzYYrdZtasWbBnzx7mQL5ixQoYM2aM8rUlS5bAq6++6vXf4tc++eQTsCyq2d1xyRnw8uWjIDctHrYVV8O0l1ZAeW2DkFJzzu2n9GXGNT9vL4MlW0rASviSVYVzrNj3fKwYD7zZk2ij2s3pd6b0PruPZK5mMpTRGRHqPc9IioO5lw6HOecNgkRHDLtOT3nmJ9hTppqNLjDeNu1wgYeBW07uAwuvGQv56Qmwp6wWLpj7C3z7h+cpFgQRLurkEVFK766AeJvjfbQ52uNMbyK4NW3QSs3VgTetr38GgOqKt6fAW13xJqm5Hx4ELW1IzUlBYFZMEXgTPtDM8cbe6DevHsPMJ9AtePrLK6GitlHYwLsgM0mZ641VbyvN9fYlqwoHaLCG/+uwgrizpFo+HMi/e8jF/jmUD7oIYOJdAGc9C3Zz4fYGGi1dMrozfH7jeOiVkwJHahvhvdXmNmk0wxxvX4zulglfzT4OTuqfyw4OLy2zps8DYV64fBglrpG8n4THXE0jNXereFNFNrhAsXWPt5KgSVMltWl9/bpGWY+3jzMRFmA43ShQbPs1LyeGvJ2JHDxJRKPETAcF3gJVvPnjXrmp8NZfj2GzsDfsr4DLFqyAyrpG4Xq8OTdM7AkZSQ5WxX/XIgGNEUENynlP6CO5rb6zcq8kMUSDNEzeTPCj2s1Hfx1/G0DnY8CMKNeoAW7rPXNS4JrjpOQFVr6tVPGOxCQDLelJDvjnaf3Y49/2HoHaBur3JiJHvVzxFrXa7W6uppGaN6HiSn5Nk9Q8pDnJnnu8SWruL/w8ie1aisLKg5knT3jg+mNPMuGf677LcNbzWDyEpObmggJvgXq81dXvPnkYfI+BdkkOWL+vAi57eWXIB1cuXYn0IRzHRnDX2Ke/22oZwyWeMI/kevL56Ng/W9fYDHDZpwA3/dZ6breguOZ4G/P70cQO+X1fOVQc1UdpYseKN6dLVhIboYiHMhwtSBCRok4bTAke1Gj/tiaQJdAUeIe8pj6l5rS+fvd4+0qc8/FhPdqnuPUnE15c93ngzUesag5FeK0mOKLZ9dyTAm9TQVe32YlP91z9lg2g3vzrGFYtRnnxh2v2CWG05IlpY7pAt+xk5nj8n8XbwQpwqVokq7MT++aw3lmUQ3+9sQggLgkgWQoWLTX+yqDIG2dTY78UPo1fd4pf9TZSQcBl/ON6ZrHHP2+Xx9gRRAQr3jg2TFR4gKKuzvK/rYkf76IpMAx1TVtLzaniHYqruadE76CO6fDwuQPhyYuGRPw5igRXC/BCmVLx1uzhuO7/mTYc5k4bDu2S6Ro1ExR4mx11sK3u95YZkJ8OMyZI8tel20I7uPIXshGBN2bn/nFqX/b4P0t2wEtLd4LocFlVJKuJ+P9u6iip6v32ir1gNYyueCPjekiJjF8sECi6+sOMew5cRWAV+T4hBq2cqi3Sj8yl0ejWzqCKbJCBYkvrtgTufh8bD5DcXv4HFNT4K933pQLEJCwWYHAEJeEdh6bH25XMaP29J/bNhZMH5EX2CRJtIu6OY0upueqxh4MrVuC0mW8Rerw5J/fPhavGSbO9H/pyEzz0xZ9Cz03mCoJIS/enjipg/w9X7j4M2w7JM70tAI6b4xPnjKrQql9vyywQeCuJDAPX81g5kYFmkWXV9YY9D8JesFYctXxYZNmpVmre2AxLWwZCcWwHgHaSeSkRgqt5s3ytqDOUvOpNiQ2f8PnReL7kyQwj9xvL9XgbrAIkAof+T5mdtI4AjmSArJ4A0Z4lcSjRSU2Ihcq6Jti4vyLoX+V6ARsnO737jH5wh1z5Rqfjm99dpxibiIayyUR4PdH5flJfyWTtLQtVvd3mohvoQjy2exZzj99RUgNFFWLP9DbCJV5L+9R46JsnJRV/2UFVbyKyFW+RpeZqx2jt33ZD42x4oOubAI5Eg56d+IGi14o3P5shVPH2L1BUm6sJOkXATCoXrbkaxd3iQP+rRJCa37AC4KpvvX4L3sSO6S73Se4oFdZoiQff1x7fA56eOoQlAD5bfwD++trqkCr5RsFlVUZUZ/8yRpKbf7RWNlmzAOqDkJHXKLpxY7LLCn3JzSY5CHEVwS8h3L8IIhBaOVULfAhv1LiaS/f8KIhz0IzpUCuK6iSNe8WbAu+AFASsx9v9c0RoPfOYODeDCpAIDHF3HDuRUQCQLAXW3hjXQ/r6LyH0SfLAxgw3xXOHdYJXrhwFiY4Y1rsuoqzXyKDmuF7toVO7RKaC+OL3g2AFeLbcDJuMqy9ZvOtSDZdTGh94S/cvEV/nhJjUKVVM8SvereZ4W+BvMz5QbGnlau62nrkDWhutET575o1SAVq1Z56fMaXPUzgnCvR/yiLwQGDV7sNBVzh5hlc7lsAoJvRqDxeM6MQef7buAIiGkWZ1uLFdIo8WW7BsF3z/5yFYvfswbC+u0mXmu52l5sh4HnjvKGW956KiSP8MTmSM7pbFDhSFh4/C3rJaQ58LYa+Kd4IFKt54b1Tfh6xQzTdcat7cxnoOmw5wxf8AJvxf5J+koBVvI1WA1ht31+J2JjLJsZ3wA/pfZRF65qRATmo8k0St3XtE+Io356yhUjb52z+KhJNMGzmeDblwZCf2/xJNq/76+mq4YN5ymPzUTzD8ge+EdORWG/caHXgP79KOHcIOVdbDjpJqEBUztJcgKfGxMKxzRsjtMgThL/UWqApzh2Nt1ZtXvEXuXzdDRdGnA35MLEDXcQCOhMg/SYGI4ePZml0VWqP3b5FR+zqYqRhB+A8F3hYBe6OPDVFubgajJS0jOreDDukJUFXfBEu2FININBu8njmpCWwu5oRe2TCkUzp0yUpiAQ4e0O757I9WfYFmRy2rMjpjjgfaUV0z2eNlIY7xMxK+b5vhNc/dzUluTkSCOgtUhflMX22FliepE9RmYERgFUVPUnOBrxVz9HgbpwK0Cq4Rgu5Sc1pTcaC7iIU4ViV/FXGcmCewEnfmEKnqjUZrQgbeBgaJONP7javHwKezxsOPt02En/9xImQmx8H24mp489c9IBLusirjr9Fj5b7knwV24lYq3iaQ/o3vJd2/lu8oE3qMICFWxVvk4FStTnObO60EilTxDhSHxjUaofXUQ0GA0mjz7N/WmItunmIE4T/i7jiE1z7v3/dVQFUQfbw8G2kmqTlylhx4L9pUHNTfZRSuMQ/mWc/0RAfcclJv9viZ77fBkZoGEAWjFQTe+rx/3VEGTYKpB8wyQlDNkE4ZkBQXA4drGmBTUaXRT4ewOFYIptwCb6p46wL3uHGb481dzaniHVqF1kT7jTXM6qjiLSJ0F7EQHTMSoWtWEru5rdh52BIVb2RAfhp0z05mB6Xv/jwEotBi0k0GTddwbnLF0UZ4+vutIApKf5hJMrsD8tNZIgPbIH7fXwEiYqZkBh5qx3TLtIRbPGF+eHAqsnxY/bp1mzttgRnlZnI1J7M6fRIZZlABWqnHm58x8ZLFdlNCDOguYjHGhSA3VxyOTXAIV4M3FBHl5vwgZKaKN///e8+Z/dljlJtvKaoCETCbBwE+j7HdJbn50q1iBoqKKsMkmza/f+EIQYIIJ1YITnFv5NJodaBohaSCGXqSraSOMNP4K7Ps4aLP8ab1FBO6K1sMfnANxmDNLDN9fbmbo5EVSlFFwJXdBdOBRlanDMhj5loPfPGHECOxzFSd5Uzql8Pev/HrHjjaIJbrvhmTGRP75iiB958HSG5OhA+rVDGVg7h6/BW5moc+oo2k5rpLo82234icyMAjW2OTuRLnhH/QXcRiYAUOX4NbDlVBSVV9QP/WzP03PdqnMMk5Zvn+t+EgiABXEHBpkNm487R+EBcTDT9vL2P98+JUZ8E0nD20I3Rqlwil1fXw+vLdIBqujDmY5nV+xuAO7PFT34nTBkEIPE5M8GCKjxRzr9BaI6lgdEXR5zgxIuCKt1lVgKJOMuCvczOe2Qnv0F3EYrRLjoP+HdLY418ClJu7erzNeVmcJZjc3LXJgCnpnJUEfxnTmT3+fpP5e+fNmC3HCsjsSb3Y43k/7hDK/M9sruacmyf3ZskVvCbXFZYb/XQIi8IPraJXhRXzKpXBI83xDh6eKPfY401mdQETK2d18TxkVt8bERNt6oQQJTLEgu4iFoTP8169+0iQPd5gSs6QA+9Vuw/DwYqjYHbMGChq6Z2byt4Hqo4wArOa/507rCMz/ztS2wgLlolV9XYdhMzzou+ZkwLnDuvEHj/57Rajnw5hUZQqpuDBFE+UN6pdzZWkgth/mxl6vPEeydcWFWJE6D3eZkr0iob6/MPvYZTIEAu6i1iQzlnJ7H1xVV2QPd7RpnVtH1qQwXpbft1ZJlBPsjnXE8lOiWPvUSptdsxYneUZ/ZvlEW0vLd0J5bVieBCYWZWBKgI8TGCv9woBXuuEeLgMyGKsN3dakdGL/bcZKeXlPd4NKiVBPCkIgg4UG5td468ofxE86iCbew+YrRhB+IYufwuSnSwFU2XVDZbp8eZ0zkwK6m8zAjObq3GyU+PZ+1IB1tPVM2++BT1jUAc2og1Hi734004QBbNOMsA2iKmjCtjjJ7/dKoT5HyEWLlfzaEtIzRvVruZU8dat4s2TGAhVvEOreJtRYSUaKCvntQeeFDJbMYLwDV39FiQrRQqmygJ0/xZhNEGWUqE1f6Aownq2l68VrHibPbhRKt4mXE98TrfIVe9Xft4thIIAMfNc1Vkn9mQ99Ct3H4ZlNNeb0BmrVIWVnmQPruai/21m6PGub5aSGHiL5OoCIsjxVybew0VMZtTLqh0zFiMI71DgbUFcwWlgh/8mEx/COVlyNf9wjfkDGzOOv9KSLQfeWP2prm8CM2PW6iznpP65MLhTOhxtbIa5S3aA2cFEC1enmvEg1CE9ES4d04U9fuJbcjgn9IVXhUV3qnZVaFuU17Xyt1HFO6QKrdb9HuemE8ElMliPtwAqQBHgZyCl4m3C/ZvwDt2VLUh2shRMVdU1KW6c/tAsb9zqcQWmreYLUPE2e6CIJMbFQHJcjBAqAt5qZ9bEEB7Krj+hB3v849YSMDuqllDTrulMeT3XF5YL1TtPmB+rzLrWzvHGwzgXL4n+txkBP/9wQzXekkAycx0q3sqZiNZSj2QGv4eZ+YxJtIaufguSlhirSKICCVD5xm1m2Uom718PUEZvBHw9zd5/4+rzNreKgFd0zJzd7Zadwt6XmXwttWZMZk22tU+Nh9SEWCESQ4RYWGXWtSNGI42WA0UkgaTmQY9r4vdHbmBFxmqhm/+5VIAGPynB4b4O/LVOgbdY0OVvQbDyliVXvQMJvEWo0HKpeZkAUnMzm4F5kpuXmnykGPcOMmt1Vp0YKj/a6BbYmj7wFqK9hAJvIgzjxGKtMsfb6ebWTj3JoVdorZSgMV6R0SJE+50I8DNlg3xtmnn/JlpDdxKr93kHEKAK0eMtB4mHBah+iWIkwgMbs1e8RTCra5fkYO/xqR4xuTSar6fZ15QnMyjwJvSC9UE3WsP525sLN1a7qSc5lERGi1vFG40eiVDM6tQVb7ou9ezxpvUUC7qTWJRgeqGVcWIx5j+E1zQ0KwcnsyJCIkMtNS8xeTKDjyIx8yaDM70z5OD7iMkDRXXF28ztEJmyeocCb0LPezO//IWveKsCG7cKreAJBfOspzWUEUbB25ik15wYZyKzQz3eYkN3ZsvP8g6g4t1sfuOLtARV/7rJD+ItAiQy3KTmZq94C6IgEMWHgF+fZt+4RZpkQIiBug9a9ABVW6GtU1W8CR1czZXAW+zrxAzr2STIHm52qOItNnQnsbjUPJDDvwg9ySidU6Sn1WJIec1cTUTa87aEKkGk5uZeTshMEkMarZaam/glD+0ESWQQ4qBWS4keUClSc02Pt+gSeqPgQUwjSc11XU+1uZqZz5hCzfGWr02znzEJd+hOYnGpeSBVTCUbafIXMTeOC6R/3QhE6WcSreJt9vUUreKN62nmXlAyVyP0RhkRZYHZzNjegpA0Wl8FgaviTeZqerjEq5MYVPEODX4GqpeTbJTIEAu6k1gUxf3bYj3e6mq+6SveggSKrnFiYqyn6RNDglyfongQkLkaoTf8wGqFYIq3XvFxYlTxDg3q8dYX9ahKZfyVyfccUZJtXGpOiQyxoDuzRQmmisl7xMweKIoyUswljTb3eopS8VZaIWJECRRF6ZkHU5PJ22ZMnsggxEHpg7bAbGbuydLYrAkULfC3GT3+ym2OtwWSNEagrsZy9QBVaPWVmpv9jEm4Q3cSi8KDqcDmeIMQN0Xucmx2KW+zYlZn7vXMlgOb2oZmqG1oArMiSsVblOtTFIdZkpoTemMl+bBD6aF1r3hb4W8zUkFAUnN9UJ9/lJ5kk5+JhJGay+tp9mIE4Q7dSSxvrlbPZpb6A5eqmT2wyRKkAibC3GkkJT5WOVSUVpl3TUWR7osSKIrmEo/r6e+9jCB8YSWnan7o5hVvK1XzDa14a+aik7lacKgTu1w9YPZkr9nhxTGlZ57WUyjoTmJR+GEVN+PKuiZr9XgLEtiIMHcaQXMhRW5uYnm0KBVaUXqSRZhioDZTxH626nrzKjIIcXD1QVtHas5dzalCq1OPt7yevI+W1jM4MLHLtxgl8Db5GVO0irfZz5iEO3QnsSh4oEiNjw1olrditmTyF7EortGiuMS7GayZeKSYKDNARbk+5fOk6V/viXExkCgHSGZPZhBiYKWKt0sarZnjbYGkgqFz0eX1pJ55/czAeFLI7MlzUa5RbhJp9j2ccEf8XYfQZZY3Vme5itPsN0U+Ks3fhIJRiFJRdJvlbWL5vqIgMP31Ka3lEZNLo0VpLREpmUGIgZWcqpW50/L9kVzNQ4Pv10qPt7yecXLwSIQujaZAUR9VBldjmP1MRLhDdxILE0iAyvuR1S9qsyKK1FyUHlq32egmTmYoPd4ml6nxIBEr9JVHzSuNluNuIQ5B6mQGQYSKlYJThxwQuszArJNUMDSRQVJz3SBpdJhczWV1C62nWNCdxMLwANWfKibftEUIbLJULtxHG6QDlBkRRbqPZKfGmT/wFkSRgQdeNKwz+8g7nmyjijdhN6wUnPJDeKMcIFopqWCKRIYc3MTTeuo3/kqAM5GZ4eunVLxpPYWC7iQ2qHj7E0zxIFEEaTQGNVz2ZebAhkujzb6eoszyFsWsThSDNVFc4kVZT0IcuHzYCsEU319c5mpyj7cFkgqmcDWX15Ok5qEbAJILt7493iTdFxO6k1iY7ADGbqkr3ma/KaILtwgjxXiF1uzr6RZ4m3mcGFVobetBIEp7CSEGVgpOuXGVa/yVdZIKhiYyyFwtbD3eIuw5IiQyFLM6Wk+hoDuzheHBlD9VYXXgLcJNUYQKGHeZFeGmKELF21WhBdMjwvXJK2QieBC0SzZ/os0uvPDCC9C1a1dISEiAMWPGwMqVK71+7/z582HChAnQrl079jZ58mSf3x8prBScKi7cXGouH8bJ1Ty0REYzjWcLQ493szB7jlBmdQIUIwgXdCexMLwq7E+PN8/u4utXhJuiYhxn4sBGJHO19nKPd4kQgbf511OEwFuUuejuFW/zXp924N1334VbbrkF7r33Xli7di0MGTIEpkyZAsXFxR6/f8mSJXDJJZfA4sWLYfny5VBQUAAnn3wy7N+/H4zESuPEXBVa955kK1TzzbCePLiJs8C1YvTIO6p4h8esToQzJuGC7iQWhjtV++VqLlA/svogbuaRYnxOcqxAFe+quibFnMdsiBR4iyCNFikxlCnfy8y8nnbgqaeeghkzZsCVV14J/fv3h3nz5kFSUhIsWLDA4/e/9dZbcP3118PQoUOhb9++8NJLL0FLSwssWrQIjMRlQCZ+cMqnkPBAkVe8rVDNN7bHWyM1p0RG0JAZWHgSGfzaFOGMSbigO7Mderz9OKwqh3ABql/CSc0FWNP0RIdyMzerikCkCq0Q1ydfTwF2ARF65q1OQ0MDrFmzhsnFOdHR0exjrGb7Q21tLTQ2NkJmZqbX76mvr4fKykq3N72xUsXboZWacxduChRDk+63Gs8m/rVidHKIj2gT5ZxpVnjiQqRiBOGC7iQWhsuxy2sblVEjlql4ByCjN9xcTYA1ZYZ1fJZ3lTlVBGJVaM0fKCou8QIcgkRQEFid0tJSaG5uhtzcXLfP48dFRUV+/Yzbb78d8vPz3YJ3LXPmzIH09HTlDeXpemOlKmaMJqhRepKp4h1SkIh5SbxHNsjrSVLz4NEGhqKcM81+jXIokSEWdCexMBmJDuD3tyNtHFhFmjktSs+nSOPERJjlrVRoBdhkeGLIzNenSNnyTHk9axuaTdsKQfjmkUcegYULF8LHH3/MjNm8cccdd0BFRYXyVlhYqPtzsdKsa16h5QorXvGmHu/gUN8PG1taqOKt4zXKESF5LlQiQ7O+hLmJNfoJEOEDb27YG4mBFJpm5aQltF3xFkF3qu5fN3EFjPeIibLJmN3ZXKw53nJPspkVGQKtZ2p8LJPUYlUPX/MdMxKNfkq2Izs7G2JiYuDQoUNun8eP8/LyfP7bJ554ggXe33//PQwePNjn98bHx7O3cGKlirciNec93hZKKhi5nvweqczxpsA7aLR7jAjJczOjLeZQxVss6E5icfyd5S1cj7cAc7zluFuYTcYVeJtzTfnBUoREhmL+V9MATrlSbzZEmouOrRBK37xJr0+rExcXByNGjHAzRuNGaWPHjvX67x577DF48MEH4euvv4aRI0eCGbCSHNslNSczML2DRNxzuBM3rWfwODTS6Biq0OqbyBD/NmYr6H+XxfF3lrdoPd7ZSsXbnNVZd/Mq0frmzbmmIkn3eZCIh2CUR5sRkSrebiqCWgq8jQJHieFs7tdeew02bdoEM2fOhJqaGuZyjlx22WVMKs559NFH4e6772au5zj7G3vB8a26utrAv8JaBmQOjdESVbz165/FWd40xzt0qOKtL9ozEE++EWJAUnOLk+VnZVi0Hm9e8cYDVG1DEyTFme9SFm1N25u84i1ShTYpLoYd1DDwRkOw5PhY87rEC3J9iuDrYHWmTp0KJSUlcM8997AAGseEYSWbG67t3buXOZ1z5s6dy9zQL7jgArefg3PA77vvPjAKa1W8ozTmai2WGZVm1HriFoO3R+rx1gdtD7Ioe45Z0baEUiJDLMx3GiR0RXGqblNqLs8DFEQClKwKbDCpkJQZa+KeZBBLam5aV3NxNm3JJT4ODlTUMbl5QWYSmHU9RUhkuDnFmzQxZBdmzZrF3jyxZMkSt493794NZqReqXgLcnP2gUPeYLDiLblwW+dvM7KiiIkMvE54p5AV1BHmkUaLseeYFZKaiw3977JNxbstqblYmTMe2JjZYM0l5RXjZUbmauFRZZi1QiuSdF+U2eiEGNTJFW8rVIV5shx7vHl11ip/m1HwPaamoUn5nBXUEeaRRoux55gVkpqLDf3fsou5WpvjxFqEuyHyOeVmDWyUwFuQZIYo48REqdC2SzJ3hVYkszqEAm9CL6xU8eZ7Nr6euYTeKn+b0WZgNfWu9YyjsmLQaM+VouzhZoUq3mJD/7ssjjJ2q82Kt1jVRPVB3PQ9yYK8ynjF+0hto+KQayZc1ygI1pNs7uszRjSpuUnXkxAHKzl/q6Xm3DQOK2KijAY1I9x1G/1j+IgxURKUZjeskz6mtQwFGicmNnRntjgup2r/zNVE6fEWIbBxSXmjhanQ8vu5GddUNOm+4sJtwrUUUbpv9tc7IQ5Wcv7mh3BMlrr+LvETCmZYU17xtkKCxkjIXE1fYjRJNUpkiIX4uw7hd9+ur3nCyiFcoMyZv/3rxruagxDgZsiDxRITGqy5KrQg1vVp0kCRJzJEqeSQ1JzQA9wHrVTx5ondJjb6yjoSejOsKa94x9F6hgRJzfWFeubFhu4mFocf/nFDrvExT1i00VcIDxJNH9gItMlwTwAz9nmLVqHlgeIRk16ffJyYKNlysyfaCDFoULXRWMEwi1cTcQ+nirfe5mo0w1sPtHuMSMpKIaTmguzhhATdTSwOzrfGmcJtHVibBZNFBzKj3PjARpw1bZ9q3lneolZoKTGkb6Ktsq7JlB4EhBjwPmgkwQIVb+w/5gapSsXbAgkFI+GBYW29VPGmwDs0tO1houw5ZkWbuBAleU5I0N3EBvjT5y2iuZrZez5drtEgDGYeKcYTGaK0Q4hyfYrSCpGR6FA8CMyqIiDMD3f+xtsID1qtENSg1JxXvK0goTdTxZuk5qFB0mh9oUSG2JjibvLCCy9A165dISEhAcaMGQMrV670+r3z58+HCRMmQLt27djb5MmTfX4/4Z+zuZCBtzJOzJyHcNGk0W5ScxP2eNP4K3tfn/j/XRnRZtI1JcQaJRZlgQMrD2qw4m0l0zgzjBNzVbwpkREK2j2GKrShQdJ9sTH87vzuu+/CLbfcAvfeey+sXbsWhgwZAlOmTIHi4mKP379kyRK45JJLYPHixbB8+XIoKCiAk08+Gfbv3x/x526lWd4i9njzimJbxnFGm4HFCpjMMGPF29UOESVUwqu6vsltvq5ZEG0uugh984T54a9FqwRTfJyY2lzNChJ6I6GKt75olSWiJM/NCpnViY3hd5OnnnoKZsyYAVdeeSX0798f5s2bB0lJSbBgwQKP3//WW2/B9ddfD0OHDoW+ffvCSy+9BC0tLbBo0aKIP3drVbxd8z9FNI6r9WEcZxTNzeIFNi6peYN5peaCXKNpibHK68mMVW/RKt4i9M0T4vR4W6UqzF+/anM16vHWqcdbdjWnHm99pdGitIuZFZLui42hd5OGhgZYs2YNk4srTyg6mn2M1Wx/qK2thcbGRsjMzPT49fr6eqisrHR7sxv+9XiL9wJG4zh+eDKjwZoy/kqgNc1LS2DvD5QfBbMhmhkYyljb8UCRrk9d72VmTGQQYmClUWLaaiJPQFPFW+853hR4hwIFivpC0n2xMfRuUlpaCs3NzZCbm+v2efy4qKjIr59x++23Q35+vlvwrmbOnDmQnp6uvKE03W74Ix/mFW/RbohKNb/GvNJokda0d24Ke7+7rEapnpgF+RIVaj3NbLCmJNsESWQgVPEmQqW+0VrBlPp+iG0tCFW8Q4PmeOuLds8WaQ83c3sJR5RiBCEh9N3kkUcegYULF8LHH3/MjNk8cccdd0BFRYXyVlhYCLbt8a62Vo+32UeKiRh44zixdkkOwKe+7VA1mAmRe5LNGXiLl2zjI8UOmzDRRoiB0gdtkVnX6kM4D7yp4q33HG9aT10r3gLt4WaEEhliY2jgnZ2dDTExMXDo0CG3z+PHeXl5Pv/tE088wQLvb7/9FgYPHuz1++Lj4yEtLc3tzW7kyvLhvYdrLWNcJURgI9j4Ky6P7pOXyh5vLjJXW4aIySFFam7iirdIRjeZSQ7Tvt4J0czVhK47KKj37BoeeFPFOyRojre+xGjM1bQfE4FB0n2xMfRuEhcXByNGjHAzRuNGaWPHjvX67x577DF48MEH4euvv4aRI0dG6NmKS//8NDazdH/5Ua9yc6V/VlCpeanJKmDoss6N1kW7KfbNk5JTW4qqwIxmYLFCSs3NdX2KOBcdyZTbZsyocCEE6/F2WFBqXsel5lShDQW+x/CeeZKa6zOejSPSnmNGqOItNobfTXCUGM7mfu2112DTpk0wc+ZMqKmpYS7nyGWXXcbk4pxHH30U7r77buZ6jrO/sRcc36qrzSWLNRNpCQ7o0V7q3f19X7nPaqJIQY1aRl9caa7AhicyRLwp8or3lkPmCrxFTA6ZWpEh4HqauWeeEANl1rVF5MOoUuL7tktqbvjRzhIu3DWKq7k1rhXTjL+iy1MXDwIOJTLEItboJzB16lQoKSmBe+65hwXQOCYMK9nccG3v3r3M6Zwzd+5c5oZ+wQUXuP0cnAN+3333Rfz5i8KQThmwvbga1hVWwIl93c3s3PuRxboj9u0gBYkb9lcY/VQ8JjJEC2wQl9TcXIG3iBVaHiiasUIr4px5MycyCDGwWsWbS6Nxz1ECRap46+IUX8tdzS10rRgp3Vc+FuycaTao4i02hgfeyKxZs9ibJ5YsWeL28e7duyP0rKzF0IJ0+HDtPlhfaK2K99CCduz9xv0V0NDUYhpJGA8SRVzT3rlS4F1SVc8CHB7smKdCCwKagTWYds68SJs2T2QcqW1grQeiJbUI46mX53hbqYopBTItUE3jr3SB3xMbZCOMOI2LNBFixZtu27omMkTawwkTSM2JyDCkIIO9X7+vnPUfe+ufFe0F3DUrCTKSHKyKYSYzMLXUXCQXbiQlPhY6Zyaxx6ZaUwEr3mau0IroEs/N6vDlVX600einQ4gsNbdQFZMfxKvrGi3l2G4U2mQ5Vbz1W088Y2J7BKHf9UkJaLGgu4lNQMMszNqW1zZ6dDcX0TEawRv4UDmp8Ntez9V8IxC5x9utz9tEcnMRx7PxcXeHa80XeLuSbSDU6KS0hFjTGtYRAknNLVfxRldzqnjrQazmpmila8UI1C2MIiXOzYpWqi+aqtLu0N3ZJqAEG93NkXUe5OZ8pq+IL+Bhstzc099lisBbwI2mLwXeula8MeHFK21mQcSKN5IlO5sXV1HgTQSO1caJqfdt1zgxChRDQXsOMksLmxXWU6RWMbOiHccm2h5ud+glYCN4ZXh9YYVlKt7IsM684n0EzBbU4P0wWuCK9yYTBd4itkNgT3K2HCiuNdH1KWoiQ50UWrPbXOtJiEEd7/G2UHCqSM1lczUKvENDe0+0UpLG6J5kMlYLHZrjLTb0CrARQwrSlT5vKwQ12v713WW1pumlVYIaQTORPLjZdqhKuTaMRsQKLbZCjO+ZxR7/vL0UzAQ3ABRN5TKuZzZ7v8xk60mIgRUr3tiCgXD7Fiv9bUauJ4fWU8eKt1jbjSnRntNF28PtDt1NbDZSjDuAN8punVaoeKcn4pzyZPbYm2t7pBG1msjpmpXM5HW1Dc1QeKS1J4AR8Es2RthAsQzMRJPsai6aImO8vJ6oIODSWoIIvMfbOscf7T2RKt6hQRXvMPZ4C7bfmBEyVxMbupvYiG7ZycyYCA8e2t5dHiiKmjnjY8XMIjeXW+aF3WTQXKZn+xRTzfNW5ngLtqbje0mB4oZ95VBRax4nbhHnoiNdspKgU7tEaGx2wsrdh41+OoSwrubWCU61+7aVHNtN4WpO5mo6uprTtan7HG/B9nC7Q68AG4GyVy7L1hqRuSreYl4SSp+3SSreTXLkLfIN0WwGa01yyVskqTnSIT2RKTLwJbZ8p3nk0a656GKtpyTfl5IZP28zz3oSYmDFird2ri8FivquJ5mr6RcoijRFQ5RWCNGKEXaHXgK2NVgrF360kKfAGxMKZuhJVqqJmg1cJPp2MFfgzf+3iqjKGG/CvmRZaS5kcoj6vIlgqbeiuZomYU4V79DQFiCslKQxvOIt4H5j+oq3gGciOyMNRCVs1+etNVgTveLdJzcVEh0xUFXXBDtLq6FnjhQ0Gt6PLPAm0ydPGj+3uagSzIDIffPje7WH15bvgWUmqtCKbKjIA29sgyiuqoOc1ASjnxIhCHWyuVqChYIphybBayUZvRGQ1Dx8c9FFLkboSXNzMzQ2Nga9d3dMdV2TLU0NUFdH6xpOHA4HxMTocx+gwNtmDJadzbcVV0N1fROkxMdaoscbb+yDOqXDyl2HYe3ecsMDby41F03G60lqjm7x2Bdp9GFOcTUXcE3HdM9kAS6uZeHhWijITDL6KQmdyMD56APy0+CPA5WwfEcZnD20o9FPiRAEK1a8yQxMX0hqHkapucDFCD1wOp1QVFQE5eWhtUXePzEHuLaz/NB+qCqx97pGgoyMDMjLy2PtbqFAgbfNwMpQx4xE2F9+FDbsq4CxPbLce5IFPISr5eYYeKPc/KKRBaYwVxM1kYHkpMZDRpIDymsbYXtxNQzsKCVtDK/QCrhxpyU4YEindJYU+mVHKUzN7Gz0UxI68ObyfQy8l24rpcCb8BsrjxPjGJ0ktV7F2zrXiuHjxATdb/SCB905OTmQlJQUdBDXmFTFgnika/sUN1UBoS+4zrW1tVBcXMw+7tChQ0g/jwJvm87zxsAb5eY88BZ1VJOaYXL/+m97jTdYE3HmtBbcEFDCv2LXYdbnbXTg7ap4g7CBIgbeOFZs6igTBN6CX6MoN//vTzvZfHTcGEPNQhP2oE6ueFspONUGinF0CNe3x5t65kNCfa4UuRihh7ycB91ZWdLZO1iiY+sVL6HExARh20RFITExkb3H4Bv//4UiO6f/U3bu81YZrDVbouItjRTbUlRp+HxfK6ynm7P5oSrDq93yHiNkxZv3eSMYKJrBAFD0ivfobplMAnqwog52ltYY/XQIQbCiq7n60I2vCbtXFfXumadEhn7SfVETvXrAe7qx0h0q7qto3zWNJPz/W7C9+Ry6m9gQ9UgxLlXh5moiZyNz0xKgQ3oCc7/esL/C0OdiBQWBu8FalSmqs54cfEWaKJAUFwOHaxpgkwkM61xz0UFIsGI5souUbDOTaR1hbqwpNXftM1YyjTNNz7yF1BHGz/EW+0ykB3qos9Q/glY0MuilqqM7tA0Z1DGdHTqwUvSTfGAVvfrVap63wXJzq6wnHym2+WClkqQxcj0RQeNuVoka0y1TqXobjesaFXRBaawYEYK5mqWk5qrsGQWJoUM93vqi3mNELu6YC+tH3lFRUfDJJ5/o/r1GQ3cTG5IcHwvTj+nCHj/17RYWUFklUBxWIFXAVuwqM/R5KOsZJb7UHGfCFlfVw/ebJGMJI6uzol+jXG6OhmBGY4VrdEIvKfD+dUcZNHGZCUF4AVs8GuTrxErBlDqYoRneoaNWVeHtkYLF0CBzNf2JdMX7iiuuYMEtvsXFxUHPnj3hgQcegKam8LV1Hjx4EE499VTdv9do6A5tU647oQeTva7fV8ECKtHHiXGO692e3ZCWbCkxtKoo8ugrNUlxsXDVuG7s8SNfbTIsuHGreAscKKLBGrJq92E2os1I+JoKXPCGAfnpkJ7ogKr6JnYvIwhf8KDbapVht8CbZk7r2pOMCRoybtRvPUVO9JoJ9SpG6vo85ZRTWIC7bds2+L//+z+477774PHHH2/1fQ0NDbr8vry8PIiPj9f9e41G4CMXEQrZKfFwxbFd2eMnv90CjfKBRGTZKdInL1Wp5v/z4w2GBTctFklk8CRNuyQH7CipgfdW7zN0PJvoFe/euSlsTBs6Kz/93VZDnwtPDol8EMJrYVxPyR328W82G57MIMyN+vqwUi+0W6BIFe+QUe8xZKym8xxvgfdvUyEvY1QEdeYY2GKA26VLF5g5cyZMnjwZPvvsM1YNP+ecc+Dhhx+G/Px86NOnD/v+wsJCuOiii9j868zMTDj77LNh9+7dbj9zwYIFMGDAAPazcUzXrFmzPMrHMZjHr+H3JCQksOcwZ84cj9+LbNiwAU488UTmRo4O8tdccw1UV1crX+fP+YknnmA/E7/nhhtuCNk4zR/ojmJjrjmuO6TGxzLjrI0HKi0TKN46pQ8LbnaX1cILi7cb8hy4WZ3oFW8+g/qmSb3Y46e/32qIYzyfMy96oIibwz9O7cse4yisl5buNH4uuuDX6I0n9oKU+Fj4dedhuOW9dW7qCILw5GiO17yV5t6qpdFU8dZ3Pa2kjDDDeoq+34RlRnRDU8Bv6FWBicS6puag/j2+herbg0Etr24vWrQItmzZAt999x188cUXLICdMmUKpKamwtKlS+Hnn3+GlJQUVjXn/2bu3Lks2MWgGANlDOJRwu6JZ599ln39vffeY7/nrbfegq5dpeKhlpqaGva727VrB6tWrYL3338fvv/+e7egHlm8eDHs2LGDvX/ttdfg1VdfZW/hhuZ425iMpDi4ekI3eOb7bSrZqTUCxfvPGgAz31oL837cAWcNyYdeuZJJWOT7Z8ESTBvTBV75eTfsPVwLLy3dBbMnS4F4pKuzGHOLfo2eN7wTHKqsh0e/3gwPfbkJslLi4NxhnSL+PKzSDtGvQxq8OH0EXPHKKvjfhiLITN4ID549kOShhFdjNSv1dyNU8dYXdQHCateKEVDF2ztHG5uh/z3fGPK7/3xgCmsnDBQM2DHQ/uabb+DGG2+EkpISSE5Ohpdeeon1fyNvvvkmtLS0sM/xvfiVV15h1e8lS5bAySefDA899BCTrM+ePVv52aNGjfL4O/fu3Qu9evWC8ePHs5+HFW9vvP3221BXVwevv/46e17I888/D2eeeSY8+uijkJubyz6HgTl+Hmdy9+3bF04//XT2d82YMQPCCd1RbM5V47uxHkmOFSreyCkD82ByvxxobHbCnR9viPjcZG4GJuroK0+O3H8/RZIP/fenHVBSVR/R388L3iJXu9Vcd3x3pXf+tvd/hyVbIm9cx9fUCq/5Y3tmw9NTh7LEzJu/7oVnFxmjdCHMDVaHrOZojlCPt77EqBIZuPcRoUHjxKwBVrKxao1SbzQymzp1KuvzRgYNGqQE3cj69eth+/btrOKN/wbfUG5eV1fHqszFxcVw4MABmDRpkl+/G6Xh69atYzL2m266Cb799luv37tp0yYYMmSIEnQj48aNY4kArJZzUOKOQTcHJef4vMINVbxtDlaHrz2+Ozz29RZL3RQxI3b/2QPhlx0/wqrdR+C91YVw8ejOBkjNwTKcPqgDzO+0k5lY/XvRVnjonEER+91Wqc6qr8+7Tu8HZTX18Om6AzDzzbXw/nVjYWDH9Ig9B0XlYpFkxumDO8DhmgFw96d/sJaIDukJcNGoAqOfFmEirFvxVknNLZZUMAKHWmpOiYyQIXM17yQ6YljlOVC2l1RDXUMzO7Oj6ivY3x0IEydOZPJwDLCxlzs21hVCqoNcBPupR4wYwSThWtq3bw/RAR6Ohw8fDrt27YKvvvqKycaxdxx7zD/44AMIFofDVXTk5zIMzsONtXYfIijQZC07RcpUZSa7Mlai0zEjEW45qTd7/PCXm2B3aU3EfrdV+me1N6U7TuvHHr+zshDWFZZHfj0ttGljEuHxC4awkVgoN7v1/fXQIPegRjI5ZKVrdPrYrnDTiVKP2H2f/wGFh2uNfkqEiaiXK95WC7wdJI3WFfU9kdYzdNTKP6skz/U8V6HcO+A3RyxLsiU6gvi38lug7VgYXGMPdufOnd2Cbm+BMrqf5+TksH+jfktPT2eVcOzRRmm3v6SlpbEq+/z58+Hdd9+FDz/8EA4fPtzq+/r168cq7tjrzcEecwz2ufGbkdAdhWAvwIXXjIV5lw6H3hHuhY5EUmFkl3Zs3NC1b6xhhhKRwDUX3VovsWO6Z7HKN/59176xGoor6yLye60yZ14LyhifmTqUJbzQ5HDukh0Rb4ew2prePLk3jO6aCbUNzazNJFQDGcI64DQBK1aF1fsMmYHpW6ElqXnoqLcYK7Q2mQFlFU26nNOmTYPs7GzmZI7malitxt7um266Cfbtk6bjoEz9ySefZMZpGKSvXbsWnnvuOY8/76mnnoJ33nkHNm/eDFu3bmWGaeiwjj3jnn43yuEvv/xy2LhxIzNPw1706dOnK/3dRkJ3FILRMycFThnYAawGSvBemDYc2qfGw5ZDVfCPDyNzELeauZqaR84fxK4XNAi77s01ShUpItJ9C65nVko83Htmf/b4+cXbYEtRVUR+r9Wk5uqKCl6jWKlauq0UPlhjzAg8wnxYteKtDhQTyFwtZMhcTV+wssrXlCreeo8TMydJSUnw008/ser4eeedx6rQV199Nevxxso1goHxM888A//5z39Yv/UZZ5zBAnBPYIX8scceg5EjRzIDNhxL9r///c+jZB1/Nxq/YTUcv/eCCy5gveRopGYGqMebsDy5aQnwwl+Gw1/m/wqfrT8AQwoy4OrxkrFV2GckW3CTSU1wwPzLRsLZzy+DtXvL4Z5P/mCBTjhdpBWzOguNAFKDzvufrz8A328qhr9/+Dt8NPPYsF87VmyH4HRvnwJ/O6k3PPLVZnjwiz/h+N7tISctweinRZhknJjV+nYdaldzi/1tho8To/XUBdxnMIFupXYxI+GrGKnV9DVmy9vXsCKNY7p8ce2117I3T6iLZOg07sttXFtQQ7O3H374IaDnjEmASGDNUyxBaBjdLRPulPuT//W/TbBiZ1lYf59VpdGcbtnJ8Owlw1gF+t3VhfDGr3vC+vusWp3lYNICzepS42NhfWE5vPLzrrD/Tp4csqr076/ju8GgjulQWdcEd3+6kSTnBJt7a8WRW2qpOVW8Q4d6vPWH7zNW3W8ijVLooOUUDrqjELbhynFd4eyh+SyIu+Ht36CoInz9yVYPvJET+uTA30/pyx4/8Pmf8M7KvWELblzrCZYlLz0B7jxdSg498e0W2BVmM0AlmWHRaxTVEY+eP5gd9L754xB8ueGg0U+JMBg7VLyt1r9uvILAwptOBOFqNavuN8ZVvGk9RYPuKIStMoRzzhsEffNSobQ6vP3JVq/Qcq49rjucMzSfScju+GgDXP7KKjhYcTR8RmAWX8+LRxXAsT2ymAnUWc8vg5eW7gyb07nLh8C6a9o/Pw2uP6EHezx74Tq459ONcKSmweinRRhEvUUr3u7SaGv9bYZXvC12rRgFr3Rbeb+JJLSM4kJ3FMJ2Du4vTh8J6YkONg4L+5PDUaVVepItnt3FZMaTFw2Ff57Wj7m//rS1BE5++id4f3Whrutq9eqsej2fuHAIDMhPg6q6Jnjoy01wyjM/waJNh3S/Tl2z0cHS3HBiTzbjG6+h15fvgROeWMKk/I3NkRvdRpiDOjmJlWCxird6n6GKt76JjDgry6wMSGbEWNFx1kAoABcPuqMQtqNzVhI8p+pPfmvF3vC5cFs8UOQb6ozjusP/bpoAQwsyWMB42we/wy3v6TeX2g7SfU5+RiJ8Nms8PHr+IMhOiYOdpTVw9Wur4Ya31yo9qqGCQTyP461egUBZMZorvv3XMUztUnG0Ee7//E8487llcKBcf3UGYV7q5XFiVqtiql3NqeKt83pSIkMXqOKtLyQxFxe6QxO25Lje7ZX+5Ps//wNW7z6s68+3g4xXC44Y++C6sXD7KX3ZJvvxb/vhqldXQVVdY8g/206BN/87p47qDItvPQGuPb476zn834Yitp419U26rSf/XXbg2J7Z8OVNE+Bf5w5S5qZfOG952HvpCfNg1XFi6tcwVbz1VRBQxVsfeKXbLvtNuCFvNXGhOwphW7A/GSWojc1OuO7NtfDl7wd1qyjyUU3qzLldDFRmntADXr5iFCTFxcCy7aVw0X9/heLKOn3Gs9kokcFHt91xaj94/aoxkBwXA7/sKINpL62A8toGXdbTbgch/Fv/MqYzfH7jeOienQz7y4+y4HvTwUqjnxoRAdA7wYrBqUMVHJKreeiQq3n45Pt22m8iQTjHuBLhge4ohK1vWI9fMFgxW0Mp76iHv4d/fPg7GzfGg+eQpOY2vSni3OR3rxnLpNIY1Jz7n19gS1FV0D+vRVas23XTHtsjC96ecQxkJEneBBe/+CsUVwWfzLBjxVtNx4xEePfasdCvQxp77U/973JYu/eI0U+LCDNWrXirK7RWc2w33KyOEhn69njbcL8JBzY9WlqCWKOfAEEYbbaGAQ26R3+67gCrgC1cVcje8HB+7rCOcO7wjtCjfUpwLtw23mQGdUqHj2aOg8tfWcnkvKf++yc4Y3A+q4hjwBOUEZiNd5shBRksmTH95RVMJj3piR+hX34aSxz1zUuDIQXpMCA/PeDA265r2j41HhZecwyT76/Zc4QF37iOuJ598lKZI/qYblm2fg1bDauOE1Mrq6jire96ktRc5x5vup/q2uNNqykedEchbA/2e2K/99K/T4R3ZhwDF43sBCnxsSwIf37xdpj05I9w9vPLmBTdX+zWk+zLyA77vif3ywFcks/WH4BT/70Urn51Ffy+r9zvn8PVB3ZfTwwI379uLHTLToaq+iZYueswc+q+8+MNcPqzy2DG66thb1mt3woCu68pTjd44+rRcEKf9qzlZMP+Cnh/zT7mJv+X+SvgjOeWMfULYQ14K1GCpceJWSupYPw4MVpPPZMZdmsXCxfKMkbZS6X6ySefsMe7d+9mH69btw5Ew1q7D0GEADqQo6T3sQuGwOq7JjPn8xP75rBNeP2+CiZF/9u766DSD7MwO5qreSMrJR5eunwUfHHjeNZTj0uyaHMxnD/3F/hle6lfP8Mu48T8oUtWMnz7t+PYej554RC45rjuMKFXNrtOv/vzEEx+6kd4/JvNPk3Y3Hq8bX6NourllStGwQ//dzzMnTYcZk/qBVMG5EJqQixrk5j64q8w6+215IBuAajiTQQu3af11IMYOTlEe7i+RGo1r7jiChbo4pvD4YBu3brB3//+d6irC82/x46Q1JwgPIDmO2cOyWdv2AOKc3/nLtnBnLqxyvjMxUNhVNdMr/+eKt6tGdgxnY112llSDQ9+8Scs3lIC176xhvXaoqzXn555q89FD8RMCdcT3zjbDlWxMVloaPfC4h3w4Zr9cMdpfeGsIfmtDFjcpOa0pmx9urdPYW+nDurAPne4pgGe/HYLvL1yL3zx+0H4ftMhuP6EnizRYTVzLvsF3tYKpqjirS/qfTvOYteKUfC9m/ZwnV3NI5g4P+WUU+CVV16BxsZGWLNmDVx++eXs9z/66KMRew5WgO4oBNEG2SnxcNuUvvDetWOhU7tEJkHHftA5X22CIzUNvl24aZNpBQY3cy8dAWO6ZTK59BWvrIR9R2r965m3eXXWF71yU5ls+r/TR0BBZiIUVdbB7IXrWMX2zwOVHteTDkG+W1AePncQUxaM7prJHLGf+m4rnPT0j/DtH0VsFjohFvWK1DzGwnOn6VgXKhhM8HsjJTL0gczV9MWIVYyPj4e8vDwoKCiAc845ByZPngzfffcd+1pLSwvMmTOHVcITExNhyJAh8MEHH7j9+z/++APOOOMMSEtLg9TUVJgwYQLs2LGDfW3VqlVw0kknQXZ2NqSnp8Pxxx8Pa9euBStCd2iC8JORXTPhq9kT4LxhHVm/8n9/3AnjHv0BHv7yz1bjsqgn2Td48H3xspHQOzcFiqvq4YpXVvkckeWSmkfwSQp6YJwyIA+++9vxcOvJvZnsFBUaZzy3FO7+ZCNTb7i57tP12SZoWPfutcfAs5cMg7y0BCg8fBSueWMNXP7KKth6KHinfiLy1Fm04u1Q3RitllQwCr53W+1aMQqeyLCrmadXMIHbUBPwW1RTLUQ11kJ0Y21Q/569hZA83rhxI/zyyy8QFxfHPsag+/XXX4d58+axAPtvf/sbXHrppfDjjz+yr+/fvx+OO+44Frz/8MMPrGJ+1VVXQVOT1BJXVVXFKujLli2DX3/9FXr16gWnnXYa+7zVIKk5QQQ4V/mpqUPhlIF58PT321gP6Pylu+C15Xvg/OGd4LzhHWFE53a2Hyfmr7HVa1eNhvP+8wtsL65mgcylYzozN/Se7VPYTHAOucQHBh6+Z53YC84d3gn+9eUm+HLDQXjj1z2wcNVeOKl/LpzQO4d9HykI/E9ooGR/Ut8ceGHxdnhp6S74aWsJnLy1hFXDLx5dAKcN6kBBjyAVb6tVhdX3xQSq0OrWzoOtCSQ11we+n5PKSgMGzv/KD/if5cpvIXHnAYC4ZL+//YsvvoCUlBQWLNfX10N0dDQ8//zz7PG//vUv+P7772Hs2LHse7t3786C6P/+97+sev3CCy+wSvbChQtZjzjSu3dv5WefeOKJbr/rxRdfhIyMDBa4Y5XcSlDgTRBBcPKAPBbALNlSwpzPcRzROyv3sjesivHNmjYZ33RIT4RXrxwNF8z7BdYXlrM3BCu1WGnEPno0vKusk7KilMgIDByJ98K04TBteyk8+s0Wtr7/21DE3hBKZARGcnwsm4Bw4cgCePSrzfDtn0Wwcvdh9nbfZ3+w8YN/ndAdCjKTjH6qhAca5Iq31RIkDllqjrdH/pgIDap4h6niTXuOsEycOBHmzp0LNTU18PTTT0NsbCycf/75rMJdW1vLpOJqGhoaYNiwYewxuo+jtNwhB91aDh06BHfddRcsWbIEiouLobm5mf3MvXv3gtWgwJsgQqiCTeybw0YRoZz3vdX7WO8n9tZyaJPxb0TWRzOPhXdXFbJxTn8cqITq+iaWzMC3eT9KPUAIBYrBcWzPbPi0Zzbr9caqN5oEVtU1MdUBETg4zm3e9BFwsOIofLB6HyxcVci8H1D5ct7wThR4m3ycmNWCKazO8mp3JM2WrAy/RnDqAaFjjzddnu44kqTKc4CUVNdBUUU9ZCQ6gt9v8HcHQHJyMvTs2ZM9XrBgAevjfvnll2HgwIHsc19++SV07NjR7d+gtBzBvm9fXH755VBWVgb//ve/oUuXLuzfYfUcg3erQXcUgggRPOiM6Z7F3uqbBsLSraVM2osydAzKCf+Mwe46o7/SH7+rrAZ+21vOZigv31kG+44cVSrkRPCge/wDZw+EO07tB4u3FENnChBDAq/HGyf1ghsm9mRu8ku3lcDgTi6neSuCksHHH38cioqK2MHrueeeg9GjR3v9/vfffx/uvvtuNncV+/bQARd794ygc1YSq3ajcsFK4OsYR+D1aJ9i9FOxDLdN6cOSwOhDQoRObpoUgOWkJRj9VMwFJsoCkHtzHAkOcNbGQExCPEBc5M9FKDO/88474ZZbboGtW7eyQBmr0ygr98TgwYPhtddeY47onqreP//8M/znP/9R9obCwkIoLfVv3KxoWGv3IQiDQQfUyf1z2RsRHKgSwAMkvl0wohP7XOHhWmZkNbKL9xFuhP8kxsWwnmRCv2v2uN7t2ZuVeffdd9lBCw10xowZA8888wxMmTIFtmzZAjk5km+AGjTfueSSS5jxDvbpvf3228wNF91qeZUkkiy8Ruo/tOL199/pI41+GpYC20kuNPpJWAhs0Tm5fx4c2yPL6KdiCVCthsqrpDjj2mYuvPBCuO2221gf96233soM1dDdfPz48VBRUcGCaXQwx2r2rFmzWJL24osvhjvuuIP1e6OJGiZt+/Tpw5Kyb7zxBowcORIqKyvZz22rSi4q1tJbEQRhSVBKNalfLqQnkTSaIIziqaeeghkzZsCVV14J/fv3ZwF4UlISkx16AmWDOPsVD1H9+vWDBx98EIYPH84MeQiCsA9pCQ6WmFSbphKhKS3R7DfGwFEv2OONAfVjjz3GgmlUNmGSFe/1eN9H6TmOF0OysrKYm3l1dTWrio8YMQLmz5+vVL9Rsn7kyBG2P0yfPh1uuukmj8lcKxDltNkwUsykYKYFszGYiSEIgiAIs2G2vQp77TDIxtmsWLXmYDWjvLwcPv3001b/pnPnzqxCfvPNNyufu/fee+GTTz6B9evXC7kOBEEQwVBXVwe7du1iwWhCAknurfT/L5B9iqTmBEEQBEH4BPvt0Gk2N9e9jQY/3rx5s8d/g33gnr4fP+8NHE2Db+oDDUEQBEFYAdJ8EARBEARhClCqiJUD/lZQUGD0UyIIgiAIXaDAmyAIgiAIn2RnZ0NMTAybt6oGP87Ly/P4b/DzgXw/gr2CKNfjb+huSxAEQRBWgAJvgiAIgiB8EhcXxwxxFi1apHwOHWzxY5y36gn8vPr7ke+++87r9yM4lgZ75NRvBEEQBGEFqMebIAiCIIg2QaM0NFPDkS84BgbHidXU1DCXc+Syyy6Djh07Mrk4Mnv2bOZg++STT8Lpp58OCxcuhNWrV8OLL75o8F9CEARBEJGHAm+CIAiCINpk6tSpUFJSAvfccw8zSBs6dCh8/fXXioHa3r17IVo13ubYY49ls7vvuusuuPPOO9msVnQ0N2KGN0EQhBmw2TApy+DU6f8bjRMjCIIgCJNBe5UErQNBEFYAp0Js3bqVzafGudaEWJSVlUFxcTH07t2b+Z2ooXFiBEEQBEEQBEEQJgCDtYyMDBa8IUlJSRAVFWX00yLaAOvTtbW17P8b/v/TBt2BQoE3QRAEQRAEQRBEGOETHXjwTYgDBt2+JnL4CwXeBEEQBEEQBEEQYQQr3B06dGBy88bGRqOfDuEnDocj5Eo3hwJvgiAIgiAIgiCICIBBnF6BHCEWNMebIAiCIAiCIAiCIMIIBd4EQRAEQRAEQRAEEUYo8CYIgiAIgiAIgiCIMGK7Hm8+thxnrhEEQRCEGeF7FN+z7Art2QRBEIRV9mvbBd5VVVXsfUFBgdFPhSAIgiDa3LPS09PBrtCeTRAEQVhlv45y2iyd3tLSAgcOHIDU1FRdBtdjlgMPBIWFhZCWlqbLc7QztJ76QuupL7Se+kNr6hncmnETz8/Ph+ho+3aF6bln07WmL7Se+kNrqi+0nvpC6xn6fm27ijcuSKdOnXT/uXgB0kWoH7Se+kLrqS+0nvpDa9oaO1e6w7ln07WmL7Se+kNrqi+0nvpC6xn8fm3fNDpBEARBEARBEARBRAAKvAmCIAiCIAiCIAgijFDgHSLx8fFw7733svdE6NB66gutp77QeuoPrSkRKeha0xdaT/2hNdUXWk99ofUMHduZqxEEQRAEQRAEQRBEJKGKN0EQBEEQBEEQBEGEEQq8CYIgCIIgCIIgCCKMUOBNEARBEARBEARBEGGEAu8QeOGFF6Br166QkJAAY8aMgZUrVxr9lIRgzpw5MGrUKEhNTYWcnBw455xzYMuWLW7fU1dXBzfccANkZWVBSkoKnH/++XDo0CHDnrNIPPLIIxAVFQU333yz8jlaz8DZv38/XHrppWzNEhMTYdCgQbB69Wrl62iPcc8990CHDh3Y1ydPngzbtm0z9DmblebmZrj77ruhW7dubK169OgBDz74IFtDDq0nEW5ozw4O2rPDC+3ZoUP7tX7Qfh1m0FyNCJyFCxc64+LinAsWLHD+8ccfzhkzZjgzMjKchw4dMvqpmZ4pU6Y4X3nlFefGjRud69atc5522mnOzp07O6urq5Xvue6665wFBQXORYsWOVevXu085phjnMcee6yhz1sEVq5c6ezatatz8ODBztmzZyufp/UMjMOHDzu7dOnivOKKK5wrVqxw7ty50/nNN984t2/frnzPI4884kxPT3d+8sknzvXr1zvPOussZ7du3ZxHjx419LmbkYcfftiZlZXl/OKLL5y7du1yvv/++86UlBTnv//9b+V7aD2JcEJ7dvDQnh0+aM8OHdqv9YX26/BCgXeQjB492nnDDTcoHzc3Nzvz8/Odc+bMMfR5iUhxcTGm0Zw//vgj+7i8vNzpcDjYi52zadMm9j3Lly838Jmam6qqKmevXr2c3333nfP4449XNnFaz8C5/fbbnePHj/f69ZaWFmdeXp7z8ccfVz6H6xwfH+985513IvQsxeH00093XnXVVW6fO++885zTpk1jj2k9iXBDe7Z+0J6tD7Rn6wPt1/pC+3V4Ial5EDQ0NMCaNWuYtIITHR3NPl6+fLmhz01EKioq2PvMzEz2Hte2sbHRbX379u0LnTt3pvX1AcrSTj/9dLd1Q2g9A+ezzz6DkSNHwoUXXsiklcOGDYP58+crX9+1axcUFRW5rWl6ejqTr9KatubYY4+FRYsWwdatW9nH69evh2XLlsGpp57KPqb1JMIJ7dn6Qnu2PtCerQ+0X+sL7dfhJTbMP9+SlJaWsh6I3Nxct8/jx5s3bzbseYlIS0sL62saN24cDBw4kH0OX9BxcXGQkZHRan3xa0RrFi5cCGvXroVVq1a1+hqtZ+Ds3LkT5s6dC7fccgvceeedbF1vuukmto6XX365sm6e7gG0pq35xz/+AZWVlezwGBMTw+6fDz/8MEybNo19ndaTCCe0Z+sH7dn6QHu2ftB+rS+0X4cXCrwJwzO+GzduZNk0IjgKCwth9uzZ8N133zHTIEKfwyVm0P/1r3+xjzGDjtfpvHnz2EZOBMZ7770Hb731Frz99tswYMAAWLduHTu85+fn03oShEDQnh06tGfrC+3X+kL7dXghqXkQZGdnsyyQ1mESP87LyzPseYnGrFmz4IsvvoDFixdDp06dlM/jGqI0sLy83O37aX09g7K04uJiGD58OMTGxrK3H3/8EZ599ln2GLOQtJ6BgU6d/fv3d/tcv379YO/evewxXze6B/jHbbfdxrLoF198MXObnT59Ovztb39jbskIrScRTmjP1gfas/WB9mx9of1aX2i/Di8UeAcByldGjBjBeiDUGTf8eOzYsYY+NxFAUz/cwD/++GP44Ycf2MgCNbi2DofDbX1xdAneRGl9WzNp0iTYsGEDy0ryN8z+oiyIP6b1DAyUUWrH5WC/U5cuXdhjvGZxg1GvKUqzVqxYQWvqgdraWtZTqwYDIbxvIrSeRDihPTs0aM/WF9qz9YX2a32h/TrMhNm8zdKjSdDB79VXX3X++eefzmuuuYaNJikqKjL6qZmemTNnsjEES5YscR48eFB5q62tdRulgeNKfvjhBzZKY+zYseyN8A+1QypC6xn4iJfY2Fg2VmPbtm3Ot956y5mUlOR888033cZp4Gv+008/df7+++/Os88+m8ZpeOHyyy93duzYURlP8tFHHzmzs7Odf//735XvofUkwgnt2cFDe3b4oT07eGi/1hfar8MLBd4h8Nxzz7EbI84GxVElv/76q9FPSQgw3+PpDeeEcvDFe/311zvbtWvHbqDnnnsu2+iJ4DZxWs/A+fzzz50DBw5kh/W+ffs6X3zxRbev40iNu+++25mbm8u+Z9KkSc4tW7YY9nzNTGVlJbse8X6ZkJDg7N69u/Of//yns76+XvkeWk8i3NCeHRy0Z4cf2rNDg/Zr/aD9OrxE4X+MrroTBEEQBEEQBEEQhFWhHm+CIAiCIAiCIAiCCCMUeBMEQRAEQRAEQRBEGKHAmyAIgiAIgiAIgiDCCAXeBEEQBEEQBEEQBBFGKPAmCIIgCIIgCIIgiDBCgTdBEARBEARBEARBhBEKvAmCIAiCIAiCIAgijFDgTRAEQRAEQRAEQRBhhAJvgiAMIyoqCj755BOjnwZBEARBED6g/ZogQocCb4KwKVdccQXbSLVvp5xyitFPjSAIgiAIGdqvCcIaxBr9BAiCMA7ctF955RW3z8XHxxv2fAiCIAiCaA3t1wQhPlTxJggbg5t2Xl6e21u7du3Y1zCbPnfuXDj11FMhMTERunfvDh988IHbv9+wYQOceOKJ7OtZWVlwzTXXQHV1tdv3LFiwAAYMGMB+V4cOHWDWrFluXy8tLYVzzz0XkpKSoFevXvDZZ59F4C8nCIIgCHGg/ZogxIcCb4IgvHL33XfD+eefD+vXr4dp06bBxRdfDJs2bWJfq6mpgSlTprCNf9WqVfD+++/D999/77ZR40HghhtuYBs8bvq4Sffs2dPtd9x///1w0UUXwe+//w6nnXYa+z2HDx+O+N9KEARBEKJC+zVBCICTIAhbcvnllztjYmKcycnJbm8PP/ww+zreHq677jq3fzNmzBjnzJkz2eMXX3zR2a5dO2d1dbXy9S+//NIZHR3tLCoqYh/n5+c7//nPf3p9Dvg77rrrLuVj/Fn4ua+++kr3v5cgCIIgRIT2a4KwBtTjTRA2ZuLEiSzLrSYzM1N5PHbsWLev4cfr1q1jjzGTPmTIEEhOTla+Pm7cOGhpaYEtW7Yw6duBAwdg0qRJPp/D4MGDlcf4s9LS0qC4uDjkv40gCIIgrALt1wQhPhR4E4SNwY1TKyXTC+wj8weHw+H2MR4A8DBAEARBEIQE7dcEIT7U400QhFd+/fXXVh/369ePPcb32EuGvWOcn3/+GaKjo6FPnz6QmpoKXbt2hUWLFkX8eRMEQRCEnaD9miDMD1W8CcLG1NfXQ1FRkdvnYmNjITs7mz1GA5aRI0fC+PHj4a233oKVK1fCyy+/zL6Gpir33nsvXH755XDfffdBSUkJ3HjjjTB9+nTIzc1l34Ofv+666yAnJ4e5rVZVVbHNHr+PIAiCIAj/oP2aIMSHAm+CsDFff/01GxmiBrPfmzdvVhxMFy5cCNdffz37vnfeeQf69+/PvobjRL755huYPXs2jBo1in2MjqpPPfWU8rNwk6+rq4Onn34abr31VnZAuOCCCyL8VxIEQRCE2NB+TRDiE4UOa0Y/CYIgzAf2bn388cdwzjnnGP1UCIIgCILwAu3XBCEG1ONNEARBEARBEARBEGGEAm+CIAiCIAiCIAiCCCMkNScIgiAIgiAIgiCIMEIVb4IgCIIgCIIgCIIIIxR4EwRBEARBEARBEEQYocCbIAiCIAiCIAiCIMIIBd4EQRAEQRAEQRAEEUYo8CYIgiAIgiAIgiCIMEKBN0EQBEEQBEEQBEGEEQq8CYIgCIIgCIIgCCKMUOBNEARBEARBEARBEGGEAm+CIAiCIAiCIAiCgPDx/8XkuICQkRwTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11. 학습 결과 시각화\n",
    "results_csv = os.path.join(BASE_DIR, 'acne_yolo', 'results.csv')\n",
    "if os.path.exists(results_csv):\n",
    "    results_df = pd.read_csv(results_csv)\n",
    "    print(\"Available columns:\", results_df.columns.tolist())\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(results_df['train/box_loss'], label='Train Box Loss')\n",
    "    plt.plot(results_df['val/box_loss'], label='Val Box Loss')\n",
    "    plt.title('Box Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(results_df['metrics/precision(B)'], label='Precision')\n",
    "    plt.plot(results_df['metrics/recall(B)'], label='Recall')\n",
    "    plt.title('Precision & Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"[ERROR] Results CSV not found at: {results_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd1fcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 이미지에서 여드름 감지 함수\n",
    "def detect_acne_image(image_path, conf_threshold=0.3, save_output=True):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERROR] Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # 416x416\n",
    "    results = model.predict(img, conf=conf_threshold, device=DEVICE, verbose=True)\n",
    "    print(f\"Number of detections: {len(results[0].boxes)}\")\n",
    "    \n",
    "    img_with_boxes = img.copy()\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()\n",
    "        scores = result.boxes.conf.cpu().numpy()\n",
    "        classes = result.boxes.cls.cpu().numpy()\n",
    "        \n",
    "        for box, score, cls in zip(boxes, scores, classes):\n",
    "            print(f\"Detected: {CLASS_NAMES[int(cls)]}, Confidence: {score:.2f}, Box: {box}\")\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            # 바운딩 박스 크기 축소 (옵션, 필요 시 활성화)\n",
    "            # scale = 0.8\n",
    "            # w, h = x2 - x1, y2 - y1\n",
    "            # x1, y1 = int(x1 + w * (1 - scale) / 2), int(y1 + h * (1 - scale) / 2)\n",
    "            # x2, y2 = int(x2 - w * (1 - scale) / 2), int(y2 - h * (1 - scale) / 2)\n",
    "            label = f\"{CLASS_NAMES[int(cls)]} {score:.2f}\"\n",
    "            color = (0, 255, 0) if CLASS_NAMES[int(cls)] == 'normal' else (0, 0, 255)\n",
    "            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 1)  # 두께 2 -> 1\n",
    "            cv2.putText(img_with_boxes, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)  # 텍스트 두께 2 -> 1\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Acne Detection: {os.path.basename(image_path)}\")\n",
    "    plt.show()\n",
    "    \n",
    "    if save_output:\n",
    "        output_path = os.path.join(OUTPUT_DIR, f\"detected_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, img_with_boxes)\n",
    "        print(f\"Saved output to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "049958bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. 비디오에서 여드름 감지 함수\n",
    "def detect_acne_video(video_path, conf_threshold=0.3, save_output=True):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Video not found: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    if save_output:\n",
    "        output_path = os.path.join(OUTPUT_DIR, f\"detected_{os.path.basename(video_path)}\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_input = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))  # 416x416\n",
    "        results = model.predict(frame_input, conf=conf_threshold, device=DEVICE, verbose=True)\n",
    "        print(f\"Number of detections: {len(results[0].boxes)}\")\n",
    "        \n",
    "        frame_display = frame.copy()\n",
    "        scale_x = width / IMG_SIZE\n",
    "        scale_y = height / IMG_SIZE\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            scores = result.boxes.conf.cpu().numpy()\n",
    "            classes = result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            for box, score, cls in zip(boxes, scores, classes):\n",
    "                print(f\"Detected: {CLASS_NAMES[int(cls)]}, Confidence: {score:.2f}, Box: {box}\")\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                # 원본 프레임에 맞게 스케일링\n",
    "                x1, y1, x2, y2 = int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y)\n",
    "                # 바운딩 박스 크기 축소 (옵션)\n",
    "                # scale = 0.8\n",
    "                # w, h = x2 - x1, y2 - y1\n",
    "                # x1, y1 = int(x1 + w * (1 - scale) / 2), int(y1 + h * (1 - scale) / 2)\n",
    "                # x2, y2 = int(x2 - w * (1 - scale) / 2), int(y2 - h * (1 - scale) / 2)\n",
    "                label = f\"{CLASS_NAMES[int(cls)]} {score:.2f}\"\n",
    "                color = (0, 255, 0) if CLASS_NAMES[int(cls)] == 'normal' else (0, 0, 255)\n",
    "                cv2.rectangle(frame_display, (x1, y1), (x2, y2), color, 1)  # 두께 2 -> 1\n",
    "                cv2.putText(frame_display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        if save_output:\n",
    "            out.write(frame_display)\n",
    "        \n",
    "        cv2.imshow('Acne Detection', frame_display)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if save_output:\n",
    "        out.release()\n",
    "        print(f\"Saved output video to: {output_path}\")\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7522b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. 웹캠 실시간 감지 함수 (박스 크기 줄임)\n",
    "def detect_acne_webcam(conf_threshold=0.3):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # 웹캠 해상도 640x480\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Webcam not found.\")\n",
    "        return\n",
    "    \n",
    "    cv2.namedWindow('Acne Detection - Webcam', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Acne Detection - Webcam', 960, 720)  # 창 크기 960x720\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[ERROR] Failed to capture frame.\")\n",
    "            break\n",
    "        \n",
    "        frame_input = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))  # 416x416\n",
    "        results = model.predict(frame_input, conf=conf_threshold, device=DEVICE, verbose=True)\n",
    "        print(f\"Number of detections: {len(results[0].boxes)}\")\n",
    "        \n",
    "        frame_display = frame.copy()\n",
    "        scale_x = 640 / IMG_SIZE\n",
    "        scale_y = 480 / IMG_SIZE\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            scores = result.boxes.conf.cpu().numpy()\n",
    "            classes = result.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            for box, score, cls in zip(boxes, scores, classes):\n",
    "                print(f\"Detected: {CLASS_NAMES[int(cls)]}, Confidence: {score:.2f}, Box: {box}\")\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                x1, y1, x2, y2 = int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y)\n",
    "                # 바운딩 박스 크기 축소 (옵션)\n",
    "                # scale = 0.8\n",
    "                # w, h = x2 - x1, y2 - y1\n",
    "                # x1, y1 = int(x1 + w * (1 - scale) / 2), int(y1 + h * (1 - scale) / 2)\n",
    "                # x2, y2 = int(x2 - w * (1 - scale) / 2), int(y2 - h * (1 - scale) / 2)\n",
    "                label = f\"{CLASS_NAMES[int(cls)]} {score:.2f}\"\n",
    "                color = (0, 255, 0) if CLASS_NAMES[int(cls)] == 'normal' else (0, 0, 255)\n",
    "                cv2.rectangle(frame_display, (x1, y1), (x2, y2), color, 1)  # 두께 2 -> 1\n",
    "                cv2.putText(frame_display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        cv2.imshow('Acne Detection - Webcam', frame_display)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8224e019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting webcam detection... Press 'q' to quit.\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 15.8ms preprocess, 6.8ms inference, 76.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 0.7ms preprocess, 6.4ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 0.7ms preprocess, 5.4ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 0.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 0.7ms preprocess, 5.4ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.9ms\n",
      "Speed: 0.7ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 0.7ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 0.7ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 0.7ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.3ms\n",
      "Speed: 0.6ms preprocess, 5.3ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 0.8ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 0.8ms preprocess, 6.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.02199         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.2ms\n",
      "Speed: 1.0ms preprocess, 4.2ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 0.7ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.8ms preprocess, 5.5ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.6ms\n",
      "Speed: 0.7ms preprocess, 5.6ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.6ms\n",
      "Speed: 0.6ms preprocess, 5.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.2ms\n",
      "Speed: 0.7ms preprocess, 5.2ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.9ms\n",
      "Speed: 0.8ms preprocess, 4.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 0.7ms preprocess, 5.7ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0    0.016323         416       415.7]\n",
      "\n",
      "0: 224x224 1 normal, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.66]\n",
      "\n",
      "0: 224x224 1 normal, 6.5ms\n",
      "Speed: 0.9ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 0.6ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.4ms\n",
      "Speed: 0.9ms preprocess, 4.4ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.9ms\n",
      "Speed: 0.7ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.5ms\n",
      "Speed: 0.7ms preprocess, 6.5ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 0.9ms preprocess, 6.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.25796         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.5ms\n",
      "Speed: 0.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 0.7ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.7ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 0.7ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.5ms\n",
      "Speed: 0.7ms preprocess, 4.5ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.5ms\n",
      "Speed: 0.8ms preprocess, 4.5ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 0.8ms preprocess, 6.0ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.8ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.3ms\n",
      "Speed: 0.7ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.2ms\n",
      "Speed: 0.6ms preprocess, 4.2ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.3ms\n",
      "Speed: 0.6ms preprocess, 4.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 0.7ms preprocess, 6.0ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.9ms\n",
      "Speed: 0.7ms preprocess, 4.9ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.0ms\n",
      "Speed: 0.7ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.0ms\n",
      "Speed: 0.6ms preprocess, 4.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.82984      415.98      415.69]\n",
      "\n",
      "0: 224x224 1 normal, 6.5ms\n",
      "Speed: 0.6ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 3.9ms\n",
      "Speed: 0.6ms preprocess, 3.9ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.1ms\n",
      "Speed: 0.6ms preprocess, 4.1ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.4ms\n",
      "Speed: 0.7ms preprocess, 4.4ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.3ms\n",
      "Speed: 0.7ms preprocess, 4.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.3ms\n",
      "Speed: 0.7ms preprocess, 5.3ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.1ms\n",
      "Speed: 0.6ms preprocess, 4.1ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.7ms\n",
      "Speed: 0.6ms preprocess, 4.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.5ms\n",
      "Speed: 0.6ms preprocess, 4.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.0ms\n",
      "Speed: 0.6ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 0.7ms preprocess, 6.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.2ms\n",
      "Speed: 0.7ms preprocess, 4.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 0.8ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.8ms\n",
      "Speed: 0.7ms preprocess, 4.8ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 0.8ms preprocess, 6.2ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 0.8ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 0.8ms preprocess, 6.4ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 4.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.6ms\n",
      "Speed: 0.9ms preprocess, 5.6ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.9ms\n",
      "Speed: 1.2ms preprocess, 5.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.9ms\n",
      "Speed: 2.7ms preprocess, 4.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 4.9ms\n",
      "Speed: 1.2ms preprocess, 4.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.2ms\n",
      "Speed: 2.5ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 0.9ms preprocess, 5.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 1.1ms preprocess, 5.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.01893         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 1.1ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.02233         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.2ms preprocess, 5.4ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.26331         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.21491         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 0.8ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.18703         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.2ms preprocess, 6.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0    0.059254         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      0.1093         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 0.8ms preprocess, 6.4ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 0.9ms preprocess, 5.4ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.2ms preprocess, 5.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.8ms preprocess, 5.5ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.7ms preprocess, 5.5ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 0.8ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.7ms\n",
      "Speed: 2.5ms preprocess, 5.7ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.5ms\n",
      "Speed: 0.9ms preprocess, 5.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      0.8318         416      415.68]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      0.6132         416      415.69]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      0.3515         416      415.69]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.47888         416      415.69]\n",
      "\n",
      "0: 224x224 1 normal, 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.72]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 1.1ms preprocess, 6.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.73]\n",
      "\n",
      "0: 224x224 1 normal, 5.9ms\n",
      "Speed: 0.8ms preprocess, 5.9ms inference, 20.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.73]\n",
      "\n",
      "0: 224x224 1 normal, 8.8ms\n",
      "Speed: 2.1ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.73]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.72]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 2.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.74]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.73]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 4.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416      415.74]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 2.8ms preprocess, 6.2ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 1.2ms preprocess, 6.0ms inference, 4.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0     0.35303         416      415.74]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 2.9ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.1ms\n",
      "Speed: 2.8ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 1.9ms preprocess, 6.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.0ms\n",
      "Speed: 0.8ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.2ms\n",
      "Speed: 2.4ms preprocess, 6.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.4ms\n",
      "Speed: 2.9ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 2.4ms preprocess, 7.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.4ms\n",
      "Speed: 1.2ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 3.2ms preprocess, 6.6ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 1.3ms preprocess, 6.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416       415.7]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.21197      415.97      415.67]\n",
      "\n",
      "0: 224x224 1 normal, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 19.9ms\n",
      "Speed: 2.5ms preprocess, 19.9ms inference, 4.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.62405         416      415.68]\n",
      "\n",
      "0: 224x224 1 normal, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.5ms\n",
      "Speed: 1.1ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0    0.018986         416      415.68]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 5.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 2.9ms preprocess, 6.8ms inference, 5.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.3ms\n",
      "Speed: 0.8ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 2.9ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [    0.71771           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.95, Box: [    0.28182           0         416      415.74]\n",
      "\n",
      "0: 224x224 1 normal, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.89, Box: [          0           0         416      415.72]\n",
      "\n",
      "0: 224x224 1 normal, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.90, Box: [      1.273     0.48208         416      415.67]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.92, Box: [     12.957     0.47205         416      415.67]\n",
      "\n",
      "0: 224x224 1 normal, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.90, Box: [     102.34      4.0793         416      415.65]\n",
      "\n",
      "0: 224x224 1 normal, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.86, Box: [     101.35      3.5822         416      415.54]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.83, Box: [     95.231      3.7238         416      415.51]\n",
      "\n",
      "0: 224x224 1 normal, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.66, Box: [     108.77      5.7161         416      415.49]\n",
      "\n",
      "0: 224x224 1 normal, 13.0ms\n",
      "Speed: 1.1ms preprocess, 13.0ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.66, Box: [     108.77      5.7161         416      415.49]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 4.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.71, Box: [     109.12      6.1661         416      415.48]\n",
      "\n",
      "0: 224x224 1 normal, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.73, Box: [     108.86      6.0124         416       415.5]\n",
      "\n",
      "0: 224x224 1 normal, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.88, Box: [     107.41      4.6985         416      415.51]\n",
      "\n",
      "0: 224x224 1 normal, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.88, Box: [     110.31      5.4313         416      415.51]\n",
      "\n",
      "0: 224x224 1 normal, 9.6ms\n",
      "Speed: 3.6ms preprocess, 9.6ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.93, Box: [     94.839      5.9722         416      415.52]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 0.8ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.94, Box: [     35.637      4.3267         416      415.55]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 3.4ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.93, Box: [     19.381      5.9552         416      415.59]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 0.8ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.94, Box: [      25.64      5.3989         416      415.83]\n",
      "\n",
      "0: 224x224 1 normal, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.94, Box: [     5.1597        7.36         416       415.9]\n",
      "\n",
      "0: 224x224 1 normal, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.94, Box: [     5.1081       17.64         416      415.71]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.93, Box: [    0.80901      22.466         416      415.69]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.93, Box: [    0.38585      12.383         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.89, Box: [    0.56024      14.758         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 5.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.80, Box: [    0.70003      16.128         416         416]\n",
      "Detected: very_severe, Confidence: 0.35, Box: [     1.1066      62.727         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.80, Box: [     1.0632      11.693         416      415.66]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     1.0652      52.509         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.79, Box: [     2.7106       10.45         416      415.61]\n",
      "Detected: very_severe, Confidence: 0.37, Box: [     1.0784      44.368         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 8.1ms\n",
      "Speed: 3.2ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.69, Box: [     4.3639      9.4156         416       415.6]\n",
      "Detected: very_severe, Confidence: 0.40, Box: [    0.92599      37.984         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.63, Box: [     6.1711      9.5584         416      415.57]\n",
      "Detected: very_severe, Confidence: 0.42, Box: [    0.87195       36.97         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 1 very_severe, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: normal, Confidence: 0.48, Box: [     3.8212      6.4451         416      415.56]\n",
      "Detected: very_severe, Confidence: 0.43, Box: [    0.86991      30.793         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.46, Box: [    0.46349      24.578         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.47, Box: [     1.4397       27.23         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.3ms\n",
      "Speed: 4.1ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.43, Box: [     4.1039      33.107         416         416]\n",
      "Detected: severe, Confidence: 0.31, Box: [     6.6739      8.0824      415.71      415.15]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.41, Box: [     18.032      19.187         416         416]\n",
      "Detected: severe, Confidence: 0.31, Box: [     8.7528      8.4036      415.69      415.21]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.44, Box: [     21.027      17.814         416      415.99]\n",
      "Detected: severe, Confidence: 0.37, Box: [     10.968      7.6502      415.68      415.18]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: severe, Confidence: 0.47, Box: [     8.7788      9.1709      415.71      415.08]\n",
      "Detected: very_severe, Confidence: 0.45, Box: [      5.524      44.241      405.25      415.85]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: severe, Confidence: 0.48, Box: [     8.7724       10.27      415.75      415.08]\n",
      "Detected: very_severe, Confidence: 0.46, Box: [     5.2853      45.769      407.53      415.93]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     4.3675      45.024      412.53      415.95]\n",
      "Detected: severe, Confidence: 0.50, Box: [     8.1968      8.2771      415.81      415.13]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 5.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [      4.046      45.501      408.31      415.98]\n",
      "Detected: severe, Confidence: 0.49, Box: [     9.9749      8.2195       415.8      415.12]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.5ms\n",
      "Speed: 1.1ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     4.0052      46.593      411.62      415.96]\n",
      "Detected: severe, Confidence: 0.51, Box: [     10.037       11.02       415.9      415.14]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     3.8742      44.295       409.9      415.95]\n",
      "Detected: severe, Confidence: 0.49, Box: [     12.703      7.7168       415.9      415.16]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 7.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     3.2369      45.033      409.15      415.97]\n",
      "Detected: severe, Confidence: 0.46, Box: [     11.827      8.1721      415.89      415.19]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     2.8309      41.391      411.71         416]\n",
      "Detected: severe, Confidence: 0.47, Box: [     9.9261      6.3063      415.92      415.19]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     4.0014      34.606         416         416]\n",
      "Detected: severe, Confidence: 0.46, Box: [     10.506      6.3027      415.91      415.18]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     4.2621       32.84         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     10.177      4.5474      415.93      415.16]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     1.3332      28.116         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     6.1291      1.9558      415.95      415.14]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.2ms\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     2.5719      41.303      413.78         416]\n",
      "Detected: severe, Confidence: 0.50, Box: [     7.7364      2.6368      415.96      415.14]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     2.6015      33.501         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     7.3457      2.9182      415.95       415.1]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     3.0345      36.094         416         416]\n",
      "Detected: severe, Confidence: 0.46, Box: [     8.2887      3.1768      415.93      415.04]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     4.0362      38.844         416         416]\n",
      "Detected: severe, Confidence: 0.47, Box: [     8.3667      3.7379      415.95      415.01]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     4.1448      45.725         416         416]\n",
      "Detected: severe, Confidence: 0.46, Box: [     7.6496      7.6344      415.96      415.03]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.2ms\n",
      "Speed: 4.1ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     4.1613      42.967         416         416]\n",
      "Detected: severe, Confidence: 0.49, Box: [     8.0348      4.8566      415.96      414.99]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [      3.592       49.76         416         416]\n",
      "Detected: severe, Confidence: 0.47, Box: [     7.8174      7.9041      415.97      414.98]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     3.2132      57.323         416         416]\n",
      "Detected: severe, Confidence: 0.45, Box: [     7.4792      15.359      415.98      414.89]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     2.2364      58.809         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     6.1265      16.584      415.99       414.9]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     1.9322      61.316         416         416]\n",
      "Detected: severe, Confidence: 0.45, Box: [     5.3136      18.476      415.99      414.91]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.1ms\n",
      "Speed: 3.8ms preprocess, 10.1ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     1.1766      62.184         416         416]\n",
      "Detected: severe, Confidence: 0.47, Box: [      4.255      17.665         416      414.88]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     1.1731      56.507         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     3.6939      8.3183         416      414.86]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [    0.95232      61.452         416         416]\n",
      "Detected: severe, Confidence: 0.49, Box: [     2.7555      39.397         416      415.21]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     1.4654      63.326         416         416]\n",
      "Detected: severe, Confidence: 0.49, Box: [     3.5196      40.223         416      415.23]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     1.8382      61.963         416         416]\n",
      "Detected: severe, Confidence: 0.43, Box: [     4.6264      9.7137         416      414.94]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     2.9566      61.018         416         416]\n",
      "Detected: severe, Confidence: 0.44, Box: [     6.7707      6.9308         416      414.95]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     4.1433      62.121         416         416]\n",
      "Detected: severe, Confidence: 0.46, Box: [     8.2832      7.2668         416      414.97]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.50, Box: [     7.0795      71.694      401.49      415.55]\n",
      "Detected: severe, Confidence: 0.43, Box: [      10.46      4.0225      415.97      415.02]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.51, Box: [      9.117      25.877         416         416]\n",
      "Detected: severe, Confidence: 0.41, Box: [     10.921      3.7164      415.98      415.01]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     9.4806      27.804         416         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [     11.269      5.3819      415.98      414.95]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.53, Box: [      8.551      27.238         416         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     10.191      5.8925      415.99      414.95]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.53, Box: [      8.551      27.238         416         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     10.191      5.8925      415.99      414.95]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     8.0791      27.855         416      415.94]\n",
      "Detected: severe, Confidence: 0.41, Box: [     9.6721      5.1963      415.98      414.93]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     5.7559      63.328         416      415.72]\n",
      "Detected: severe, Confidence: 0.44, Box: [     10.442      7.3746         416      414.86]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [      5.167      61.689         416      415.48]\n",
      "Detected: severe, Confidence: 0.43, Box: [     9.3156      8.4459         416      414.87]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.9ms\n",
      "Speed: 1.8ms preprocess, 13.9ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     7.2524      32.105         416      415.79]\n",
      "Detected: severe, Confidence: 0.40, Box: [     8.4034       9.677         416      414.79]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     4.4609      61.961         416      415.67]\n",
      "Detected: severe, Confidence: 0.41, Box: [     8.6478      9.1747         416      414.86]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [      4.623      61.137         416      415.82]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     6.2453      61.849         416      415.31]\n",
      "Detected: severe, Confidence: 0.41, Box: [      10.45      7.8739         416      414.87]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     4.5103      62.542         416      414.93]\n",
      "Detected: severe, Confidence: 0.40, Box: [      7.779      6.9297         416      414.85]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     3.4497       54.45         416      415.55]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     2.6772      47.141         416      415.54]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     2.2466      40.118         416      415.96]\n",
      "Detected: severe, Confidence: 0.43, Box: [     4.0311           0         416      415.08]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     4.6406      70.519      413.25      415.79]\n",
      "Detected: severe, Confidence: 0.42, Box: [     3.6963           0         416      415.11]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.8ms\n",
      "Speed: 0.8ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     1.9993      33.164         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     1.8931      34.235         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     1.5468      35.471         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     1.1492      32.164         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [    0.88621      27.747         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     1.1454       24.54         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.62, Box: [    0.46165      20.167         416         416]\n",
      "Detected: severe, Confidence: 0.42, Box: [     1.5141           0         416      414.86]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [          0      27.096         416         416]\n",
      "Detected: severe, Confidence: 0.43, Box: [    0.84702           0         416      414.79]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     1.4559      72.915         416         416]\n",
      "Detected: severe, Confidence: 0.45, Box: [     0.6709      5.6398         416      415.12]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.62, Box: [      1.229      70.537         416         416]\n",
      "Detected: severe, Confidence: 0.52, Box: [    0.49087      2.1576         416      415.07]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     1.3638      73.401         416         416]\n",
      "Detected: severe, Confidence: 0.52, Box: [     0.5317      2.2406         416      415.07]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     1.2598      75.039         416         416]\n",
      "Detected: severe, Confidence: 0.51, Box: [    0.49795      1.4105         416      415.08]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     1.1789      78.962         416         416]\n",
      "Detected: severe, Confidence: 0.56, Box: [    0.38211     0.70295         416      415.04]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [      1.145      83.722         416         416]\n",
      "Detected: severe, Confidence: 0.57, Box: [     0.2749      2.6731         416      415.04]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [    0.96887      86.039         416         416]\n",
      "Detected: severe, Confidence: 0.48, Box: [     0.1715      2.4809         416      415.13]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     1.1043      88.843         416         416]\n",
      "Detected: severe, Confidence: 0.51, Box: [    0.24606      4.0495         416      415.09]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     1.1677      86.848         416         416]\n",
      "Detected: severe, Confidence: 0.52, Box: [    0.23716      2.9557         416      415.12]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     1.1283      85.419         416         416]\n",
      "Detected: severe, Confidence: 0.50, Box: [    0.23648      3.6249         416      415.12]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 6.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     1.0759      80.748         416         416]\n",
      "Detected: severe, Confidence: 0.50, Box: [    0.17025      2.9789         416      415.11]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 5.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     0.9609      72.569         416         416]\n",
      "Detected: severe, Confidence: 0.54, Box: [    0.19621     0.26671         416      415.05]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.8ms\n",
      "Speed: 3.4ms preprocess, 7.8ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     1.1468      76.746         416         416]\n",
      "Detected: severe, Confidence: 0.52, Box: [    0.43697     0.21185         416      415.07]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     1.5979      73.413         416         416]\n",
      "Detected: severe, Confidence: 0.44, Box: [    0.84823           0         416       414.9]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [    0.80513      25.676         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     1.9936      46.938         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     4.4094      46.588         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     12.412      51.325         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.66, Box: [     21.387      75.221         416         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [      22.09           0      415.95         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     23.997       76.46         416         416]\n",
      "\n",
      "0: 224x224 2 very_severes, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     13.002      68.384      412.45      415.81]\n",
      "Detected: very_severe, Confidence: 0.37, Box: [     33.329      116.19      269.58      411.94]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 10.2ms\n",
      "Speed: 1.2ms preprocess, 10.2ms inference, 3.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     20.786      62.645      414.98         416]\n",
      "Detected: very_severe, Confidence: 0.39, Box: [     41.833      119.11      272.46      414.44]\n",
      "Detected: severe, Confidence: 0.34, Box: [     27.825      5.5032      415.89      415.79]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     26.666       59.51         416         416]\n",
      "Detected: severe, Confidence: 0.37, Box: [     19.691           0      415.89         416]\n",
      "Detected: very_severe, Confidence: 0.32, Box: [     43.677      119.85      273.31      415.85]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.65, Box: [      27.13      114.68         416         416]\n",
      "Detected: severe, Confidence: 0.37, Box: [     22.242           0         416      415.15]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [     34.677      132.37       266.8      414.79]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.66, Box: [     31.549      112.01         416         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     26.192           0         416      415.07]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     37.422      131.99      269.26      415.39]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     40.636      125.01         416         416]\n",
      "Detected: severe, Confidence: 0.42, Box: [     38.234      5.6416         416       415.9]\n",
      "Detected: very_severe, Confidence: 0.35, Box: [     42.316      134.54      270.73      415.51]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 5.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     34.089      127.96         416         416]\n",
      "Detected: severe, Confidence: 0.41, Box: [      31.64      4.4481         416      415.87]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 9.8ms\n",
      "Speed: 1.2ms preprocess, 9.8ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.46, Box: [     24.246      123.96      415.81         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [     25.282      2.6586         416      415.82]\n",
      "Detected: very_severe, Confidence: 0.32, Box: [     43.575      140.77      270.21      414.41]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 7.7ms\n",
      "Speed: 4.1ms preprocess, 7.7ms inference, 4.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     31.029      142.07      397.73      415.98]\n",
      "Detected: very_severe, Confidence: 0.37, Box: [     32.886      44.564         416      415.56]\n",
      "Detected: severe, Confidence: 0.34, Box: [     32.729      4.1883      415.97      415.82]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [     52.571      144.16      273.45      413.87]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 5.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     19.054      144.75      378.53      415.58]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     59.732      148.72      277.14      404.21]\n",
      "Detected: severe, Confidence: 0.34, Box: [     14.899           0      415.94      415.88]\n",
      "Detected: very_severe, Confidence: 0.33, Box: [     20.676      29.022         416       415.3]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     29.123      148.95       341.7      415.81]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     40.477      140.51      339.31       415.3]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     74.861      153.18      282.23      401.98]\n",
      "Detected: severe, Confidence: 0.32, Box: [      30.72           0      415.93      415.78]\n",
      "\n",
      "0: 224x224 2 severes, 2 very_severes, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     41.172      107.79      342.66      414.94]\n",
      "Detected: very_severe, Confidence: 0.43, Box: [     79.343      157.05      285.35      402.25]\n",
      "Detected: severe, Confidence: 0.33, Box: [     32.743           0      415.93      415.72]\n",
      "Detected: severe, Confidence: 0.32, Box: [     73.652      157.46       285.6      406.12]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 9.3ms\n",
      "Speed: 2.6ms preprocess, 9.3ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.52, Box: [      46.26      90.525       344.3      412.28]\n",
      "Detected: very_severe, Confidence: 0.36, Box: [     82.913      160.64      287.73      400.34]\n",
      "Detected: severe, Confidence: 0.32, Box: [     34.778           0      415.96       414.8]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 6.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.52, Box: [      46.26      90.525       344.3      412.28]\n",
      "Detected: very_severe, Confidence: 0.36, Box: [     82.913      160.64      287.73      400.34]\n",
      "Detected: severe, Confidence: 0.32, Box: [     34.778           0      415.96       414.8]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     57.314      127.59      314.43      410.78]\n",
      "Detected: very_severe, Confidence: 0.44, Box: [     85.841      162.82      288.48      399.25]\n",
      "Detected: severe, Confidence: 0.31, Box: [     41.567           0      415.95      414.47]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.1ms\n",
      "Speed: 1.3ms preprocess, 13.1ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     62.024       156.2      309.81       409.3]\n",
      "Detected: severe, Confidence: 0.30, Box: [     45.662           0      415.96      413.73]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 8.1ms\n",
      "Speed: 2.2ms preprocess, 8.1ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     61.735      142.87      337.54      409.63]\n",
      "Detected: very_severe, Confidence: 0.46, Box: [     87.991      168.08      288.62      400.71]\n",
      "Detected: severe, Confidence: 0.33, Box: [     40.782           0      415.97      414.04]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 5.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     38.754      99.317      380.63      411.45]\n",
      "Detected: very_severe, Confidence: 0.43, Box: [     88.361      168.01      288.82      404.18]\n",
      "Detected: severe, Confidence: 0.35, Box: [      26.87           0      415.96      414.44]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [     41.972       7.949         416      412.52]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 3.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     5.1866      47.839      390.68      412.11]\n",
      "Detected: severe, Confidence: 0.31, Box: [     6.8116           0      415.97      414.93]\n",
      "\n",
      "0: 224x224 2 very_severes, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 6.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     15.015      139.63      304.82      410.27]\n",
      "Detected: very_severe, Confidence: 0.35, Box: [     66.065      168.27      280.39      404.69]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     40.824      166.83       304.8      410.58]\n",
      "\n",
      "0: 224x224 3 very_severes, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     33.793      164.35      346.05      410.58]\n",
      "Detected: very_severe, Confidence: 0.47, Box: [      68.08      170.28      277.99       405.2]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [     33.621        30.3         416      412.68]\n",
      "\n",
      "0: 224x224 2 very_severes, 11.9ms\n",
      "Speed: 1.0ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     12.645       162.2      307.82      409.78]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     72.784      170.47      276.11      404.69]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     32.254      130.71      402.63      415.97]\n",
      "Detected: very_severe, Confidence: 0.39, Box: [     33.884       10.15         416      415.51]\n",
      "Detected: severe, Confidence: 0.35, Box: [     20.259           0      415.91         416]\n",
      "Detected: very_severe, Confidence: 0.35, Box: [     61.256      165.49      280.34      413.17]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     21.339      30.736      406.47      415.69]\n",
      "Detected: severe, Confidence: 0.32, Box: [       14.8           0      415.96         416]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     24.741      75.555      414.11      415.84]\n",
      "Detected: very_severe, Confidence: 0.46, Box: [          0      150.41      370.33      415.95]\n",
      "Detected: severe, Confidence: 0.34, Box: [     26.451           0      415.97         416]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     35.956      106.75      413.42      415.73]\n",
      "Detected: very_severe, Confidence: 0.46, Box: [     2.9313      151.22      357.87       415.8]\n",
      "Detected: severe, Confidence: 0.37, Box: [     40.091           0      415.94      415.96]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 4.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     26.096      61.071      413.74       415.7]\n",
      "Detected: very_severe, Confidence: 0.50, Box: [          0      132.19      367.28      415.69]\n",
      "Detected: severe, Confidence: 0.34, Box: [     31.406           0      415.98      415.92]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 4.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     34.915      119.02      398.73      415.75]\n",
      "Detected: very_severe, Confidence: 0.53, Box: [      1.266       141.1      326.05      415.79]\n",
      "Detected: severe, Confidence: 0.34, Box: [     41.319           0      415.94      415.93]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [     48.939       19.85         416      415.95]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     35.508       113.3      384.62      415.82]\n",
      "Detected: very_severe, Confidence: 0.55, Box: [          0      135.16      310.71      415.87]\n",
      "Detected: severe, Confidence: 0.35, Box: [     45.693           0      415.95      415.97]\n",
      "Detected: very_severe, Confidence: 0.34, Box: [     52.791      28.634         416      415.29]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 7.7ms\n",
      "Speed: 2.3ms preprocess, 7.7ms inference, 5.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     48.559      128.27      374.26      415.82]\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     6.9373      137.13      303.19      415.87]\n",
      "Detected: very_severe, Confidence: 0.35, Box: [     62.752      46.986         416      415.33]\n",
      "Detected: severe, Confidence: 0.32, Box: [     58.679     0.16515      415.95      415.95]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 4.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     40.623      83.793      408.61      415.82]\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     2.5532      124.55      341.54      415.91]\n",
      "Detected: severe, Confidence: 0.37, Box: [     49.759           0      415.94         416]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 4.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     40.623      83.793      408.61      415.82]\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     2.5532      124.55      341.54      415.91]\n",
      "Detected: severe, Confidence: 0.37, Box: [     49.759           0      415.94         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     24.024      70.871      411.75      415.88]\n",
      "Detected: severe, Confidence: 0.37, Box: [     34.235           0      415.94         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     39.519      49.482         416      415.66]\n",
      "Detected: severe, Confidence: 0.36, Box: [      51.52           0      415.98      415.91]\n",
      "\n",
      "0: 224x224 1 severe, 2 very_severes, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     61.916      85.877      405.89      415.11]\n",
      "Detected: very_severe, Confidence: 0.49, Box: [     3.9925      107.11      352.23      414.95]\n",
      "Detected: severe, Confidence: 0.38, Box: [     85.174      4.1548         416      415.26]\n",
      "\n",
      "0: 224x224 1 severe, 3 very_severes, 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 4.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 4\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     66.358      84.249      353.49      414.98]\n",
      "Detected: very_severe, Confidence: 0.51, Box: [     2.0008      105.87      314.71      414.96]\n",
      "Detected: severe, Confidence: 0.35, Box: [     71.793           0      415.98       415.7]\n",
      "Detected: very_severe, Confidence: 0.31, Box: [      86.36      41.421         416      414.56]\n",
      "\n",
      "0: 224x224 3 very_severes, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 4.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 3\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     73.154       87.07      350.99      414.41]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     3.4885       104.5      322.36      414.62]\n",
      "Detected: very_severe, Confidence: 0.38, Box: [     88.509      32.925         416      414.77]\n",
      "\n",
      "0: 224x224 2 very_severes, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     102.65      110.52      307.68      414.47]\n",
      "Detected: very_severe, Confidence: 0.32, Box: [     104.02      100.06      395.89      414.92]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.66, Box: [     104.31      107.85      322.69      412.97]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     104.21      104.67      328.44      415.59]\n",
      "Detected: severe, Confidence: 0.30, Box: [     100.95      43.281         416         416]\n",
      "\n",
      "0: 224x224 2 very_severes, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     106.06      102.06      313.35      414.81]\n",
      "Detected: very_severe, Confidence: 0.40, Box: [      107.3      104.92      398.64      414.68]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [      106.6      101.38      312.58         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     106.63      101.33      308.94      415.74]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     104.22      101.14      302.92      415.35]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     101.68      101.96      302.28      414.25]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     97.698      103.25      300.27       414.8]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     96.187      103.61      300.38      414.67]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     96.354      103.25      300.66      414.39]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     96.921      103.11      301.14      414.56]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     96.561      103.31      300.48      414.53]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     95.614       103.4      300.39      414.92]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     96.715      104.09      302.05      414.68]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     99.338      103.31      302.87      414.23]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     100.74      100.91      306.58      414.35]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     101.88      100.68      310.09      415.27]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     103.86      100.34      307.27         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 4.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     104.02      99.158      312.89         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.53, Box: [      105.7       96.27      337.07         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.53, Box: [     108.24      95.578      328.28         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.50, Box: [     109.45      94.762      321.87         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [      111.3      93.604      328.72         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     111.31       91.85      327.34         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     110.79      92.051      326.94         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.5ms\n",
      "Speed: 2.5ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     111.01      91.959      326.77         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     110.95      91.858      328.26         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     110.05      92.322      327.86         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     108.96       93.43      324.51         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     108.96       93.43      324.51         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.51, Box: [     107.58      92.873      331.68         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.50, Box: [     106.45      92.909      342.72         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [      106.5      98.761      333.72      414.69]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     105.91      99.861      326.08      414.62]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     106.06      100.63      334.77      415.66]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     105.81      101.81      335.57      415.44]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     107.23      101.85      337.01      415.51]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     108.53      101.82      334.19      414.45]\n",
      "\n",
      "0: 224x224 1 very_severe, 17.3ms\n",
      "Speed: 1.6ms preprocess, 17.3ms inference, 6.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     106.11      102.07      334.99      415.12]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.8ms\n",
      "Speed: 3.5ms preprocess, 11.8ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.71      103.17      347.03      415.53]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     103.58      102.83      337.05       414.8]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.0ms\n",
      "Speed: 2.2ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [      102.2      101.81      347.41      414.84]\n",
      "Detected: severe, Confidence: 0.31, Box: [     98.346      52.959         416      415.99]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.3ms\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     101.85      101.06      318.81      414.42]\n",
      "Detected: severe, Confidence: 0.30, Box: [     98.011      66.387         416      415.95]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     102.33      101.32      321.29      415.23]\n",
      "Detected: severe, Confidence: 0.31, Box: [     98.107      76.406         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     101.92      100.92      325.23      414.35]\n",
      "Detected: severe, Confidence: 0.32, Box: [     97.748      75.295         416      415.99]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.9ms\n",
      "Speed: 0.9ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     101.92      100.92      325.23      414.35]\n",
      "Detected: severe, Confidence: 0.32, Box: [     97.748      75.295         416      415.99]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     101.14      100.36      330.08      413.13]\n",
      "Detected: severe, Confidence: 0.31, Box: [     97.234      74.475         416       415.6]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     100.35      100.88      338.76      415.64]\n",
      "Detected: severe, Confidence: 0.32, Box: [      96.35      67.162         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     100.86      100.25      342.52      415.04]\n",
      "Detected: severe, Confidence: 0.31, Box: [     96.834      66.854         416      415.96]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     103.85      100.02      349.79      415.09]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     105.09      100.28      341.22         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [      105.8      98.651      329.88         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     106.43      96.372      333.22         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.3ms\n",
      "Speed: 4.3ms preprocess, 10.3ms inference, 4.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     106.92      96.319      330.65         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 13.0ms\n",
      "Speed: 3.6ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     106.28      94.679      330.65         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     105.85      94.606      334.43         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.52, Box: [     105.69      92.822      334.66         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     105.75      91.698       338.3         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     106.74      92.591      335.82         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     106.74      93.031      340.71         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [     105.82      91.305      374.97         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     106.58      92.793      340.09         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [     105.72       90.97      378.88         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 2.7ms preprocess, 8.0ms inference, 6.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     106.22      93.046      344.44         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 13.0ms\n",
      "Speed: 1.5ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     106.74      92.529      341.29         416]\n",
      "Detected: severe, Confidence: 0.40, Box: [     105.83      90.805      376.77         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.4ms\n",
      "Speed: 2.2ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     108.44      92.496      336.73         416]\n",
      "Detected: severe, Confidence: 0.42, Box: [     107.13      91.371      366.42         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     108.43      92.545      341.06         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     109.87      92.568      331.71         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     110.59      92.386      331.37         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     106.43      92.197       337.6      415.53]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     107.15      93.235      337.88      415.52]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     109.18      95.487      335.44      415.53]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     109.19      100.06      330.93      415.36]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     109.63      103.74      335.76      415.38]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     110.98      104.36      331.77      415.17]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     111.67      105.44      332.35      414.67]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     112.39      102.45      337.78      414.83]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     113.71      94.712      347.79      414.77]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     112.35      100.88      347.39      414.73]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     111.62      102.01      348.02      413.97]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     109.89      102.73      336.47      414.26]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     109.44       104.6      338.73      414.22]\n",
      "\n",
      "0: 224x224 1 very_severe, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     109.78      105.04      338.08      414.64]\n",
      "\n",
      "0: 224x224 1 very_severe, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 5.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     109.64      106.49      336.81      414.11]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     109.36      107.91      337.63      414.31]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     109.55      103.61      329.95      412.85]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.3ms\n",
      "Speed: 1.3ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     109.78      103.91      329.58      412.62]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 3.8ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     109.42      104.78       329.9      414.15]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.64, Box: [     107.75      104.93      332.13       414.2]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     107.23      104.03      339.24      414.44]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     107.33      104.78      338.56      414.33]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     107.81      105.43       335.2      414.55]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     107.01      104.63       342.2      414.73]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 4.5ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     106.19      102.27      346.65      414.67]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.5ms\n",
      "Speed: 1.6ms preprocess, 12.5ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     105.65      100.04      352.25      415.13]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     105.61      98.119      354.04      415.13]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     105.29      98.935      346.39      415.28]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     106.47      98.839      327.93         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     105.51      98.644      328.99      415.55]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     105.72      99.509      336.18       415.1]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     105.05      99.305      345.72      415.38]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     104.96      101.19      344.42      414.96]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 7.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     104.96      101.19      344.42      414.96]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.09      102.05       342.4      415.38]\n",
      "Detected: severe, Confidence: 0.38, Box: [      103.7          98      393.56       415.8]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     103.03      101.56      357.26      415.32]\n",
      "Detected: severe, Confidence: 0.32, Box: [     98.495      39.467         416      415.91]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 2.2ms preprocess, 8.0ms inference, 5.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     102.82      100.31      342.25      415.64]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     101.54       100.3      331.81      415.51]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     100.76      100.78      344.21      415.78]\n",
      "Detected: severe, Confidence: 0.30, Box: [     96.572      32.663         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     101.26      101.52      328.47      415.88]\n",
      "Detected: severe, Confidence: 0.35, Box: [     101.14      96.707      389.67         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.5ms\n",
      "Speed: 1.4ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [        103      100.37      341.26      414.96]\n",
      "Detected: severe, Confidence: 0.31, Box: [     99.079      54.105         416      415.93]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.49      99.326      329.58      415.11]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.67      98.829       334.4      415.26]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     104.67      98.475      321.33      415.74]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     104.51      99.698      321.85       415.4]\n",
      "Detected: severe, Confidence: 0.39, Box: [     103.83      98.779      360.47         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 3.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.68      100.18      337.48      414.55]\n",
      "Detected: severe, Confidence: 0.40, Box: [     103.77      99.217      381.69      415.45]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 0.8ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.88      99.188      353.08      415.83]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     105.48      100.14      346.18      415.33]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     104.98      99.519      336.52      415.62]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     104.45      99.321      357.74      415.46]\n",
      "Detected: severe, Confidence: 0.31, Box: [      99.95      59.591         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     103.09      100.56         317      415.68]\n",
      "Detected: severe, Confidence: 0.40, Box: [     102.76      99.641      353.65         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.1ms\n",
      "Speed: 2.9ms preprocess, 8.1ms inference, 7.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [      103.5      99.488      321.05      415.65]\n",
      "Detected: severe, Confidence: 0.38, Box: [     103.08      98.255       360.2         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     104.31      97.199      317.09         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     104.84      95.982      321.88         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 11.0ms\n",
      "Speed: 1.2ms preprocess, 11.0ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     104.87      96.271      320.26         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 5.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.54, Box: [     104.34      96.199       317.3         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     104.43      92.246      345.61         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 0.8ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     104.06      96.228      315.36         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     104.23      92.117       343.7         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 6.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [      103.9      95.357      315.43         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     104.13      91.596      344.55         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     103.16      96.157      317.23         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     103.74      91.553       371.8         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [      102.8      96.156      334.36         416]\n",
      "Detected: severe, Confidence: 0.36, Box: [     103.22      88.956      392.87         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     102.81       95.78      338.67         416]\n",
      "Detected: severe, Confidence: 0.34, Box: [     103.42      90.314      400.35         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     102.41      97.822      322.85         416]\n",
      "Detected: severe, Confidence: 0.37, Box: [     102.85      95.589      385.09         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 10.6ms\n",
      "Speed: 1.2ms preprocess, 10.6ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     103.19       99.82       339.3         416]\n",
      "Detected: severe, Confidence: 0.37, Box: [     103.15      98.827       395.9         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.55, Box: [     103.77      95.649      366.33         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     103.98       86.39      409.65         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     104.05      93.419      337.04         416]\n",
      "Detected: severe, Confidence: 0.41, Box: [     103.75      91.241      391.86         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     103.37      91.463      328.97         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     102.94      90.517      394.24         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [      100.6      91.259      304.82         416]\n",
      "Detected: severe, Confidence: 0.33, Box: [     100.52      90.853      359.37         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.59, Box: [     100.05      93.214      307.24         416]\n",
      "Detected: severe, Confidence: 0.36, Box: [     99.513      93.356      375.68         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     98.854      94.934      302.09         416]\n",
      "Detected: severe, Confidence: 0.30, Box: [     98.954      94.572      352.14         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     98.731      94.562      302.01         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.56, Box: [     96.683      95.133      299.34         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 8.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.57, Box: [     95.546      94.754      301.09         416]\n",
      "\n",
      "0: 224x224 2 very_severes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     94.218       93.36      303.19         416]\n",
      "Detected: very_severe, Confidence: 0.30, Box: [     92.162      91.411      393.03      415.17]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.61, Box: [     92.401      93.901      298.79         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.62, Box: [     89.459      94.017      298.09         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.63, Box: [     88.524      93.947      335.68         416]\n",
      "Detected: severe, Confidence: 0.34, Box: [     88.028      35.749         416         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     90.017      92.853      332.83         416]\n",
      "\n",
      "0: 224x224 1 very_severe, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: very_severe, Confidence: 0.60, Box: [     92.543       97.86      336.77         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 3.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     98.201      97.184      378.95         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     94.987      9.2753         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 3.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.51, Box: [     100.21      91.806      401.67         416]\n",
      "Detected: severe, Confidence: 0.35, Box: [     96.027      1.1855         416         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.46, Box: [     106.01       21.92      401.47         416]\n",
      "Detected: severe, Confidence: 0.39, Box: [     100.18     0.61227      415.99         416]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.44, Box: [     110.57      1.5562         416      415.89]\n",
      "Detected: severe, Confidence: 0.41, Box: [     104.89      1.5474      415.99      415.58]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.50, Box: [     79.607           0         416      415.91]\n",
      "Detected: severe, Confidence: 0.40, Box: [     103.35           0      415.93      415.57]\n",
      "\n",
      "0: 224x224 1 severe, 1 very_severe, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 3.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 2\n",
      "Detected: very_severe, Confidence: 0.58, Box: [     85.755     0.26091         416      415.55]\n",
      "Detected: severe, Confidence: 0.41, Box: [     10.399           0         416       415.3]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 2.9ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.56, Box: [    0.74783           0         416      415.99]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 16.4ms\n",
      "Speed: 1.6ms preprocess, 16.4ms inference, 5.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 7.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.2ms\n",
      "Speed: 4.1ms preprocess, 10.2ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.9ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.0ms\n",
      "Speed: 1.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.4ms\n",
      "Speed: 2.4ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 3.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 6.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.3ms\n",
      "Speed: 3.1ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 5.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 6.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 14.0ms\n",
      "Speed: 1.6ms preprocess, 14.0ms inference, 4.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.8ms\n",
      "Speed: 1.5ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 5.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 14.7ms\n",
      "Speed: 4.4ms preprocess, 14.7ms inference, 5.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.7ms\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 13.0ms\n",
      "Speed: 1.2ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.2ms\n",
      "Speed: 1.2ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0    0.023577         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.19686         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0      1.8793         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      2.4881         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0       2.297         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      1.9064         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      1.4109         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 4.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0       1.537      415.99         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 5.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0      1.3593         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.88448         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.13747         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 2.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0    0.041175         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.98958         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 3.2ms preprocess, 7.8ms inference, 5.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0      1.7095         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0      1.2926         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 14.7ms\n",
      "Speed: 1.5ms preprocess, 14.7ms inference, 12.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.89822         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 6.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.25269         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.60141         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.96, Box: [          0     0.18762         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0       1.402      415.88      415.64]\n",
      "\n",
      "0: 224x224 1 normal, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 4.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.18626         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.47664         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      0.8146         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0      1.3055         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 5.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.75104         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 5.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.26161         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 5.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 5.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.5ms\n",
      "Speed: 1.7ms preprocess, 12.5ms inference, 4.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0     0.18845         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.4ms\n",
      "Speed: 0.9ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.5ms\n",
      "Speed: 4.2ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 6.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 2.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 5.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 13.0ms\n",
      "Speed: 1.5ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 5.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.8ms\n",
      "Speed: 0.9ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.9ms\n",
      "Speed: 1.3ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 9.5ms\n",
      "Speed: 1.3ms preprocess, 9.5ms inference, 5.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 11.9ms\n",
      "Speed: 4.3ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.97, Box: [          0           0         416         416]\n",
      "\n",
      "0: 224x224 1 normal, 12.0ms\n",
      "Speed: 1.1ms preprocess, 12.0ms inference, 3.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Number of detections: 1\n",
      "Detected: normal, Confidence: 0.98, Box: [          0           0         416         416]\n"
     ]
    }
   ],
   "source": [
    "# 15. 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 재학습 (필요 시 주석 해제)\n",
    "    # retrain_model()\n",
    "    \n",
    "    # 학습 결과 시각화 (이미 실행됨)\n",
    "    \n",
    "    # 테스트 이미지\n",
    "    sample_image = os.path.join(BASE_DIR, 'yolo_dataset/test/images/severe_image.jpg')\n",
    "    if os.path.exists(sample_image):\n",
    "        print(\"Processing image...\")\n",
    "        detect_acne_image(sample_path, conf_threshold=0.3, save_output=True)\n",
    "    \n",
    "    # 테스트 비디오\n",
    "    sample_video = os.path.join(BASE_DIR, 'test/videos/sample.mp4')\n",
    "    if os.path.exists(sample_video):\n",
    "        print(\"Processing video...\")\n",
    "        detect_acne_video(sample_video, conf_threshold=0.3, save_output=True)\n",
    "    \n",
    "    # 웹캠 감지\n",
    "    print(\"Starting webcam detection... Press 'q' to quit.\")\n",
    "    detect_acne_webcam(conf_threshold=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
