{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "910ca836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from glob import glob\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# --- 1. 기본 경로 및 최종 설정 ---\n",
    "BASE_DATA_PATH = 'C:/Users/Admin/work space/2nd/'\n",
    "ROBOFLOW_API_KEY = \"NjIXpou4o4gsuGClT8hI\"\n",
    "PREVIOUS_MODEL_PATH = os.path.join(BASE_DATA_PATH, 'acne_model_8_classes_retrained', 'weights', 'best.pt')\n",
    "DATASET1_NAME = 'acne04-1'\n",
    "DATASET2_NAME = 'Acne-detection-1'\n",
    "# 사용자가 확인하고 수정한 실제 폴더 이름\n",
    "DATASET3_NAME = \"Acne-detection-9\"\n",
    "DATASET4_NAME = \"acne-detection-nv9i6-ddxoy-1\"\n",
    "COMBINED_DATASET_NAME = 'acne_dataset_final_ALL'\n",
    "TRAINING_NAME = 'acne_model_final_ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1c338de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 데이터셋 폴더 존재 여부를 확인합니다...\n",
      "✅ 'Acne-detection-9' 데이터셋 폴더를 찾았습니다.\n",
      "✅ 'acne-detection-nv9i6-ddxoy-1' 데이터셋 폴더를 찾았습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 데이터셋 폴더 확인 ---\n",
    "print(\"🚀 데이터셋 폴더 존재 여부를 확인합니다...\")\n",
    "if os.path.exists(os.path.join(BASE_DATA_PATH, DATASET3_NAME)): print(f\"✅ '{DATASET3_NAME}' 데이터셋 폴더를 찾았습니다.\")\n",
    "else: print(f\"🚨 '{DATASET3_NAME}' 데이터셋 폴더를 찾을 수 없습니다.\")\n",
    "if os.path.exists(os.path.join(BASE_DATA_PATH, DATASET4_NAME)): print(f\"✅ '{DATASET4_NAME}' 데이터셋 폴더를 찾았습니다.\")\n",
    "else: print(f\"🚨 '{DATASET4_NAME}' 데이터셋 폴더를 찾을 수 없습니다.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee0d751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 3 원본 클래스: ['Pustula', 'acne fulminans', 'blackhead', 'fungal acne', 'nodules', 'papula', 'whitehead']\n",
      "데이터셋 4 원본 클래스: ['Acne', 'Birthmark', 'Blackhead', 'Cysts', 'Milium', 'Papular', 'Purulent', 'Scars', 'Whitehead']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 클래스 목록 정의 및 확인 (수정된 함수) ---\n",
    "FINAL_CLASS_NAMES = sorted(['blackheads', 'comedone', 'cyst', 'fore', 'nodule', 'papule', 'pustule', 'whiteheads'])\n",
    "final_class_set = set(FINAL_CLASS_NAMES)\n",
    "\n",
    "def get_class_names(dataset_path):\n",
    "    yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
    "    if os.path.exists(yaml_path):\n",
    "        with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "            # ❗️[수정]❗️ yaml.safe_load 로 수정\n",
    "            return yaml.safe_load(f).get('names', [])\n",
    "    return []\n",
    "\n",
    "src_path_d3 = os.path.join(BASE_DATA_PATH, DATASET3_NAME)\n",
    "src_path_d4 = os.path.join(BASE_DATA_PATH, DATASET4_NAME)\n",
    "d3_names = get_class_names(src_path_d3)\n",
    "d4_names = get_class_names(src_path_d4)\n",
    "print(f\"데이터셋 3 원본 클래스: {d3_names}\")\n",
    "print(f\"데이터셋 4 원본 클래스: {d4_names}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a277fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수동 매핑 규칙이 적용되었습니다.\n",
      "데이터셋 3 매핑: {'blackhead': 'blackheads', 'nodules': 'nodule', 'papula': 'papule', 'Pustula': 'pustule', 'whitehead': 'whiteheads'}\n",
      "데이터셋 4 매핑: {'Blackhead': 'blackheads', 'Cysts': 'cyst', 'Papular': 'papule', 'Whitehead': 'whiteheads'}\n"
     ]
    }
   ],
   "source": [
    "# --- 4. 클래스 ID 재매핑 테이블 생성 (수동 매핑 적용) ---\n",
    "final_name_to_id = {name: i for i, name in enumerate(FINAL_CLASS_NAMES)}\n",
    "\n",
    "# 기존 데이터셋 1, 2 매핑\n",
    "ORIGINAL_D1_NAMES = ['fore', 'papule', 'pustule', 'nodule', 'whiteheads', 'cyst', 'blackheads']\n",
    "remap_d1 = {i: final_name_to_id[name] for i, name in enumerate(ORIGINAL_D1_NAMES)}\n",
    "ORIGINAL_D2_NAMES = ['comedone', 'pustule', 'papule', 'cyst', 'nodule']\n",
    "remap_d2 = {i: final_name_to_id[name] for i, name in enumerate(ORIGINAL_D2_NAMES)}\n",
    "\n",
    "# 수동 매핑 규칙\n",
    "MANUAL_MAP_D3 = {\n",
    "    'blackhead': 'blackheads',\n",
    "    'nodules': 'nodule',\n",
    "    'papula': 'papule',\n",
    "    'Pustula': 'pustule',\n",
    "    'whitehead': 'whiteheads'\n",
    "}\n",
    "MANUAL_MAP_D4 = {\n",
    "    'Blackhead': 'blackheads',\n",
    "    'Cysts': 'cyst',\n",
    "    'Papular': 'papule',\n",
    "    'Whitehead': 'whiteheads'\n",
    "}\n",
    "print(\"✅ 수동 매핑 규칙이 적용되었습니다.\")\n",
    "print(f\"데이터셋 3 매핑: {MANUAL_MAP_D3}\")\n",
    "print(f\"데이터셋 4 매핑: {MANUAL_MAP_D4}\")\n",
    "\n",
    "# 수동 매핑 규칙 기반 ID 변환 테이블 생성\n",
    "original_d3_name_to_id = {name: i for i, name in enumerate(d3_names)}\n",
    "remap_d3 = {\n",
    "    original_d3_name_to_id[new_name]: final_name_to_id[final_name]\n",
    "    for new_name, final_name in MANUAL_MAP_D3.items()\n",
    "    if new_name in original_d3_name_to_id\n",
    "}\n",
    "id_to_name_d3 = {i: name for name, i in original_d3_name_to_id.items()}\n",
    "\n",
    "original_d4_name_to_id = {name: i for i, name in enumerate(d4_names)}\n",
    "remap_d4 = {\n",
    "    original_d4_name_to_id[new_name]: final_name_to_id[final_name]\n",
    "    for new_name, final_name in MANUAL_MAP_D4.items()\n",
    "    if new_name in original_d4_name_to_id\n",
    "}\n",
    "id_to_name_d4 = {i: name for name, i in original_d4_name_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ac95d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'C:/Users/Admin/work space/2nd/acne_dataset_final_ALL' 폴더를 생성하고 4개 데이터셋 병합을 시작합니다...\n",
      "1/4 - 기존 데이터셋 1 처리 중...\n",
      "2/4 - 기존 데이터셋 2 처리 중...\n",
      "3/4 - 추가 데이터셋 3 처리 중...\n",
      "4/4 - 추가 데이터셋 4 처리 중...\n",
      "✅ 데이터 병합 완료!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 데이터 병합 및 라벨 재매핑 실행 ---\n",
    "src_path_d1 = os.path.join(BASE_DATA_PATH, DATASET1_NAME)\n",
    "src_path_d2 = os.path.join(BASE_DATA_PATH, DATASET2_NAME)\n",
    "combined_path = os.path.join(BASE_DATA_PATH, COMBINED_DATASET_NAME)\n",
    "\n",
    "if os.path.exists(combined_path):\n",
    "    shutil.rmtree(combined_path)\n",
    "print(f\"\\n'{combined_path}' 폴더를 생성하고 4개 데이터셋 병합을 시작합니다...\")\n",
    "\n",
    "def process_dataset(src_path, remap_dict, dest_path, classes_to_keep=None, id_to_name_map=None):\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        src_image_dir, src_label_dir = os.path.join(src_path, split, 'images'), os.path.join(src_path, split, 'labels')\n",
    "        if not os.path.exists(src_image_dir): continue\n",
    "        dest_image_dir, dest_label_dir = os.path.join(dest_path, split, 'images'), os.path.join(dest_path, split, 'labels')\n",
    "        os.makedirs(dest_image_dir, exist_ok=True); os.makedirs(dest_label_dir, exist_ok=True)\n",
    "        for label_filename in glob(os.path.join(src_label_dir, '*.txt')):\n",
    "            base_filename = os.path.basename(label_filename)\n",
    "            with open(label_filename, 'r') as f_in: lines = f_in.readlines()\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split();\n",
    "                if not parts: continue\n",
    "                original_id = int(parts[0])\n",
    "                if classes_to_keep and id_to_name_map.get(original_id) not in classes_to_keep: continue\n",
    "                if original_id in remap_dict:\n",
    "                    parts[0] = str(remap_dict[original_id]); new_lines.append(' '.join(parts) + '\\n')\n",
    "            if new_lines:\n",
    "                with open(os.path.join(dest_label_dir, base_filename), 'w') as f_out: f_out.writelines(new_lines)\n",
    "                img_name_base = os.path.splitext(base_filename)[0]\n",
    "                for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                    src_image_path = os.path.join(src_image_dir, img_name_base + ext)\n",
    "                    if os.path.exists(src_image_path): shutil.copy(src_image_path, os.path.join(dest_image_dir, img_name_base + ext)); break\n",
    "\n",
    "print(\"1/4 - 기존 데이터셋 1 처리 중...\"); process_dataset(src_path_d1, remap_d1, combined_path)\n",
    "print(\"2/4 - 기존 데이터셋 2 처리 중...\"); process_dataset(src_path_d2, remap_d2, combined_path)\n",
    "print(\"3/4 - 추가 데이터셋 3 처리 중...\"); process_dataset(src_path_d3, remap_d3, combined_path, classes_to_keep=list(MANUAL_MAP_D3.keys()), id_to_name_map=id_to_name_d3)\n",
    "print(\"4/4 - 추가 데이터셋 4 처리 중...\"); process_dataset(src_path_d4, remap_d4, combined_path, classes_to_keep=list(MANUAL_MAP_D4.keys()), id_to_name_map=id_to_name_d4)\n",
    "print(\"✅ 데이터 병합 완료!\"); print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e8fb0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 최종 'C:/Users/Admin/work space/2nd/acne_dataset_final_ALL\\data.yaml' 파일 생성 완료!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 6. 최종 data.yaml 파일 생성 ---\n",
    "final_yaml_path = os.path.join(combined_path, 'data.yaml')\n",
    "yaml_data = {'train': 'train/images', 'val': 'valid/images', 'test': 'test/images', 'nc': len(FINAL_CLASS_NAMES), 'names': FINAL_CLASS_NAMES}\n",
    "with open(final_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)\n",
    "print(f\"✅ 최종 '{final_yaml_path}' 파일 생성 완료!\"); print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6192e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 이전 최강 모델 'C:/Users/Admin/work space/2nd/acne_model_8_classes_retrained\\weights\\best.pt'을 불러와 최종 학습을 시작합니다...\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.200  Python-3.13.7 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/Admin/work space/2nd/acne_dataset_final_ALL\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/Admin/work space/2nd/acne_model_8_classes_retrained\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=acne_model_final_ALL3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/Admin/work space/2nd/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Admin\\work space\\2nd\\acne_model_final_ALL3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 33.865.1 MB/s, size: 228.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Admin\\work space\\2nd\\acne_dataset_final_ALL\\train\\labels... 3512 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3512/3512 236.8it/s 14.8s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Admin\\work space\\2nd\\acne_dataset_final_ALL\\train\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 3, len(boxes) = 25779. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "WARNING cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.0GB RAM): 100% ━━━━━━━━━━━━ 3512/3512 749.0it/s 4.7s0.1ss\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.80.4 ms, read: 1.00.7 MB/s, size: 23.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Admin\\work space\\2nd\\acne_dataset_final_ALL\\valid\\labels... 634 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 634/634 105.3it/s 6.0s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Admin\\work space\\2nd\\acne_dataset_final_ALL\\valid\\labels.cache\n",
      "WARNING cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100% ━━━━━━━━━━━━ 634/634 664.5it/s 1.0s0.0s\n",
      "Plotting labels to C:\\Users\\Admin\\work space\\2nd\\acne_model_final_ALL3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Admin\\work space\\2nd\\acne_model_final_ALL3\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/150      2.96G       2.49      3.776      1.858         69        640: 100% ━━━━━━━━━━━━ 220/220 3.0it/s 1:12<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 2.9it/s 6.8s0.3s\n",
      "                   all        634       4875      0.407      0.227       0.16     0.0597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/150      3.27G      2.355      2.623      1.747        101        640: 100% ━━━━━━━━━━━━ 220/220 3.8it/s 57.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.0it/s 6.7s0.3s\n",
      "                   all        634       4875      0.228      0.252      0.167     0.0606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/150      3.29G      2.334       2.52      1.706         67        640: 100% ━━━━━━━━━━━━ 220/220 4.1it/s 53.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 2.8it/s 7.1s0.3s\n",
      "                   all        634       4875      0.235      0.257      0.155     0.0572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/150      3.64G      2.307      2.508      1.698         90        640: 100% ━━━━━━━━━━━━ 220/220 3.9it/s 56.7s<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.1it/s 6.4s0.2s\n",
      "                   all        634       4875      0.413      0.222      0.193     0.0752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/150      3.65G      2.277      2.454      1.681         96        640: 100% ━━━━━━━━━━━━ 220/220 5.0it/s 44.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 4.1it/s 4.9s0.2s\n",
      "                   all        634       4875      0.296      0.235      0.216     0.0869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/150      3.67G      2.269      2.406      1.669         41        640: 100% ━━━━━━━━━━━━ 220/220 6.5it/s 33.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 4.0it/s 4.9s0.2s\n",
      "                   all        634       4875      0.305      0.254      0.202     0.0742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/150      3.69G       2.27      2.424      1.671         54        640: 100% ━━━━━━━━━━━━ 220/220 5.7it/s 38.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.3it/s 6.1s0.3s\n",
      "                   all        634       4875      0.209      0.277       0.16     0.0618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/150      3.71G      2.249      2.409      1.658        103        640: 100% ━━━━━━━━━━━━ 220/220 4.7it/s 47.2s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.6it/s 5.6s0.3s\n",
      "                   all        634       4875      0.286      0.288      0.222     0.0931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/150      3.72G      2.234      2.371      1.638         59        640: 100% ━━━━━━━━━━━━ 220/220 4.9it/s 44.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.3it/s 6.1s0.3s\n",
      "                   all        634       4875      0.279      0.265      0.187     0.0747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/150      3.74G      2.217      2.356      1.631         46        640: 100% ━━━━━━━━━━━━ 220/220 5.0it/s 44.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.4it/s 5.8s0.3s\n",
      "                   all        634       4875      0.235      0.301       0.22     0.0856\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/150      3.76G      2.217      2.322      1.617         33        640: 100% ━━━━━━━━━━━━ 220/220 4.9it/s 44.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.2it/s 6.2s0.3s\n",
      "                   all        634       4875      0.285      0.282      0.224     0.0941\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/150      3.77G      2.208      2.294      1.605         85        640: 100% ━━━━━━━━━━━━ 220/220 5.3it/s 41.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.3it/s 6.1s0.3s\n",
      "                   all        634       4875      0.288      0.296      0.234     0.0992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/150      3.79G      2.199      2.296      1.605         70        640: 100% ━━━━━━━━━━━━ 220/220 5.2it/s 42.2s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 3.3it/s 6.0s0.3s\n",
      "                   all        634       4875      0.267      0.304      0.232     0.0903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/150      3.81G      2.208      2.281      1.599         59        640: 100% ━━━━━━━━━━━━ 220/220 5.4it/s 40.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 20/20 4.8it/s 4.1s0.2s\n",
      "                   all        634       4875       0.27      0.301      0.219     0.0905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/150      3.81G      2.217      2.264      1.623        107        640: 5% ╸─────────── 12/220 6.4it/s 2.2s<32.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🚀 이전 최강 모델 \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREVIOUS_MODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m을 불러와 최종 학습을 시작합니다...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m model = YOLO(PREVIOUS_MODEL_PATH)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_yaml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_DATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAINING_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 최종 학습 완료! 결과 저장 경로: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.join(BASE_DATA_PATH,\u001b[38;5;250m \u001b[39mTRAINING_NAME)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- 8. 최종 모델 성능 검증 ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:235\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:420\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# decouple inference and loss calculations for torch.compile convenience\u001b[39;00m\n\u001b[32m    419\u001b[39m preds = \u001b[38;5;28mself\u001b[39m.model(batch[\u001b[33m\"\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[43munwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:339\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    338\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.forward(batch[\u001b[33m\"\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\utils\\loss.py:263\u001b[39m, in \u001b[36mv8DetectionLoss.__call__\u001b[39m\u001b[34m(self, preds, batch)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# Targets\u001b[39;00m\n\u001b[32m    262\u001b[39m targets = torch.cat((batch[\u001b[33m\"\u001b[39m\u001b[33mbatch_idx\u001b[39m\u001b[33m\"\u001b[39m].view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m), batch[\u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m].view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m), batch[\u001b[33m\"\u001b[39m\u001b[33mbboxes\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m targets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m gt_labels, gt_bboxes = targets.split((\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m), \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# cls, xyxy\u001b[39;00m\n\u001b[32m    265\u001b[39m mask_gt = gt_bboxes.sum(\u001b[32m2\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).gt_(\u001b[32m0.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\project\\Lib\\site-packages\\ultralytics\\utils\\loss.py:232\u001b[39m, in \u001b[36mv8DetectionLoss.preprocess\u001b[39m\u001b[34m(self, targets, batch_size, scale_tensor)\u001b[39m\n\u001b[32m    230\u001b[39m         matches = i == j\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n := matches.sum():\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m             out[j, :n] = targets[matches, \u001b[32m1\u001b[39m:]\n\u001b[32m    233\u001b[39m     out[..., \u001b[32m1\u001b[39m:\u001b[32m5\u001b[39m] = xywh2xyxy(out[..., \u001b[32m1\u001b[39m:\u001b[32m5\u001b[39m].mul_(scale_tensor))\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 7. 최종 모델 추가 학습 (Fine-tuning) ---\n",
    "if not os.path.exists(PREVIOUS_MODEL_PATH):\n",
    "     print(f\"🚨 에러: 이전 모델 '{PREVIOUS_MODEL_PATH}'를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"🚀 이전 최강 모델 '{PREVIOUS_MODEL_PATH}'을 불러와 최종 학습을 시작합니다...\")\n",
    "    model = YOLO(PREVIOUS_MODEL_PATH)\n",
    "    results = model.train(data=final_yaml_path, epochs=150, imgsz=640, batch=16, patience=50, project=BASE_DATA_PATH, name=TRAINING_NAME, workers=4, cache=True)\n",
    "    print(f\"\\n🎉 최종 학습 완료! 결과 저장 경로: {os.path.join(BASE_DATA_PATH, TRAINING_NAME)}\")\n",
    "\n",
    "    # --- 8. 최종 모델 성능 검증 ---\n",
    "    print(\"\\n🚀 테스트 데이터셋으로 최종 모델 성능을 검증합니다...\")\n",
    "    best_model_path = os.path.join(BASE_DATA_PATH, TRAINING_NAME, 'weights', 'best.pt')\n",
    "    if os.path.exists(best_model_path):\n",
    "        model = YOLO(best_model_path)\n",
    "        metrics = model.val(data=final_yaml_path, split='test', imgsz=640)\n",
    "        print(\"\\n--- 최종 성능 지표 ---\")\n",
    "        print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "        print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "        print(f\"mAP75: {metrics.box.map75:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe8633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
